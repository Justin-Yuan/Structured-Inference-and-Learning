{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practical 2: Text Classification with Word Embedding\n",
    "<p>Oxford CS - Deep NLP 2017<br>\n",
    "https://www.cs.ox.ac.uk/teaching/courses/2016-2017/dl/</p>\n",
    "<p>[Yannis Assael, Brendan Shillingford, Chris Dyer]</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from random import shuffle\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <a href=\"http://bokeh.pydata.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"ed9f3fa6-62cb-4b83-84c1-ce6a6f754b8a\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(global) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "\n",
       "  if (typeof (window._bokeh_onload_callbacks) === \"undefined\" || force === true) {\n",
       "    window._bokeh_onload_callbacks = [];\n",
       "    window._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "\n",
       "  \n",
       "  if (typeof (window._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    window._bokeh_timeout = Date.now() + 5000;\n",
       "    window._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  var NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    if (window.Bokeh !== undefined) {\n",
       "      var el = document.getElementById(\"ed9f3fa6-62cb-4b83-84c1-ce6a6f754b8a\");\n",
       "      el.textContent = \"BokehJS \" + Bokeh.version + \" successfully loaded.\";\n",
       "    } else if (Date.now() < window._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function run_callbacks() {\n",
       "    window._bokeh_onload_callbacks.forEach(function(callback) { callback() });\n",
       "    delete window._bokeh_onload_callbacks\n",
       "    console.info(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(js_urls, callback) {\n",
       "    window._bokeh_onload_callbacks.push(callback);\n",
       "    if (window._bokeh_is_loading > 0) {\n",
       "      console.log(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.log(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    window._bokeh_is_loading = js_urls.length;\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      var s = document.createElement('script');\n",
       "      s.src = url;\n",
       "      s.async = false;\n",
       "      s.onreadystatechange = s.onload = function() {\n",
       "        window._bokeh_is_loading--;\n",
       "        if (window._bokeh_is_loading === 0) {\n",
       "          console.log(\"Bokeh: all BokehJS libraries loaded\");\n",
       "          run_callbacks()\n",
       "        }\n",
       "      };\n",
       "      s.onerror = function() {\n",
       "        console.warn(\"failed to load library \" + url);\n",
       "      };\n",
       "      console.log(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "    }\n",
       "  };var element = document.getElementById(\"ed9f3fa6-62cb-4b83-84c1-ce6a6f754b8a\");\n",
       "  if (element == null) {\n",
       "    console.log(\"Bokeh: ERROR: autoload.js configured with elementid 'ed9f3fa6-62cb-4b83-84c1-ce6a6f754b8a' but no matching script tag was found. \")\n",
       "    return false;\n",
       "  }\n",
       "\n",
       "  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.5.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.5.min.js\"];\n",
       "\n",
       "  var inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    \n",
       "    function(Bokeh) {\n",
       "      \n",
       "    },\n",
       "    \n",
       "    function(Bokeh) {\n",
       "      \n",
       "      document.getElementById(\"ed9f3fa6-62cb-4b83-84c1-ce6a6f754b8a\").textContent = \"BokehJS is loading...\";\n",
       "    },\n",
       "    function(Bokeh) {\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-0.12.5.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.5.min.css\");\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.5.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.5.min.css\");\n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    \n",
       "    if ((window.Bokeh !== undefined) || (force === true)) {\n",
       "      for (var i = 0; i < inline_js.length; i++) {\n",
       "        inline_js[i](window.Bokeh);\n",
       "      }if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < window._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!window._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      window._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      var cell = $(document.getElementById(\"ed9f3fa6-62cb-4b83-84c1-ce6a6f754b8a\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "\n",
       "  }\n",
       "\n",
       "  if (window._bokeh_is_loading === 0) {\n",
       "    console.log(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(js_urls, function() {\n",
       "      console.log(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(this));"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from bokeh.models import ColumnDataSource, LabelSet\n",
    "from bokeh.plotting import figure, show, output_file\n",
    "from bokeh.io import output_notebook\n",
    "output_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load TED dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import zipfile\n",
    "import lxml.etree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Download the dataset if it's not already there: this may take a minute as it is 75MB\n",
    "if not os.path.isfile('ted_en-20160408.zip'):\n",
    "    urllib.request.urlretrieve(\"https://wit3.fbk.eu/get.php?path=XML_releases/xml/ted_en-20160408.zip&filename=ted_en-20160408.zip\", filename=\"ted_en-20160408.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with zipfile.ZipFile('ted_en-20160408.zip', 'r') as z:\n",
    "    doc = lxml.etree.parse(z.open('ted_en-20160408.xml', 'r'))\n",
    "    #print(lxml.etree.tostring(doc).decode('ascii')[10000:30000])\n",
    "\n",
    "input_text = '\\n'.join(doc.xpath('//content/text()'))\n",
    "del doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For now, we're only interested in the subtitle text, so let's extract that from the XML:\n",
    "with zipfile.ZipFile('ted_en-20160408.zip', 'r') as z:\n",
    "    doc = lxml.etree.parse(z.open('ted_en-20160408.xml', 'r'))\n",
    "    #print(lxml.etree.tostring(doc).decode('ascii')[10000:30000])\n",
    "\n",
    "# input_text = '\\n'.join(doc.xpath('//content/text()'))\n",
    "\n",
    "# print(type(doc.xpath('//content/text()')))  ->  list \n",
    "doc_list = doc.xpath('//content/text()')\n",
    "label_list = doc.xpath('//keywords/text()')\n",
    "\n",
    "del doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Here are two reasons companies fail: they only do more of the same, or they only do what\\'s new.\\nTo me the real, real solution to quality growth is figuring out the balance between two activities: exploration and exploitation. Both are necessary, but it can be too much of a good thing.\\nConsider Facit. I\\'m actually old enough to remember them. Facit was a fantastic company. They were born deep in the Swedish forest, and they made the best mechanical calculators in the world. Everybody used them. And what did Facit do when the electronic calculator came along? They continued doing exactly the same. In six months, they went from maximum revenue ... and they were gone. Gone.\\nTo me, the irony about the Facit story is hearing about the Facit engineers, who had bought cheap, small electronic calculators in Japan that they used to double-check their calculators.\\n(Laughter)\\nFacit did too much exploitation. But exploration can go wild, too.\\nA few years back, I worked closely alongside a European biotech company. Let\\'s call them OncoSearch. The company was brilliant. They had applications that promised to diagnose, even cure, certain forms of blood cancer. Every day was about creating something new. They were extremely innovative, and the mantra was, \"When we only get it right,\" or even, \"We want it perfect.\" The sad thing is, before they became perfect -- even good enough -- they became obsolete. OncoSearch did too much exploration.\\nI first heard about exploration and exploitation about 15 years ago, when I worked as a visiting scholar at Stanford University. The founder of the idea is Jim March. And to me the power of the idea is its practicality.\\nExploration. Exploration is about coming up with what\\'s new. It\\'s about search, it\\'s about discovery, it\\'s about new products, it\\'s about new innovations. It\\'s about changing our frontiers. Our heroes are people who have done exploration: Madame Curie, Picasso, Neil Armstrong, Sir Edmund Hillary, etc. I come from Norway; all our heroes are explorers, and they deserve to be. We all know that exploration is risky. We don\\'t know the answers, we don\\'t know if we\\'re going to find them, and we know that the risks are high.\\nExploitation is the opposite. Exploitation is taking the knowledge we have and making good, better. Exploitation is about making our trains run on time. It\\'s about making good products faster and cheaper. Exploitation is not risky -- in the short term. But if we only exploit, it\\'s very risky in the long term. And I think we all have memories of the famous pop groups who keep singing the same songs again and again, until they become obsolete or even pathetic. That\\'s the risk of exploitation.\\nSo if we take a long-term perspective, we explore. If we take a short-term perspective, we exploit. Small children, they explore all day. All day it\\'s about exploration. As we grow older, we explore less because we have more knowledge to exploit on. The same goes for companies. Companies become, by nature, less innovative as they become more competent.\\nAnd this is, of course, a big worry to CEOs. And I hear very often questions phrased in different ways. For example, \"How can I both effectively run and reinvent my company?\" Or, \"How can I make sure that our company changes before we become obsolete or are hit by a crisis?\" So, doing one well is difficult. Doing both well as the same time is art -- pushing both exploration and exploitation.\\nSo one thing we\\'ve found is only about two percent of companies are able to effectively explore and exploit at the same time, in parallel. But when they do, the payoffs are huge. So we have lots of great examples. We have Nestlé creating Nespresso, we have Lego going into animated films, Toyota creating the hybrids, Unilever pushing into sustainability -- there are lots of examples, and the benefits are huge.\\nWhy is balancing so difficult? I think it\\'s difficult because there are so many traps that keep us where we are. So I\\'ll talk about two, but there are many.\\nSo let\\'s talk about the perpetual search trap. We discover something, but we don\\'t have the patience or the persistence to get at it and make it work. So instead of staying with it, we create something new. But the same goes for that, then we\\'re in the vicious circle of actually coming up with ideas but being frustrated. OncoSearch was a good example. A famous example is, of course, Xerox. But we don\\'t only see this in companies. We see this in the public sector as well. We all know that any kind of effective reform of education, research, health care, even defense, takes 10, 15, maybe 20 years to work. But still, we change much more often. We really don\\'t give them the chance.\\nAnother trap is the success trap. Facit fell into the success trap. They literally held the future in their hands, but they couldn\\'t see it. They were simply so good at making what they loved doing, that they wouldn\\'t change. We are like that, too. When we know something well, it\\'s difficult to change. Bill Gates has said: \"Success is a lousy teacher. It seduces us into thinking we cannot fail.\" That\\'s the challenge with success.\\nSo I think there are some lessons, and I think they apply to us. And they apply to our companies. The first lesson is: get ahead of the crisis. And any company that\\'s able to innovate is actually able to also buy an insurance in the future. Netflix -- they could so easily have been content with earlier generations of distribution, but they always -- and I think they will always -- keep pushing for the next battle. I see other companies that say, \"I\\'ll win the next innovation cycle, whatever it takes.\"\\nSecond one: think in multiple time scales. I\\'ll share a chart with you, and I think it\\'s a wonderful one. Any company we look at, taking a one-year perspective and looking at the valuation of the company, innovation typically accounts for only about 30 percent. So when we think one year, innovation isn\\'t really that important. Move ahead, take a 10-year perspective on the same company -- suddenly, innovation and ability to renew account for 70 percent. But companies can\\'t choose. They need to fund the journey and lead the long term.\\nThird: invite talent. I don\\'t think it\\'s possible for any of us to be able to balance exploration and exploitation by ourselves. I think it\\'s a team sport. I think we need to allow challenging. I think the mark of a great company is being open to be challenged, and the mark of a good corporate board is to constructively challenge. I think that\\'s also what good parenting is about.\\nLast one: be skeptical of success. Maybe it\\'s useful to think back at the old triumph marches in Rome, when the generals, after a big victory, were given their celebration. Riding into Rome on the carriage, they always had a companion whispering in their ear, \"Remember, you\\'re only human.\"\\nSo I hope I made the point: balancing exploration and exploitation has a huge payoff. But it\\'s difficult, and we need to be conscious.\\nI want to just point out two questions that I think are useful. First question is, looking at your own company: In which areas do you see that the company is at the risk of falling into success traps, of just going on autopilot? And what can you do to challenge?\\nSecond question is: When did I explore something new last, and what kind of effect did it have on me? Is that something I should do more of? In my case, yes.\\nSo let me leave you with this. Whether you\\'re an explorer by nature or whether you tend to exploit what you already know, don\\'t forget: the beauty is in the balance.\\nThank you.\\n(Applause)', 'So there are lands few and far between on Earth itself that are hospitable to humans by any measure, but survive we have. Our primitive ancestors, when they found their homes and livelihood endangered, they dared to make their way into unfamiliar territories in search of better opportunities. And as the descendants of these explorers, we have their nomadic blood coursing through our own veins. But at the same time, distracted by our bread and circuses and embroiled in the wars that we have waged on each other, it seems that we have forgotten this desire to explore. We, as a species, we\\'re evolved uniquely for Earth, on Earth, and by Earth, and so content are we with our living conditions that we have grown complacent and just too busy to notice that its resources are finite, and that our Sun\\'s life is also finite. While Mars and all the movies made in its name have reinvigorated the ethos for space travel, few of us seem to truly realize that our species\\' fragile constitution is woefully unprepared for long duration journeys into space.\\nLet us take a trek to your local national forest for a quick reality check. So just a quick show of hands here: how many of you think you would be able to survive in this lush wilderness for a few days? Well, that\\'s a lot of you. How about a few weeks? That\\'s a decent amount. How about a few months? That\\'s pretty good too. Now, let us imagine that this local national forest experiences an eternal winter. Same questions: how many of you think you would be able to survive for a few days? That\\'s quite a lot. How about a few weeks? So for a fun twist, let us imagine that the only source of water available is trapped as frozen blocks miles below the surface. Soil nutrients are so minimal that no vegetation can be found, and of course hardly any atmosphere exists to speak of.\\nSuch examples are only a few of the many challenges we would face on a planet like Mars. So how do we steel ourselves for voyages whose destinations are so far removed from a tropical vacation? Will we continuously ship supplies from Planet Earth? Build space elevators, or impossible miles of transport belts that tether your planet of choice to our home planet? And how do we grow things like food that grew up on Earth like us?\\nBut I\\'m getting ahead of myself. In our species\\' journey to find a new home under a new sun, we are more likely than not going to be spending much time in the journey itself, in space, on a ship, a hermetic flying can, possibly for many generations.\\nThe longest continuous amount of time that any human has spent in space is in the vicinity of 12 to 14 months. From astronauts\\' experiences in space, we know that spending time in a microgravity environment means bone loss, muscle atrophy, cardiovascular problems, among many other complications that range for the physiological to the psychological. And what about macrogravity, or any other variation in gravitational pull of the planet that we find ourselves on?\\nIn short, our cosmic voyages will be fraught with dangers both known and unknown. So far we\\'ve been looking to this new piece of mechanical technology or that great next generation robot as part of a lineup to ensure our species safe passage in space. Wonderful as they are, I believe the time has come for us to complement these bulky electronic giants with what nature has already invented: the microbe, a single-celled organism that is itself a self-generating, self-replenishing, living machine. It requires fairly little to maintain, offers much flexibility in design and only asks to be carried in a single plastic tube.\\nThe field of study that has enabled us to utilize the capabilities of the microbe is known as synthetic biology. It comes from molecular biology, which has given us antibiotics, vaccines and better ways to observe the physiological nuances of the human body. Using the tools of synthetic biology, we can now edit the genes of nearly any organism, microscopic or not, with incredible speed and fidelity. Given the limitations of our man-made machines, synthetic biology will be a means for us to engineer not only our food, our fuel and our environment, but also ourselves to compensate for our physical inadequacies and to ensure our survival in space.\\nTo give you an example of how we can use synthetic biology for space exploration, let us return to the Mars environment. The Martian soil composition is similar to that of Hawaiian volcanic ash, with trace amounts of organic material. Let\\'s say, hypothetically, what if martian soil could actually support plant growth without using Earth-derived nutrients? The first question we should probably ask is, how would we make our plants cold-tolerant? Because, on average, the temperature on Mars is a very uninviting negative 60 degrees centigrade. The next question we should ask is, how do we make our plants drought-tolerant? Considering that most of the water that forms as frost evaporates more quickly than I can say the word \"evaporate.\" Well, it turns out we\\'ve already done things like this. By borrowing genes for anti-freeze protein from fish and genes for drought tolerance from other plants like rice and then stitching them into the plants that need them, we now have plants that can tolerate most droughts and freezes. They\\'re known on Earth as GMOs, or genetically modified organisms, and we rely on them to feed all the mouths of human civilization. Nature does stuff like this already, without our help. We have simply found more precise ways to do it.\\nSo why would we want to change the genetic makeup of plants for space? Well, to not do so would mean needing to engineer endless acres of land on an entirely new planet by releasing trillions of gallons of atmospheric gasses and then constructing a giant glass dome to contain it all. It\\'s an unrealistic engineering enterprise that quickly becomes a high-cost cargo transport mission. One of the best ways to ensure that we will have the food supplies and the air that we need is to bring with us organisms that have been engineered to adapt to new and harsh environments. In essence, using engineered organisms to help us terraform a planet both in the short and long term. These organisms can then also be engineered to make medicine or fuel.\\nSo we can use synthetic biology to bring highly engineered plants with us, but what else can we do? Well, I mentioned earlier that we, as a species, were evolved uniquely for planet Earth. That fact has not changed much in the last five minutes that you were sitting here and I was standing there. And so, if we were to dump any of us on Mars right this minute, even given ample food, water, air and a suit, we are likely to experience very unpleasant health problems from the amount of ionizing radiation that bombards the surface of planets like Mars that have little or nonexistent atmosphere. Unless we plan to stay holed up underground for the duration of our stay on every new planet, we must find better ways of protecting ourselves without needing to resort to wearing a suit of armor that weighs something equal to your own body weight, or needing to hide behind a wall of lead.\\nSo let us appeal to nature for inspiration. Among the plethora of life here on Earth, there\\'s a subset of organisms known as extremophiles, or lovers of extreme living conditions, if you\\'ll remember from high school biology. And among these organisms is a bacterium by the name of Deinococcus radiodurans. It is known to be able to withstand cold, dehydration, vacuum, acid, and, most notably, radiation. While its radiation tolerance mechanisms are known, we have yet to adapt the relevant genes to mammals. To do so is not particularly easy. There are many facets that go into its radiation tolerance, and it\\'s not as simple as transferring one gene. But given a little bit of human ingenuity and a little bit of time, I think to do so is not very hard either. Even if we borrow just a fraction of its ability to tolerate radiation, it would be infinitely better than what we already have, which is just the melanin in our skin. Using the tools of synthetic biology, we can harness Deinococcus radiodurans\\' ability to thrive under otherwise very lethal doses of radiation. As difficult as it is to see, homo sapiens, that is humans, evolves every day, and still continues to evolve. Thousands of years of human evolution has not only given us humans like Tibetans, who can thrive in low-oxygen conditions, but also Argentinians, who can ingest and metabolize arsenic, the chemical element that can kill the average human being. Every day, the human body evolves by accidental mutations that equally accidentally allow certain humans to persevere in dismal situations.\\nBut, and this is a big but, such evolution requires two things that we may not always have, or be able to afford, and they are death and time. In our species\\' struggle to find our place in the universe, we may not always have the time necessary for the natural evolution of extra functions for survival on non-Earth planets. We\\'re living in what E.O. Wilson has termed the age of gene circumvention, during which we remedy our genetic defects like cystic fibrosis or muscular dystrophy with temporary external supplements. But with every passing day, we approach the age of volitional evolution, a time during which we as a species will have the capacity to decide for ourselves our own genetic destiny. Augmenting the human body with new abilities is no longer a question of how, but of when.\\nUsing synthetic biology to change the genetic makeup of any living organisms, especially our own, is not without its moral and ethical quandaries. Will engineering ourselves make us less human? But then again, what is humanity but star stuff that happens to be conscious? Where should human genius direct itself? Surely it is a bit of a waste to sit back and marvel at it. How do we use our knowledge to protect ourselves from the external dangers and then protect ourselves from ourselves?\\nI pose these questions not to engender the fear of science but to bring to light the many possibilities that science has afforded and continues to afford us. We must coalesce as humans to discuss and embrace the solutions not only with caution but also with courage.\\nMars is a destination, but it will not be our last. Our true final frontier is the line we must cross in deciding what we can and should make of our species\\' improbable intelligence.\\nSpace is cold, brutal and unforgiving. Our path to the stars will be rife with trials that will bring us to question not only who we are but where we will be going. The answers will lie in our choice to use or abandon the technology that we have gleaned from life itself, and it will define us for the remainder of our term in this universe.\\nThank you.\\n(Applause)']\n"
     ]
    }
   ],
   "source": [
    "print(doc_list[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2085\n"
     ]
    }
   ],
   "source": [
    "print(len(doc_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['talks, business, creativity, curiosity, goal-setting, innovation, motivation, potential, success, work', 'talks, Planets, TEDx, bacteria, biology, engineering, environment, evolution, exploration, future, innovation, intelligence, microbiology, nature, potential, science']\n"
     ]
    }
   ],
   "source": [
    "print(label_list[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2085\n"
     ]
    }
   ],
   "source": [
    "print(len(label_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ooo': 0, 'Too': 1, 'oEo': 2, 'ooD': 3, 'TEo': 4, 'ToD': 5, 'oED': 6, 'TED': 7}\n"
     ]
    }
   ],
   "source": [
    "labels = ['ooo', 'Too', 'oEo', 'ooD', 'TEo', 'ToD', 'oED', 'TED']\n",
    "label_dict = {labels[i]: i for i in range(8)}\n",
    "print(label_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(keywords):\n",
    "    label_string = keywords.lower()\n",
    "    if (\"technology\" in label_string) and (\"entertainment\" in label_string) and (\"design\" in label_string):\n",
    "        return label_dict['TED']\n",
    "    elif (\"entertainment\" in label_string) and (\"design\" in label_string):\n",
    "        return label_dict['oED']\n",
    "    elif (\"technology\" in label_string) and (\"design\" in label_string):\n",
    "        return label_dict['ToD']\n",
    "    elif (\"technology\" in label_string) and (\"entertainment\" in label_string):\n",
    "        return label_dict['TEo']\n",
    "    elif (\"design\" in label_string):\n",
    "        return label_dict['ooD']\n",
    "    elif (\"entertainment\" in label_string):\n",
    "        return label_dict['oEo']\n",
    "    elif (\"technology\" in label_string):\n",
    "        return label_dict['Too']\n",
    "    else:\n",
    "        return label_dict['ooo']\n",
    "   \n",
    "# for keywords in label_list[:10]:\n",
    "#     print(keywords)\n",
    "label_list_temp = [get_label(keywords) for keywords in label_list]        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2085\n",
      "[0, 0, 0, 3, 5, 0, 0, 0, 0, 5]\n"
     ]
    }
   ],
   "source": [
    "print(len(label_list_temp))\n",
    "print(label_list_temp[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labelled_doc = list(zip(doc_list, label_list_temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('So there are lands few and far between on Earth itself that are hospitable to humans by any measure, but survive we have. Our primitive ancestors, when they found their homes and livelihood endangered, they dared to make their way into unfamiliar territories in search of better opportunities. And as the descendants of these explorers, we have their nomadic blood coursing through our own veins. But at the same time, distracted by our bread and circuses and embroiled in the wars that we have waged on each other, it seems that we have forgotten this desire to explore. We, as a species, we\\'re evolved uniquely for Earth, on Earth, and by Earth, and so content are we with our living conditions that we have grown complacent and just too busy to notice that its resources are finite, and that our Sun\\'s life is also finite. While Mars and all the movies made in its name have reinvigorated the ethos for space travel, few of us seem to truly realize that our species\\' fragile constitution is woefully unprepared for long duration journeys into space.\\nLet us take a trek to your local national forest for a quick reality check. So just a quick show of hands here: how many of you think you would be able to survive in this lush wilderness for a few days? Well, that\\'s a lot of you. How about a few weeks? That\\'s a decent amount. How about a few months? That\\'s pretty good too. Now, let us imagine that this local national forest experiences an eternal winter. Same questions: how many of you think you would be able to survive for a few days? That\\'s quite a lot. How about a few weeks? So for a fun twist, let us imagine that the only source of water available is trapped as frozen blocks miles below the surface. Soil nutrients are so minimal that no vegetation can be found, and of course hardly any atmosphere exists to speak of.\\nSuch examples are only a few of the many challenges we would face on a planet like Mars. So how do we steel ourselves for voyages whose destinations are so far removed from a tropical vacation? Will we continuously ship supplies from Planet Earth? Build space elevators, or impossible miles of transport belts that tether your planet of choice to our home planet? And how do we grow things like food that grew up on Earth like us?\\nBut I\\'m getting ahead of myself. In our species\\' journey to find a new home under a new sun, we are more likely than not going to be spending much time in the journey itself, in space, on a ship, a hermetic flying can, possibly for many generations.\\nThe longest continuous amount of time that any human has spent in space is in the vicinity of 12 to 14 months. From astronauts\\' experiences in space, we know that spending time in a microgravity environment means bone loss, muscle atrophy, cardiovascular problems, among many other complications that range for the physiological to the psychological. And what about macrogravity, or any other variation in gravitational pull of the planet that we find ourselves on?\\nIn short, our cosmic voyages will be fraught with dangers both known and unknown. So far we\\'ve been looking to this new piece of mechanical technology or that great next generation robot as part of a lineup to ensure our species safe passage in space. Wonderful as they are, I believe the time has come for us to complement these bulky electronic giants with what nature has already invented: the microbe, a single-celled organism that is itself a self-generating, self-replenishing, living machine. It requires fairly little to maintain, offers much flexibility in design and only asks to be carried in a single plastic tube.\\nThe field of study that has enabled us to utilize the capabilities of the microbe is known as synthetic biology. It comes from molecular biology, which has given us antibiotics, vaccines and better ways to observe the physiological nuances of the human body. Using the tools of synthetic biology, we can now edit the genes of nearly any organism, microscopic or not, with incredible speed and fidelity. Given the limitations of our man-made machines, synthetic biology will be a means for us to engineer not only our food, our fuel and our environment, but also ourselves to compensate for our physical inadequacies and to ensure our survival in space.\\nTo give you an example of how we can use synthetic biology for space exploration, let us return to the Mars environment. The Martian soil composition is similar to that of Hawaiian volcanic ash, with trace amounts of organic material. Let\\'s say, hypothetically, what if martian soil could actually support plant growth without using Earth-derived nutrients? The first question we should probably ask is, how would we make our plants cold-tolerant? Because, on average, the temperature on Mars is a very uninviting negative 60 degrees centigrade. The next question we should ask is, how do we make our plants drought-tolerant? Considering that most of the water that forms as frost evaporates more quickly than I can say the word \"evaporate.\" Well, it turns out we\\'ve already done things like this. By borrowing genes for anti-freeze protein from fish and genes for drought tolerance from other plants like rice and then stitching them into the plants that need them, we now have plants that can tolerate most droughts and freezes. They\\'re known on Earth as GMOs, or genetically modified organisms, and we rely on them to feed all the mouths of human civilization. Nature does stuff like this already, without our help. We have simply found more precise ways to do it.\\nSo why would we want to change the genetic makeup of plants for space? Well, to not do so would mean needing to engineer endless acres of land on an entirely new planet by releasing trillions of gallons of atmospheric gasses and then constructing a giant glass dome to contain it all. It\\'s an unrealistic engineering enterprise that quickly becomes a high-cost cargo transport mission. One of the best ways to ensure that we will have the food supplies and the air that we need is to bring with us organisms that have been engineered to adapt to new and harsh environments. In essence, using engineered organisms to help us terraform a planet both in the short and long term. These organisms can then also be engineered to make medicine or fuel.\\nSo we can use synthetic biology to bring highly engineered plants with us, but what else can we do? Well, I mentioned earlier that we, as a species, were evolved uniquely for planet Earth. That fact has not changed much in the last five minutes that you were sitting here and I was standing there. And so, if we were to dump any of us on Mars right this minute, even given ample food, water, air and a suit, we are likely to experience very unpleasant health problems from the amount of ionizing radiation that bombards the surface of planets like Mars that have little or nonexistent atmosphere. Unless we plan to stay holed up underground for the duration of our stay on every new planet, we must find better ways of protecting ourselves without needing to resort to wearing a suit of armor that weighs something equal to your own body weight, or needing to hide behind a wall of lead.\\nSo let us appeal to nature for inspiration. Among the plethora of life here on Earth, there\\'s a subset of organisms known as extremophiles, or lovers of extreme living conditions, if you\\'ll remember from high school biology. And among these organisms is a bacterium by the name of Deinococcus radiodurans. It is known to be able to withstand cold, dehydration, vacuum, acid, and, most notably, radiation. While its radiation tolerance mechanisms are known, we have yet to adapt the relevant genes to mammals. To do so is not particularly easy. There are many facets that go into its radiation tolerance, and it\\'s not as simple as transferring one gene. But given a little bit of human ingenuity and a little bit of time, I think to do so is not very hard either. Even if we borrow just a fraction of its ability to tolerate radiation, it would be infinitely better than what we already have, which is just the melanin in our skin. Using the tools of synthetic biology, we can harness Deinococcus radiodurans\\' ability to thrive under otherwise very lethal doses of radiation. As difficult as it is to see, homo sapiens, that is humans, evolves every day, and still continues to evolve. Thousands of years of human evolution has not only given us humans like Tibetans, who can thrive in low-oxygen conditions, but also Argentinians, who can ingest and metabolize arsenic, the chemical element that can kill the average human being. Every day, the human body evolves by accidental mutations that equally accidentally allow certain humans to persevere in dismal situations.\\nBut, and this is a big but, such evolution requires two things that we may not always have, or be able to afford, and they are death and time. In our species\\' struggle to find our place in the universe, we may not always have the time necessary for the natural evolution of extra functions for survival on non-Earth planets. We\\'re living in what E.O. Wilson has termed the age of gene circumvention, during which we remedy our genetic defects like cystic fibrosis or muscular dystrophy with temporary external supplements. But with every passing day, we approach the age of volitional evolution, a time during which we as a species will have the capacity to decide for ourselves our own genetic destiny. Augmenting the human body with new abilities is no longer a question of how, but of when.\\nUsing synthetic biology to change the genetic makeup of any living organisms, especially our own, is not without its moral and ethical quandaries. Will engineering ourselves make us less human? But then again, what is humanity but star stuff that happens to be conscious? Where should human genius direct itself? Surely it is a bit of a waste to sit back and marvel at it. How do we use our knowledge to protect ourselves from the external dangers and then protect ourselves from ourselves?\\nI pose these questions not to engender the fear of science but to bring to light the many possibilities that science has afforded and continues to afford us. We must coalesce as humans to discuss and embrace the solutions not only with caution but also with courage.\\nMars is a destination, but it will not be our last. Our true final frontier is the line we must cross in deciding what we can and should make of our species\\' improbable intelligence.\\nSpace is cold, brutal and unforgiving. Our path to the stars will be rife with trials that will bring us to question not only who we are but where we will be going. The answers will lie in our choice to use or abandon the technology that we have gleaned from life itself, and it will define us for the remainder of our term in this universe.\\nThank you.\\n(Applause)', 0)\n"
     ]
    }
   ],
   "source": [
    "print(labelled_doc[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2085\n"
     ]
    }
   ],
   "source": [
    "print(len(labelled_doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1585\n",
      "250\n",
      "250\n"
     ]
    }
   ],
   "source": [
    "train_doc_temp = labelled_doc[:1585]\n",
    "valid_doc_temp = labelled_doc[-500:-250]\n",
    "test_doc_temp = labelled_doc[-250:]\n",
    "\n",
    "print(len(train_doc_temp))\n",
    "print(len(valid_doc_temp))\n",
    "print(len(test_doc_temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Here are two reasons companies fail: they only do more of the same, or they only do what\\'s new.\\nTo me the real, real solution to quality growth is figuring out the balance between two activities: exploration and exploitation. Both are necessary, but it can be too much of a good thing.\\nConsider Facit. I\\'m actually old enough to remember them. Facit was a fantastic company. They were born deep in the Swedish forest, and they made the best mechanical calculators in the world. Everybody used them. And what did Facit do when the electronic calculator came along? They continued doing exactly the same. In six months, they went from maximum revenue ... and they were gone. Gone.\\nTo me, the irony about the Facit story is hearing about the Facit engineers, who had bought cheap, small electronic calculators in Japan that they used to double-check their calculators.\\n(Laughter)\\nFacit did too much exploitation. But exploration can go wild, too.\\nA few years back, I worked closely alongside a European biotech company. Let\\'s call them OncoSearch. The company was brilliant. They had applications that promised to diagnose, even cure, certain forms of blood cancer. Every day was about creating something new. They were extremely innovative, and the mantra was, \"When we only get it right,\" or even, \"We want it perfect.\" The sad thing is, before they became perfect -- even good enough -- they became obsolete. OncoSearch did too much exploration.\\nI first heard about exploration and exploitation about 15 years ago, when I worked as a visiting scholar at Stanford University. The founder of the idea is Jim March. And to me the power of the idea is its practicality.\\nExploration. Exploration is about coming up with what\\'s new. It\\'s about search, it\\'s about discovery, it\\'s about new products, it\\'s about new innovations. It\\'s about changing our frontiers. Our heroes are people who have done exploration: Madame Curie, Picasso, Neil Armstrong, Sir Edmund Hillary, etc. I come from Norway; all our heroes are explorers, and they deserve to be. We all know that exploration is risky. We don\\'t know the answers, we don\\'t know if we\\'re going to find them, and we know that the risks are high.\\nExploitation is the opposite. Exploitation is taking the knowledge we have and making good, better. Exploitation is about making our trains run on time. It\\'s about making good products faster and cheaper. Exploitation is not risky -- in the short term. But if we only exploit, it\\'s very risky in the long term. And I think we all have memories of the famous pop groups who keep singing the same songs again and again, until they become obsolete or even pathetic. That\\'s the risk of exploitation.\\nSo if we take a long-term perspective, we explore. If we take a short-term perspective, we exploit. Small children, they explore all day. All day it\\'s about exploration. As we grow older, we explore less because we have more knowledge to exploit on. The same goes for companies. Companies become, by nature, less innovative as they become more competent.\\nAnd this is, of course, a big worry to CEOs. And I hear very often questions phrased in different ways. For example, \"How can I both effectively run and reinvent my company?\" Or, \"How can I make sure that our company changes before we become obsolete or are hit by a crisis?\" So, doing one well is difficult. Doing both well as the same time is art -- pushing both exploration and exploitation.\\nSo one thing we\\'ve found is only about two percent of companies are able to effectively explore and exploit at the same time, in parallel. But when they do, the payoffs are huge. So we have lots of great examples. We have Nestlé creating Nespresso, we have Lego going into animated films, Toyota creating the hybrids, Unilever pushing into sustainability -- there are lots of examples, and the benefits are huge.\\nWhy is balancing so difficult? I think it\\'s difficult because there are so many traps that keep us where we are. So I\\'ll talk about two, but there are many.\\nSo let\\'s talk about the perpetual search trap. We discover something, but we don\\'t have the patience or the persistence to get at it and make it work. So instead of staying with it, we create something new. But the same goes for that, then we\\'re in the vicious circle of actually coming up with ideas but being frustrated. OncoSearch was a good example. A famous example is, of course, Xerox. But we don\\'t only see this in companies. We see this in the public sector as well. We all know that any kind of effective reform of education, research, health care, even defense, takes 10, 15, maybe 20 years to work. But still, we change much more often. We really don\\'t give them the chance.\\nAnother trap is the success trap. Facit fell into the success trap. They literally held the future in their hands, but they couldn\\'t see it. They were simply so good at making what they loved doing, that they wouldn\\'t change. We are like that, too. When we know something well, it\\'s difficult to change. Bill Gates has said: \"Success is a lousy teacher. It seduces us into thinking we cannot fail.\" That\\'s the challenge with success.\\nSo I think there are some lessons, and I think they apply to us. And they apply to our companies. The first lesson is: get ahead of the crisis. And any company that\\'s able to innovate is actually able to also buy an insurance in the future. Netflix -- they could so easily have been content with earlier generations of distribution, but they always -- and I think they will always -- keep pushing for the next battle. I see other companies that say, \"I\\'ll win the next innovation cycle, whatever it takes.\"\\nSecond one: think in multiple time scales. I\\'ll share a chart with you, and I think it\\'s a wonderful one. Any company we look at, taking a one-year perspective and looking at the valuation of the company, innovation typically accounts for only about 30 percent. So when we think one year, innovation isn\\'t really that important. Move ahead, take a 10-year perspective on the same company -- suddenly, innovation and ability to renew account for 70 percent. But companies can\\'t choose. They need to fund the journey and lead the long term.\\nThird: invite talent. I don\\'t think it\\'s possible for any of us to be able to balance exploration and exploitation by ourselves. I think it\\'s a team sport. I think we need to allow challenging. I think the mark of a great company is being open to be challenged, and the mark of a good corporate board is to constructively challenge. I think that\\'s also what good parenting is about.\\nLast one: be skeptical of success. Maybe it\\'s useful to think back at the old triumph marches in Rome, when the generals, after a big victory, were given their celebration. Riding into Rome on the carriage, they always had a companion whispering in their ear, \"Remember, you\\'re only human.\"\\nSo I hope I made the point: balancing exploration and exploitation has a huge payoff. But it\\'s difficult, and we need to be conscious.\\nI want to just point out two questions that I think are useful. First question is, looking at your own company: In which areas do you see that the company is at the risk of falling into success traps, of just going on autopilot? And what can you do to challenge?\\nSecond question is: When did I explore something new last, and what kind of effect did it have on me? Is that something I should do more of? In my case, yes.\\nSo let me leave you with this. Whether you\\'re an explorer by nature or whether you tend to exploit what you already know, don\\'t forget: the beauty is in the balance.\\nThank you.\\n(Applause)', 0)\n"
     ]
    }
   ],
   "source": [
    "print(train_doc_temp[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tokenize_and_lowercase(text):\n",
    "    text_noparens = re.sub(r'\\([^)]*\\)', '', text)\n",
    "    sentences_strings = []\n",
    "    for line in text_noparens.split('\\n'):\n",
    "        m = re.match(r'^(?:(?P<precolon>[^:]{,20}):)?(?P<postcolon>.*)$', line)\n",
    "        sentences_strings.extend(sent for sent in m.groupdict()['postcolon'].split('.') if sent)\n",
    "        \n",
    "    sentences= []\n",
    "    for sent_str in sentences_strings:\n",
    "        tokens = re.sub(r\"[^a-z0-9]+\", \" \", sent_str.lower()).split()\n",
    "        sentences.append(tokens)\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_doc = [(tokenize_and_lowercase(doc_temp[0]), doc_temp[1]) for doc_temp in train_doc_temp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1585\n"
     ]
    }
   ],
   "source": [
    "print(len(train_doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([['here', 'are', 'two', 'reasons', 'companies', 'fail', 'they', 'only', 'do', 'more', 'of', 'the', 'same', 'or', 'they', 'only', 'do', 'what', 's', 'new'], ['to', 'me', 'the', 'real', 'real', 'solution', 'to', 'quality', 'growth', 'is', 'figuring', 'out', 'the', 'balance', 'between', 'two', 'activities', 'exploration', 'and', 'exploitation'], ['both', 'are', 'necessary', 'but', 'it', 'can', 'be', 'too', 'much', 'of', 'a', 'good', 'thing'], ['consider', 'facit'], ['i', 'm', 'actually', 'old', 'enough', 'to', 'remember', 'them'], ['facit', 'was', 'a', 'fantastic', 'company'], ['they', 'were', 'born', 'deep', 'in', 'the', 'swedish', 'forest', 'and', 'they', 'made', 'the', 'best', 'mechanical', 'calculators', 'in', 'the', 'world'], ['everybody', 'used', 'them'], ['and', 'what', 'did', 'facit', 'do', 'when', 'the', 'electronic', 'calculator', 'came', 'along', 'they', 'continued', 'doing', 'exactly', 'the', 'same'], ['in', 'six', 'months', 'they', 'went', 'from', 'maximum', 'revenue'], ['and', 'they', 'were', 'gone'], ['gone'], ['to', 'me', 'the', 'irony', 'about', 'the', 'facit', 'story', 'is', 'hearing', 'about', 'the', 'facit', 'engineers', 'who', 'had', 'bought', 'cheap', 'small', 'electronic', 'calculators', 'in', 'japan', 'that', 'they', 'used', 'to', 'double', 'check', 'their', 'calculators'], ['facit', 'did', 'too', 'much', 'exploitation'], ['but', 'exploration', 'can', 'go', 'wild', 'too'], ['a', 'few', 'years', 'back', 'i', 'worked', 'closely', 'alongside', 'a', 'european', 'biotech', 'company'], ['let', 's', 'call', 'them', 'oncosearch'], ['the', 'company', 'was', 'brilliant'], ['they', 'had', 'applications', 'that', 'promised', 'to', 'diagnose', 'even', 'cure', 'certain', 'forms', 'of', 'blood', 'cancer'], ['every', 'day', 'was', 'about', 'creating', 'something', 'new'], ['they', 'were', 'extremely', 'innovative', 'and', 'the', 'mantra', 'was', 'when', 'we', 'only', 'get', 'it', 'right', 'or', 'even', 'we', 'want', 'it', 'perfect'], ['the', 'sad', 'thing', 'is', 'before', 'they', 'became', 'perfect', 'even', 'good', 'enough', 'they', 'became', 'obsolete'], ['oncosearch', 'did', 'too', 'much', 'exploration'], ['i', 'first', 'heard', 'about', 'exploration', 'and', 'exploitation', 'about', '15', 'years', 'ago', 'when', 'i', 'worked', 'as', 'a', 'visiting', 'scholar', 'at', 'stanford', 'university'], ['the', 'founder', 'of', 'the', 'idea', 'is', 'jim', 'march'], ['and', 'to', 'me', 'the', 'power', 'of', 'the', 'idea', 'is', 'its', 'practicality'], ['exploration'], ['exploration', 'is', 'about', 'coming', 'up', 'with', 'what', 's', 'new'], ['it', 's', 'about', 'search', 'it', 's', 'about', 'discovery', 'it', 's', 'about', 'new', 'products', 'it', 's', 'about', 'new', 'innovations'], ['it', 's', 'about', 'changing', 'our', 'frontiers'], ['our', 'heroes', 'are', 'people', 'who', 'have', 'done', 'exploration', 'madame', 'curie', 'picasso', 'neil', 'armstrong', 'sir', 'edmund', 'hillary', 'etc'], ['i', 'come', 'from', 'norway', 'all', 'our', 'heroes', 'are', 'explorers', 'and', 'they', 'deserve', 'to', 'be'], ['we', 'all', 'know', 'that', 'exploration', 'is', 'risky'], ['we', 'don', 't', 'know', 'the', 'answers', 'we', 'don', 't', 'know', 'if', 'we', 're', 'going', 'to', 'find', 'them', 'and', 'we', 'know', 'that', 'the', 'risks', 'are', 'high'], ['exploitation', 'is', 'the', 'opposite'], ['exploitation', 'is', 'taking', 'the', 'knowledge', 'we', 'have', 'and', 'making', 'good', 'better'], ['exploitation', 'is', 'about', 'making', 'our', 'trains', 'run', 'on', 'time'], ['it', 's', 'about', 'making', 'good', 'products', 'faster', 'and', 'cheaper'], ['exploitation', 'is', 'not', 'risky', 'in', 'the', 'short', 'term'], ['but', 'if', 'we', 'only', 'exploit', 'it', 's', 'very', 'risky', 'in', 'the', 'long', 'term'], ['and', 'i', 'think', 'we', 'all', 'have', 'memories', 'of', 'the', 'famous', 'pop', 'groups', 'who', 'keep', 'singing', 'the', 'same', 'songs', 'again', 'and', 'again', 'until', 'they', 'become', 'obsolete', 'or', 'even', 'pathetic'], ['that', 's', 'the', 'risk', 'of', 'exploitation'], ['so', 'if', 'we', 'take', 'a', 'long', 'term', 'perspective', 'we', 'explore'], ['if', 'we', 'take', 'a', 'short', 'term', 'perspective', 'we', 'exploit'], ['small', 'children', 'they', 'explore', 'all', 'day'], ['all', 'day', 'it', 's', 'about', 'exploration'], ['as', 'we', 'grow', 'older', 'we', 'explore', 'less', 'because', 'we', 'have', 'more', 'knowledge', 'to', 'exploit', 'on'], ['the', 'same', 'goes', 'for', 'companies'], ['companies', 'become', 'by', 'nature', 'less', 'innovative', 'as', 'they', 'become', 'more', 'competent'], ['and', 'this', 'is', 'of', 'course', 'a', 'big', 'worry', 'to', 'ceos'], ['and', 'i', 'hear', 'very', 'often', 'questions', 'phrased', 'in', 'different', 'ways'], ['for', 'example', 'how', 'can', 'i', 'both', 'effectively', 'run', 'and', 'reinvent', 'my', 'company', 'or', 'how', 'can', 'i', 'make', 'sure', 'that', 'our', 'company', 'changes', 'before', 'we', 'become', 'obsolete', 'or', 'are', 'hit', 'by', 'a', 'crisis', 'so', 'doing', 'one', 'well', 'is', 'difficult'], ['doing', 'both', 'well', 'as', 'the', 'same', 'time', 'is', 'art', 'pushing', 'both', 'exploration', 'and', 'exploitation'], ['so', 'one', 'thing', 'we', 've', 'found', 'is', 'only', 'about', 'two', 'percent', 'of', 'companies', 'are', 'able', 'to', 'effectively', 'explore', 'and', 'exploit', 'at', 'the', 'same', 'time', 'in', 'parallel'], ['but', 'when', 'they', 'do', 'the', 'payoffs', 'are', 'huge'], ['so', 'we', 'have', 'lots', 'of', 'great', 'examples'], ['we', 'have', 'nestl', 'creating', 'nespresso', 'we', 'have', 'lego', 'going', 'into', 'animated', 'films', 'toyota', 'creating', 'the', 'hybrids', 'unilever', 'pushing', 'into', 'sustainability', 'there', 'are', 'lots', 'of', 'examples', 'and', 'the', 'benefits', 'are', 'huge'], ['why', 'is', 'balancing', 'so', 'difficult', 'i', 'think', 'it', 's', 'difficult', 'because', 'there', 'are', 'so', 'many', 'traps', 'that', 'keep', 'us', 'where', 'we', 'are'], ['so', 'i', 'll', 'talk', 'about', 'two', 'but', 'there', 'are', 'many'], ['so', 'let', 's', 'talk', 'about', 'the', 'perpetual', 'search', 'trap'], ['we', 'discover', 'something', 'but', 'we', 'don', 't', 'have', 'the', 'patience', 'or', 'the', 'persistence', 'to', 'get', 'at', 'it', 'and', 'make', 'it', 'work'], ['so', 'instead', 'of', 'staying', 'with', 'it', 'we', 'create', 'something', 'new'], ['but', 'the', 'same', 'goes', 'for', 'that', 'then', 'we', 're', 'in', 'the', 'vicious', 'circle', 'of', 'actually', 'coming', 'up', 'with', 'ideas', 'but', 'being', 'frustrated'], ['oncosearch', 'was', 'a', 'good', 'example'], ['a', 'famous', 'example', 'is', 'of', 'course', 'xerox'], ['but', 'we', 'don', 't', 'only', 'see', 'this', 'in', 'companies'], ['we', 'see', 'this', 'in', 'the', 'public', 'sector', 'as', 'well'], ['we', 'all', 'know', 'that', 'any', 'kind', 'of', 'effective', 'reform', 'of', 'education', 'research', 'health', 'care', 'even', 'defense', 'takes', '10', '15', 'maybe', '20', 'years', 'to', 'work'], ['but', 'still', 'we', 'change', 'much', 'more', 'often'], ['we', 'really', 'don', 't', 'give', 'them', 'the', 'chance'], ['another', 'trap', 'is', 'the', 'success', 'trap'], ['facit', 'fell', 'into', 'the', 'success', 'trap'], ['they', 'literally', 'held', 'the', 'future', 'in', 'their', 'hands', 'but', 'they', 'couldn', 't', 'see', 'it'], ['they', 'were', 'simply', 'so', 'good', 'at', 'making', 'what', 'they', 'loved', 'doing', 'that', 'they', 'wouldn', 't', 'change'], ['we', 'are', 'like', 'that', 'too'], ['when', 'we', 'know', 'something', 'well', 'it', 's', 'difficult', 'to', 'change'], ['bill', 'gates', 'has', 'said', 'success', 'is', 'a', 'lousy', 'teacher'], ['it', 'seduces', 'us', 'into', 'thinking', 'we', 'cannot', 'fail'], ['that', 's', 'the', 'challenge', 'with', 'success'], ['so', 'i', 'think', 'there', 'are', 'some', 'lessons', 'and', 'i', 'think', 'they', 'apply', 'to', 'us'], ['and', 'they', 'apply', 'to', 'our', 'companies'], ['the', 'first', 'lesson', 'is', 'get', 'ahead', 'of', 'the', 'crisis'], ['and', 'any', 'company', 'that', 's', 'able', 'to', 'innovate', 'is', 'actually', 'able', 'to', 'also', 'buy', 'an', 'insurance', 'in', 'the', 'future'], ['netflix', 'they', 'could', 'so', 'easily', 'have', 'been', 'content', 'with', 'earlier', 'generations', 'of', 'distribution', 'but', 'they', 'always', 'and', 'i', 'think', 'they', 'will', 'always', 'keep', 'pushing', 'for', 'the', 'next', 'battle'], ['i', 'see', 'other', 'companies', 'that', 'say', 'i', 'll', 'win', 'the', 'next', 'innovation', 'cycle', 'whatever', 'it', 'takes'], [], ['think', 'in', 'multiple', 'time', 'scales'], ['i', 'll', 'share', 'a', 'chart', 'with', 'you', 'and', 'i', 'think', 'it', 's', 'a', 'wonderful', 'one'], ['any', 'company', 'we', 'look', 'at', 'taking', 'a', 'one', 'year', 'perspective', 'and', 'looking', 'at', 'the', 'valuation', 'of', 'the', 'company', 'innovation', 'typically', 'accounts', 'for', 'only', 'about', '30', 'percent'], ['so', 'when', 'we', 'think', 'one', 'year', 'innovation', 'isn', 't', 'really', 'that', 'important'], ['move', 'ahead', 'take', 'a', '10', 'year', 'perspective', 'on', 'the', 'same', 'company', 'suddenly', 'innovation', 'and', 'ability', 'to', 'renew', 'account', 'for', '70', 'percent'], ['but', 'companies', 'can', 't', 'choose'], ['they', 'need', 'to', 'fund', 'the', 'journey', 'and', 'lead', 'the', 'long', 'term'], ['invite', 'talent'], ['i', 'don', 't', 'think', 'it', 's', 'possible', 'for', 'any', 'of', 'us', 'to', 'be', 'able', 'to', 'balance', 'exploration', 'and', 'exploitation', 'by', 'ourselves'], ['i', 'think', 'it', 's', 'a', 'team', 'sport'], ['i', 'think', 'we', 'need', 'to', 'allow', 'challenging'], ['i', 'think', 'the', 'mark', 'of', 'a', 'great', 'company', 'is', 'being', 'open', 'to', 'be', 'challenged', 'and', 'the', 'mark', 'of', 'a', 'good', 'corporate', 'board', 'is', 'to', 'constructively', 'challenge'], ['i', 'think', 'that', 's', 'also', 'what', 'good', 'parenting', 'is', 'about'], ['be', 'skeptical', 'of', 'success'], ['maybe', 'it', 's', 'useful', 'to', 'think', 'back', 'at', 'the', 'old', 'triumph', 'marches', 'in', 'rome', 'when', 'the', 'generals', 'after', 'a', 'big', 'victory', 'were', 'given', 'their', 'celebration'], ['riding', 'into', 'rome', 'on', 'the', 'carriage', 'they', 'always', 'had', 'a', 'companion', 'whispering', 'in', 'their', 'ear', 'remember', 'you', 're', 'only', 'human'], [], ['so', 'i', 'hope', 'i', 'made', 'the', 'point', 'balancing', 'exploration', 'and', 'exploitation', 'has', 'a', 'huge', 'payoff'], ['but', 'it', 's', 'difficult', 'and', 'we', 'need', 'to', 'be', 'conscious'], ['i', 'want', 'to', 'just', 'point', 'out', 'two', 'questions', 'that', 'i', 'think', 'are', 'useful'], ['first', 'question', 'is', 'looking', 'at', 'your', 'own', 'company', 'in', 'which', 'areas', 'do', 'you', 'see', 'that', 'the', 'company', 'is', 'at', 'the', 'risk', 'of', 'falling', 'into', 'success', 'traps', 'of', 'just', 'going', 'on', 'autopilot', 'and', 'what', 'can', 'you', 'do', 'to', 'challenge'], ['when', 'did', 'i', 'explore', 'something', 'new', 'last', 'and', 'what', 'kind', 'of', 'effect', 'did', 'it', 'have', 'on', 'me', 'is', 'that', 'something', 'i', 'should', 'do', 'more', 'of', 'in', 'my', 'case', 'yes'], ['so', 'let', 'me', 'leave', 'you', 'with', 'this'], ['whether', 'you', 're', 'an', 'explorer', 'by', 'nature', 'or', 'whether', 'you', 'tend', 'to', 'exploit', 'what', 'you', 'already', 'know', 'don', 't', 'forget', 'the', 'beauty', 'is', 'in', 'the', 'balance'], ['thank', 'you']], 0) \n",
      "\n",
      "[['here', 'are', 'two', 'reasons', 'companies', 'fail', 'they', 'only', 'do', 'more', 'of', 'the', 'same', 'or', 'they', 'only', 'do', 'what', 's', 'new'], ['to', 'me', 'the', 'real', 'real', 'solution', 'to', 'quality', 'growth', 'is', 'figuring', 'out', 'the', 'balance', 'between', 'two', 'activities', 'exploration', 'and', 'exploitation'], ['both', 'are', 'necessary', 'but', 'it', 'can', 'be', 'too', 'much', 'of', 'a', 'good', 'thing'], ['consider', 'facit'], ['i', 'm', 'actually', 'old', 'enough', 'to', 'remember', 'them'], ['facit', 'was', 'a', 'fantastic', 'company'], ['they', 'were', 'born', 'deep', 'in', 'the', 'swedish', 'forest', 'and', 'they', 'made', 'the', 'best', 'mechanical', 'calculators', 'in', 'the', 'world'], ['everybody', 'used', 'them'], ['and', 'what', 'did', 'facit', 'do', 'when', 'the', 'electronic', 'calculator', 'came', 'along', 'they', 'continued', 'doing', 'exactly', 'the', 'same'], ['in', 'six', 'months', 'they', 'went', 'from', 'maximum', 'revenue'], ['and', 'they', 'were', 'gone'], ['gone'], ['to', 'me', 'the', 'irony', 'about', 'the', 'facit', 'story', 'is', 'hearing', 'about', 'the', 'facit', 'engineers', 'who', 'had', 'bought', 'cheap', 'small', 'electronic', 'calculators', 'in', 'japan', 'that', 'they', 'used', 'to', 'double', 'check', 'their', 'calculators'], ['facit', 'did', 'too', 'much', 'exploitation'], ['but', 'exploration', 'can', 'go', 'wild', 'too'], ['a', 'few', 'years', 'back', 'i', 'worked', 'closely', 'alongside', 'a', 'european', 'biotech', 'company'], ['let', 's', 'call', 'them', 'oncosearch'], ['the', 'company', 'was', 'brilliant'], ['they', 'had', 'applications', 'that', 'promised', 'to', 'diagnose', 'even', 'cure', 'certain', 'forms', 'of', 'blood', 'cancer'], ['every', 'day', 'was', 'about', 'creating', 'something', 'new'], ['they', 'were', 'extremely', 'innovative', 'and', 'the', 'mantra', 'was', 'when', 'we', 'only', 'get', 'it', 'right', 'or', 'even', 'we', 'want', 'it', 'perfect'], ['the', 'sad', 'thing', 'is', 'before', 'they', 'became', 'perfect', 'even', 'good', 'enough', 'they', 'became', 'obsolete'], ['oncosearch', 'did', 'too', 'much', 'exploration'], ['i', 'first', 'heard', 'about', 'exploration', 'and', 'exploitation', 'about', '15', 'years', 'ago', 'when', 'i', 'worked', 'as', 'a', 'visiting', 'scholar', 'at', 'stanford', 'university'], ['the', 'founder', 'of', 'the', 'idea', 'is', 'jim', 'march'], ['and', 'to', 'me', 'the', 'power', 'of', 'the', 'idea', 'is', 'its', 'practicality'], ['exploration'], ['exploration', 'is', 'about', 'coming', 'up', 'with', 'what', 's', 'new'], ['it', 's', 'about', 'search', 'it', 's', 'about', 'discovery', 'it', 's', 'about', 'new', 'products', 'it', 's', 'about', 'new', 'innovations'], ['it', 's', 'about', 'changing', 'our', 'frontiers'], ['our', 'heroes', 'are', 'people', 'who', 'have', 'done', 'exploration', 'madame', 'curie', 'picasso', 'neil', 'armstrong', 'sir', 'edmund', 'hillary', 'etc'], ['i', 'come', 'from', 'norway', 'all', 'our', 'heroes', 'are', 'explorers', 'and', 'they', 'deserve', 'to', 'be'], ['we', 'all', 'know', 'that', 'exploration', 'is', 'risky'], ['we', 'don', 't', 'know', 'the', 'answers', 'we', 'don', 't', 'know', 'if', 'we', 're', 'going', 'to', 'find', 'them', 'and', 'we', 'know', 'that', 'the', 'risks', 'are', 'high'], ['exploitation', 'is', 'the', 'opposite'], ['exploitation', 'is', 'taking', 'the', 'knowledge', 'we', 'have', 'and', 'making', 'good', 'better'], ['exploitation', 'is', 'about', 'making', 'our', 'trains', 'run', 'on', 'time'], ['it', 's', 'about', 'making', 'good', 'products', 'faster', 'and', 'cheaper'], ['exploitation', 'is', 'not', 'risky', 'in', 'the', 'short', 'term'], ['but', 'if', 'we', 'only', 'exploit', 'it', 's', 'very', 'risky', 'in', 'the', 'long', 'term'], ['and', 'i', 'think', 'we', 'all', 'have', 'memories', 'of', 'the', 'famous', 'pop', 'groups', 'who', 'keep', 'singing', 'the', 'same', 'songs', 'again', 'and', 'again', 'until', 'they', 'become', 'obsolete', 'or', 'even', 'pathetic'], ['that', 's', 'the', 'risk', 'of', 'exploitation'], ['so', 'if', 'we', 'take', 'a', 'long', 'term', 'perspective', 'we', 'explore'], ['if', 'we', 'take', 'a', 'short', 'term', 'perspective', 'we', 'exploit'], ['small', 'children', 'they', 'explore', 'all', 'day'], ['all', 'day', 'it', 's', 'about', 'exploration'], ['as', 'we', 'grow', 'older', 'we', 'explore', 'less', 'because', 'we', 'have', 'more', 'knowledge', 'to', 'exploit', 'on'], ['the', 'same', 'goes', 'for', 'companies'], ['companies', 'become', 'by', 'nature', 'less', 'innovative', 'as', 'they', 'become', 'more', 'competent'], ['and', 'this', 'is', 'of', 'course', 'a', 'big', 'worry', 'to', 'ceos'], ['and', 'i', 'hear', 'very', 'often', 'questions', 'phrased', 'in', 'different', 'ways'], ['for', 'example', 'how', 'can', 'i', 'both', 'effectively', 'run', 'and', 'reinvent', 'my', 'company', 'or', 'how', 'can', 'i', 'make', 'sure', 'that', 'our', 'company', 'changes', 'before', 'we', 'become', 'obsolete', 'or', 'are', 'hit', 'by', 'a', 'crisis', 'so', 'doing', 'one', 'well', 'is', 'difficult'], ['doing', 'both', 'well', 'as', 'the', 'same', 'time', 'is', 'art', 'pushing', 'both', 'exploration', 'and', 'exploitation'], ['so', 'one', 'thing', 'we', 've', 'found', 'is', 'only', 'about', 'two', 'percent', 'of', 'companies', 'are', 'able', 'to', 'effectively', 'explore', 'and', 'exploit', 'at', 'the', 'same', 'time', 'in', 'parallel'], ['but', 'when', 'they', 'do', 'the', 'payoffs', 'are', 'huge'], ['so', 'we', 'have', 'lots', 'of', 'great', 'examples'], ['we', 'have', 'nestl', 'creating', 'nespresso', 'we', 'have', 'lego', 'going', 'into', 'animated', 'films', 'toyota', 'creating', 'the', 'hybrids', 'unilever', 'pushing', 'into', 'sustainability', 'there', 'are', 'lots', 'of', 'examples', 'and', 'the', 'benefits', 'are', 'huge'], ['why', 'is', 'balancing', 'so', 'difficult', 'i', 'think', 'it', 's', 'difficult', 'because', 'there', 'are', 'so', 'many', 'traps', 'that', 'keep', 'us', 'where', 'we', 'are'], ['so', 'i', 'll', 'talk', 'about', 'two', 'but', 'there', 'are', 'many'], ['so', 'let', 's', 'talk', 'about', 'the', 'perpetual', 'search', 'trap'], ['we', 'discover', 'something', 'but', 'we', 'don', 't', 'have', 'the', 'patience', 'or', 'the', 'persistence', 'to', 'get', 'at', 'it', 'and', 'make', 'it', 'work'], ['so', 'instead', 'of', 'staying', 'with', 'it', 'we', 'create', 'something', 'new'], ['but', 'the', 'same', 'goes', 'for', 'that', 'then', 'we', 're', 'in', 'the', 'vicious', 'circle', 'of', 'actually', 'coming', 'up', 'with', 'ideas', 'but', 'being', 'frustrated'], ['oncosearch', 'was', 'a', 'good', 'example'], ['a', 'famous', 'example', 'is', 'of', 'course', 'xerox'], ['but', 'we', 'don', 't', 'only', 'see', 'this', 'in', 'companies'], ['we', 'see', 'this', 'in', 'the', 'public', 'sector', 'as', 'well'], ['we', 'all', 'know', 'that', 'any', 'kind', 'of', 'effective', 'reform', 'of', 'education', 'research', 'health', 'care', 'even', 'defense', 'takes', '10', '15', 'maybe', '20', 'years', 'to', 'work'], ['but', 'still', 'we', 'change', 'much', 'more', 'often'], ['we', 'really', 'don', 't', 'give', 'them', 'the', 'chance'], ['another', 'trap', 'is', 'the', 'success', 'trap'], ['facit', 'fell', 'into', 'the', 'success', 'trap'], ['they', 'literally', 'held', 'the', 'future', 'in', 'their', 'hands', 'but', 'they', 'couldn', 't', 'see', 'it'], ['they', 'were', 'simply', 'so', 'good', 'at', 'making', 'what', 'they', 'loved', 'doing', 'that', 'they', 'wouldn', 't', 'change'], ['we', 'are', 'like', 'that', 'too'], ['when', 'we', 'know', 'something', 'well', 'it', 's', 'difficult', 'to', 'change'], ['bill', 'gates', 'has', 'said', 'success', 'is', 'a', 'lousy', 'teacher'], ['it', 'seduces', 'us', 'into', 'thinking', 'we', 'cannot', 'fail'], ['that', 's', 'the', 'challenge', 'with', 'success'], ['so', 'i', 'think', 'there', 'are', 'some', 'lessons', 'and', 'i', 'think', 'they', 'apply', 'to', 'us'], ['and', 'they', 'apply', 'to', 'our', 'companies'], ['the', 'first', 'lesson', 'is', 'get', 'ahead', 'of', 'the', 'crisis'], ['and', 'any', 'company', 'that', 's', 'able', 'to', 'innovate', 'is', 'actually', 'able', 'to', 'also', 'buy', 'an', 'insurance', 'in', 'the', 'future'], ['netflix', 'they', 'could', 'so', 'easily', 'have', 'been', 'content', 'with', 'earlier', 'generations', 'of', 'distribution', 'but', 'they', 'always', 'and', 'i', 'think', 'they', 'will', 'always', 'keep', 'pushing', 'for', 'the', 'next', 'battle'], ['i', 'see', 'other', 'companies', 'that', 'say', 'i', 'll', 'win', 'the', 'next', 'innovation', 'cycle', 'whatever', 'it', 'takes'], [], ['think', 'in', 'multiple', 'time', 'scales'], ['i', 'll', 'share', 'a', 'chart', 'with', 'you', 'and', 'i', 'think', 'it', 's', 'a', 'wonderful', 'one'], ['any', 'company', 'we', 'look', 'at', 'taking', 'a', 'one', 'year', 'perspective', 'and', 'looking', 'at', 'the', 'valuation', 'of', 'the', 'company', 'innovation', 'typically', 'accounts', 'for', 'only', 'about', '30', 'percent'], ['so', 'when', 'we', 'think', 'one', 'year', 'innovation', 'isn', 't', 'really', 'that', 'important'], ['move', 'ahead', 'take', 'a', '10', 'year', 'perspective', 'on', 'the', 'same', 'company', 'suddenly', 'innovation', 'and', 'ability', 'to', 'renew', 'account', 'for', '70', 'percent'], ['but', 'companies', 'can', 't', 'choose'], ['they', 'need', 'to', 'fund', 'the', 'journey', 'and', 'lead', 'the', 'long', 'term'], ['invite', 'talent'], ['i', 'don', 't', 'think', 'it', 's', 'possible', 'for', 'any', 'of', 'us', 'to', 'be', 'able', 'to', 'balance', 'exploration', 'and', 'exploitation', 'by', 'ourselves'], ['i', 'think', 'it', 's', 'a', 'team', 'sport'], ['i', 'think', 'we', 'need', 'to', 'allow', 'challenging'], ['i', 'think', 'the', 'mark', 'of', 'a', 'great', 'company', 'is', 'being', 'open', 'to', 'be', 'challenged', 'and', 'the', 'mark', 'of', 'a', 'good', 'corporate', 'board', 'is', 'to', 'constructively', 'challenge'], ['i', 'think', 'that', 's', 'also', 'what', 'good', 'parenting', 'is', 'about'], ['be', 'skeptical', 'of', 'success'], ['maybe', 'it', 's', 'useful', 'to', 'think', 'back', 'at', 'the', 'old', 'triumph', 'marches', 'in', 'rome', 'when', 'the', 'generals', 'after', 'a', 'big', 'victory', 'were', 'given', 'their', 'celebration'], ['riding', 'into', 'rome', 'on', 'the', 'carriage', 'they', 'always', 'had', 'a', 'companion', 'whispering', 'in', 'their', 'ear', 'remember', 'you', 're', 'only', 'human'], [], ['so', 'i', 'hope', 'i', 'made', 'the', 'point', 'balancing', 'exploration', 'and', 'exploitation', 'has', 'a', 'huge', 'payoff'], ['but', 'it', 's', 'difficult', 'and', 'we', 'need', 'to', 'be', 'conscious'], ['i', 'want', 'to', 'just', 'point', 'out', 'two', 'questions', 'that', 'i', 'think', 'are', 'useful'], ['first', 'question', 'is', 'looking', 'at', 'your', 'own', 'company', 'in', 'which', 'areas', 'do', 'you', 'see', 'that', 'the', 'company', 'is', 'at', 'the', 'risk', 'of', 'falling', 'into', 'success', 'traps', 'of', 'just', 'going', 'on', 'autopilot', 'and', 'what', 'can', 'you', 'do', 'to', 'challenge'], ['when', 'did', 'i', 'explore', 'something', 'new', 'last', 'and', 'what', 'kind', 'of', 'effect', 'did', 'it', 'have', 'on', 'me', 'is', 'that', 'something', 'i', 'should', 'do', 'more', 'of', 'in', 'my', 'case', 'yes'], ['so', 'let', 'me', 'leave', 'you', 'with', 'this'], ['whether', 'you', 're', 'an', 'explorer', 'by', 'nature', 'or', 'whether', 'you', 'tend', 'to', 'exploit', 'what', 'you', 'already', 'know', 'don', 't', 'forget', 'the', 'beauty', 'is', 'in', 'the', 'balance'], ['thank', 'you']] \n",
      "\n",
      "['here', 'are', 'two', 'reasons', 'companies', 'fail', 'they', 'only', 'do', 'more', 'of', 'the', 'same', 'or', 'they', 'only', 'do', 'what', 's', 'new']\n"
     ]
    }
   ],
   "source": [
    "print(train_doc[0], '\\n')\n",
    "print(train_doc[0][0], '\\n')\n",
    "print(train_doc[0][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_text = '\\n'.join([train_doc_temp[i][0] for i in range(len(train_doc_temp))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are two reasons companies fail: they only do more of the same, or they only do what's new.\n",
      "To me the real, real solution to quality growth is figuring out the balance between two activities: exploration and exploitation. Both are necessary, but it can be too much of a good thing.\n",
      "Consider Facit. I'm actually old enough to remember them. Facit was a fantastic company. They were born deep in the Swedish forest, and they made the best mechanical calculators in the world. Everybody used them. And what did Facit do when the electronic calculator came along? They continued doing exactly the same. In six months, they went from maximum revenue ... and they were gone. Gone.\n",
      "To me, the irony about the Facit story is hearing about the Facit engineers, who had bought cheap, small electronic calculators in Japan that they used to double-check their calculators.\n",
      "(Laughter)\n",
      "Facit did too much exploitation. But exploration can go wild, too.\n",
      "A few years back, I worked closely alongside a European biotech company. Let's call them OncoSearch. The company was brilliant. They had applications that promised to diagnose, even cure, certain forms of blood cancer. Every day was about creating something new. They were extremely innovative, and the mantra was, \"When we only get it right,\" or even, \"We want it perfect.\" The sad thing is, before they became perfect -- even good enough -- they became obsolete. OncoSearch did too much exploration.\n",
      "I first heard about exploration and exploitation about 15 years ago, when I worked as a visiting scholar at Stanford University. The founder of the idea is Jim March. And to me the power of the idea is its practicality.\n",
      "Exploration. Exploration is about coming up with what's new. It's about search, it's about discovery, it's about new products, it's about new innovations. It's about changing our frontiers. Our heroes are people who have done exploration: Madame Curie, Picasso, Neil Armstrong, Sir Edmund Hillary, etc. I come from Norway; all our heroes are explorers, and they deserve to be. We all know that exploration is risky. We don't know the answers, we don't know if we're going to find them, and we know that the risks are high.\n",
      "Exploitation is the opposite. Exploitation is taking the knowledge we have and making good, better. Exploitation is about making our trains run on time. It's about making good products faster and cheaper. Exploitation is not risky -- in the short term. But if we only exploit, it's very risky in the long term. And I think we all have memories of the famous pop groups who keep singing the same songs again and again, until they become obsolete or even pathetic. That's the risk of exploitation.\n",
      "So if we take a long-term perspective, we explore. If we take a short-term perspective, we exploit. Small children, they explore all day. All day it's about exploration. As we grow older, we explore less because we have more knowledge to exploit on. The same goes for companies. Companies become, by nature, less innovative as they become more competent.\n",
      "And this is, of course, a big worry to CEOs. And I hear very often questions phrased in different ways. For example, \"How can I both effectively run and reinvent my company?\" Or, \"How can I make sure that our company changes before we become obsolete or are hit by a crisis?\" So, doing one well is difficult. Doing both well as the same time is art -- pushing both exploration and exploitation.\n",
      "So one thing we've found is only about two percent of companies are able to effectively explore and exploit at the same time, in parallel. But when they do, the payoffs are huge. So we have lots of great examples. We have Nestlé creating Nespresso, we have Lego going into animated films, Toyota creating the hybrids, Unilever pushing into sustainability -- there are lots of examples, and the benefits are huge.\n",
      "Why is balancing so difficult? I think it's difficult because there are so many traps that keep us where we are. So I'll talk about two, but there are many.\n",
      "So let's talk about the perpetual search trap. We discover something, but we don't have the patience or the persistence to get at it and make it work. So instead of staying with it, we create something new. But the same goes for that, then we're in the vicious circle of actually coming up with ideas but being frustrated. OncoSearch was a good example. A famous example is, of course, Xerox. But we don't only see this in companies. We see this in the public sector as well. We all know that any kind of effective reform of education, research, health care, even defense, takes 10, 15, maybe 20 years to work. But still, we change much more often. We really don't give them the chance.\n",
      "Another trap is the success trap. Facit fell into the success trap. They literally held the future in their hands, but they couldn't see it. They were simply so good at making what they loved doing, that they wouldn't change. We are like that, too. When we know something well, it's difficult to change. Bill Gates has said: \"Success is a lousy teacher. It seduces us into thinking we cannot fail.\" That's the challenge with success.\n",
      "So I think there are some lessons, and I think they apply to us. And they apply to our companies. The first lesson is: get ahead of the crisis. And any company that's able to innovate is actually able to also buy an insurance in the future. Netflix -- they could so easily have been content with earlier generations of distribution, but they always -- and I think they will always -- keep pushing for the next battle. I see other companies that say, \"I'll win the next innovation cycle, whatever it takes.\"\n",
      "Second one: think in multiple time scales. I'll share a chart with you, and I think it's a wonderful one. Any company we look at, taking a one-year perspective and looking at the valuation of the company, innovation typically accounts for only about 30 percent. So when we think one year, innovation isn't really that important. Move ahead, take a 10-year perspective on the same company -- suddenly, innovation and ability to renew account for 70 percent. But companies can't choose. They need to fund the journey and lead the long term.\n",
      "Third: invite talent. I don't think it's possible for any of us to be able to balance exploration and exploitation by ourselves. I think it's a team sport. I think we need to allow challenging. I think the mark of a great company is being open to be challenged, and the mark of a good corporate board is to constructively challenge. I think that's also what good parenting is about.\n",
      "Last one: be skeptical of success. Maybe it's useful to think back at the old triumph marches in Rome, when the generals, after a big victory, were given their celebration. Riding into Rome on the carriage, they always had a companion whispering in their ear, \"Remember, you're only human.\"\n",
      "So I hope I made the point: balancing exploration and exploitation has a huge payoff. But it's difficult, and we need to be conscious.\n",
      "I want to just point out two questions that I think are useful. First question is, looking at your own company: In which areas do you see that the company is at the risk of falling into success traps, of just going on autopilot? And what can you do to challenge?\n",
      "Second question is: When did I explore something new last, and what kind of effect did it have on me? Is that something I should do more of? In my case, yes.\n",
      "So let me leave you with this. Whether you're an explorer by nature or whether you tend to exploit what you already know, don't forget: the beauty is in the balance.\n",
      "Thank you.\n",
      "(Applause)\n",
      "So there are lands few and far between on Earth itself that are hospitable to humans by any measure, but survive we have. Our primitive ancestors, when they found their homes and livelihood endangered, they dared to make their way into unfamiliar territories in search of better opportunities. And as the descendants of these explorers, we have their nomadic blood coursing through our own veins. But at the same time, distracted by our bread and circuses and embroiled in the wars that we have waged on each other, it seems that we have forgotten this desire to explore. We, as a species, we're evolved uniquely for Earth, on Earth, and by Earth, and so content are we with our living conditions that we have grown complacent and just too busy to notice that its resources are finite, and that our Sun's life is also finite. While Mars and all the movies made in its name have reinvigorated the ethos for space travel, few of us seem to truly realize that our species' fragile constitution is woefully unprepared for long duration journeys into space.\n",
      "Let us take a trek to your local national forest for a quick reality check. So just a quick show of hands here: how many of you think you would be able to survive in this lush wilderness for a few days? Well, that's a lot of you. How about a few weeks? That's a decent amount. How about a few months? That's pretty good too. Now, let us imagine that this local national forest experiences an eternal winter. Same questions: how many of you think you would be able to survive for a few days? That's quite a lot. How about a few weeks? So for a fun twist, let us imagine that the only source of water available is trapped as frozen blocks miles below the surface. Soil nutrients are so minimal that no vegetation can be found, and of course hardly any atmosphere exists to speak of.\n",
      "Such examples are only a few of the many challenges we would face on a planet like Mars. So how do we steel ourselves for voyages whose destinations are so far removed from a tropical vacation? Will we continuously ship supplies from Planet Earth? Build space elevators, or impossible miles of transport belts that tether your planet of choice to our home planet? And how do we grow things like food that grew up on Earth like us?\n",
      "But I'm getting ahead of myself. In our species' journey to find a new home under a new sun, we are more likely than not going to be spending muc\n"
     ]
    }
   ],
   "source": [
    "print(input_text[:10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentences_ted = tokenize_and_lowercase(input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188306\n",
      "['here', 'are', 'two', 'reasons', 'companies', 'fail', 'they', 'only', 'do', 'more', 'of', 'the', 'same', 'or', 'they', 'only', 'do', 'what', 's', 'new']\n",
      "['to', 'me', 'the', 'real', 'real', 'solution', 'to', 'quality', 'growth', 'is', 'figuring', 'out', 'the', 'balance', 'between', 'two', 'activities', 'exploration', 'and', 'exploitation']\n"
     ]
    }
   ],
   "source": [
    "print(len(sentences_ted))\n",
    "print(sentences_ted[0])\n",
    "print(sentences_ted[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build vocabulary using training set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47115\n"
     ]
    }
   ],
   "source": [
    "k = []\n",
    "for sent in sentences_ted:\n",
    "    for word in sent:\n",
    "        if word not in k:\n",
    "            k.append(word)\n",
    "print(len(k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del k "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "counts_ted_top100000 = []\n",
    "c = Counter([word for sent in sentences_ted for word in sent])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the', 148314), ('and', 106841), ('to', 90699), ('of', 81748), ('a', 75296), ('that', 67989), ('i', 58165), ('in', 56239), ('it', 51467), ('we', 49525)]\n"
     ]
    }
   ],
   "source": [
    "list_most_common = c.most_common(47000)\n",
    "print(list_most_common[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'and', 'to', 'of', 'a', 'that', 'i', 'in', 'it', 'we']\n"
     ]
    }
   ],
   "source": [
    "words_most_common = [ item[0] for item in list_most_common]\n",
    "print(words_most_common[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[148314, 106841, 90699, 81748, 75296, 67989, 58165, 56239, 51467, 49525]\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "for word, count in list_most_common:\n",
    "    counts_ted_top100000.append(count)\n",
    "    \n",
    "print(counts_ted_top100000[:10])\n",
    "print(counts_ted_top100000[-10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unknown_token = \"UnknownTK\"\n",
    "\n",
    "def replace_unknown_token(sent_list):\n",
    "#     for word in sent:\n",
    "#         if word not in words_most_common:\n",
    "#             sent=sent.replace(word, unknown_token)\n",
    "#     return sent \n",
    "    filtered_list = [word if word in words_most_common else unknown_token for word in sent_list]  # so fast !!!\n",
    "    return filtered_list\n",
    "\n",
    "def tokenize_and_lowercase_most_common(text):\n",
    "    text_noparens = re.sub(r'\\([^)]*\\)', '', text)\n",
    "    sentences_strings = []\n",
    "    for line in text_noparens.split('\\n'):\n",
    "        m = re.match(r'^(?:(?P<precolon>[^:]{,20}):)?(?P<postcolon>.*)$', line)\n",
    "        sentences_strings.extend(sent for sent in m.groupdict()['postcolon'].split('.') if sent)\n",
    "        \n",
    "    sentences= []\n",
    "    for sent_str in sentences_strings:\n",
    "        tokens = replace_unknown_token(re.sub(r\"[^a-z0-9]+\", \" \", sent_str.lower()).split())\n",
    "        if tokens != []:\n",
    "            sentences.append(tokens)\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training set \n",
    "train_doc = [(tokenize_and_lowercase_most_common(doc_temp[0]), doc_temp[1]) for doc_temp in train_doc_temp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1585\n"
     ]
    }
   ],
   "source": [
    "print(len(train_doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([['here', 'are', 'two', 'reasons', 'companies', 'fail', 'they', 'only', 'do', 'more', 'of', 'the', 'same', 'or', 'they', 'only', 'do', 'what', 's', 'new'], ['to', 'me', 'the', 'real', 'real', 'solution', 'to', 'quality', 'growth', 'is', 'figuring', 'out', 'the', 'balance', 'between', 'two', 'activities', 'exploration', 'and', 'exploitation'], ['both', 'are', 'necessary', 'but', 'it', 'can', 'be', 'too', 'much', 'of', 'a', 'good', 'thing'], ['consider', 'facit'], ['i', 'm', 'actually', 'old', 'enough', 'to', 'remember', 'them'], ['facit', 'was', 'a', 'fantastic', 'company'], ['they', 'were', 'born', 'deep', 'in', 'the', 'swedish', 'forest', 'and', 'they', 'made', 'the', 'best', 'mechanical', 'calculators', 'in', 'the', 'world'], ['everybody', 'used', 'them'], ['and', 'what', 'did', 'facit', 'do', 'when', 'the', 'electronic', 'calculator', 'came', 'along', 'they', 'continued', 'doing', 'exactly', 'the', 'same'], ['in', 'six', 'months', 'they', 'went', 'from', 'maximum', 'revenue'], ['and', 'they', 'were', 'gone'], ['gone'], ['to', 'me', 'the', 'irony', 'about', 'the', 'facit', 'story', 'is', 'hearing', 'about', 'the', 'facit', 'engineers', 'who', 'had', 'bought', 'cheap', 'small', 'electronic', 'calculators', 'in', 'japan', 'that', 'they', 'used', 'to', 'double', 'check', 'their', 'calculators'], ['facit', 'did', 'too', 'much', 'exploitation'], ['but', 'exploration', 'can', 'go', 'wild', 'too'], ['a', 'few', 'years', 'back', 'i', 'worked', 'closely', 'alongside', 'a', 'european', 'biotech', 'company'], ['let', 's', 'call', 'them', 'oncosearch'], ['the', 'company', 'was', 'brilliant'], ['they', 'had', 'applications', 'that', 'promised', 'to', 'diagnose', 'even', 'cure', 'certain', 'forms', 'of', 'blood', 'cancer'], ['every', 'day', 'was', 'about', 'creating', 'something', 'new'], ['they', 'were', 'extremely', 'innovative', 'and', 'the', 'mantra', 'was', 'when', 'we', 'only', 'get', 'it', 'right', 'or', 'even', 'we', 'want', 'it', 'perfect'], ['the', 'sad', 'thing', 'is', 'before', 'they', 'became', 'perfect', 'even', 'good', 'enough', 'they', 'became', 'obsolete'], ['oncosearch', 'did', 'too', 'much', 'exploration'], ['i', 'first', 'heard', 'about', 'exploration', 'and', 'exploitation', 'about', '15', 'years', 'ago', 'when', 'i', 'worked', 'as', 'a', 'visiting', 'scholar', 'at', 'stanford', 'university'], ['the', 'founder', 'of', 'the', 'idea', 'is', 'jim', 'march'], ['and', 'to', 'me', 'the', 'power', 'of', 'the', 'idea', 'is', 'its', 'practicality'], ['exploration'], ['exploration', 'is', 'about', 'coming', 'up', 'with', 'what', 's', 'new'], ['it', 's', 'about', 'search', 'it', 's', 'about', 'discovery', 'it', 's', 'about', 'new', 'products', 'it', 's', 'about', 'new', 'innovations'], ['it', 's', 'about', 'changing', 'our', 'frontiers'], ['our', 'heroes', 'are', 'people', 'who', 'have', 'done', 'exploration', 'madame', 'curie', 'picasso', 'neil', 'armstrong', 'sir', 'edmund', 'hillary', 'etc'], ['i', 'come', 'from', 'norway', 'all', 'our', 'heroes', 'are', 'explorers', 'and', 'they', 'deserve', 'to', 'be'], ['we', 'all', 'know', 'that', 'exploration', 'is', 'risky'], ['we', 'don', 't', 'know', 'the', 'answers', 'we', 'don', 't', 'know', 'if', 'we', 're', 'going', 'to', 'find', 'them', 'and', 'we', 'know', 'that', 'the', 'risks', 'are', 'high'], ['exploitation', 'is', 'the', 'opposite'], ['exploitation', 'is', 'taking', 'the', 'knowledge', 'we', 'have', 'and', 'making', 'good', 'better'], ['exploitation', 'is', 'about', 'making', 'our', 'trains', 'run', 'on', 'time'], ['it', 's', 'about', 'making', 'good', 'products', 'faster', 'and', 'cheaper'], ['exploitation', 'is', 'not', 'risky', 'in', 'the', 'short', 'term'], ['but', 'if', 'we', 'only', 'exploit', 'it', 's', 'very', 'risky', 'in', 'the', 'long', 'term'], ['and', 'i', 'think', 'we', 'all', 'have', 'memories', 'of', 'the', 'famous', 'pop', 'groups', 'who', 'keep', 'singing', 'the', 'same', 'songs', 'again', 'and', 'again', 'until', 'they', 'become', 'obsolete', 'or', 'even', 'pathetic'], ['that', 's', 'the', 'risk', 'of', 'exploitation'], ['so', 'if', 'we', 'take', 'a', 'long', 'term', 'perspective', 'we', 'explore'], ['if', 'we', 'take', 'a', 'short', 'term', 'perspective', 'we', 'exploit'], ['small', 'children', 'they', 'explore', 'all', 'day'], ['all', 'day', 'it', 's', 'about', 'exploration'], ['as', 'we', 'grow', 'older', 'we', 'explore', 'less', 'because', 'we', 'have', 'more', 'knowledge', 'to', 'exploit', 'on'], ['the', 'same', 'goes', 'for', 'companies'], ['companies', 'become', 'by', 'nature', 'less', 'innovative', 'as', 'they', 'become', 'more', 'competent'], ['and', 'this', 'is', 'of', 'course', 'a', 'big', 'worry', 'to', 'ceos'], ['and', 'i', 'hear', 'very', 'often', 'questions', 'phrased', 'in', 'different', 'ways'], ['for', 'example', 'how', 'can', 'i', 'both', 'effectively', 'run', 'and', 'reinvent', 'my', 'company', 'or', 'how', 'can', 'i', 'make', 'sure', 'that', 'our', 'company', 'changes', 'before', 'we', 'become', 'obsolete', 'or', 'are', 'hit', 'by', 'a', 'crisis', 'so', 'doing', 'one', 'well', 'is', 'difficult'], ['doing', 'both', 'well', 'as', 'the', 'same', 'time', 'is', 'art', 'pushing', 'both', 'exploration', 'and', 'exploitation'], ['so', 'one', 'thing', 'we', 've', 'found', 'is', 'only', 'about', 'two', 'percent', 'of', 'companies', 'are', 'able', 'to', 'effectively', 'explore', 'and', 'exploit', 'at', 'the', 'same', 'time', 'in', 'parallel'], ['but', 'when', 'they', 'do', 'the', 'payoffs', 'are', 'huge'], ['so', 'we', 'have', 'lots', 'of', 'great', 'examples'], ['we', 'have', 'nestl', 'creating', 'nespresso', 'we', 'have', 'lego', 'going', 'into', 'animated', 'films', 'toyota', 'creating', 'the', 'hybrids', 'unilever', 'pushing', 'into', 'sustainability', 'there', 'are', 'lots', 'of', 'examples', 'and', 'the', 'benefits', 'are', 'huge'], ['why', 'is', 'balancing', 'so', 'difficult', 'i', 'think', 'it', 's', 'difficult', 'because', 'there', 'are', 'so', 'many', 'traps', 'that', 'keep', 'us', 'where', 'we', 'are'], ['so', 'i', 'll', 'talk', 'about', 'two', 'but', 'there', 'are', 'many'], ['so', 'let', 's', 'talk', 'about', 'the', 'perpetual', 'search', 'trap'], ['we', 'discover', 'something', 'but', 'we', 'don', 't', 'have', 'the', 'patience', 'or', 'the', 'persistence', 'to', 'get', 'at', 'it', 'and', 'make', 'it', 'work'], ['so', 'instead', 'of', 'staying', 'with', 'it', 'we', 'create', 'something', 'new'], ['but', 'the', 'same', 'goes', 'for', 'that', 'then', 'we', 're', 'in', 'the', 'vicious', 'circle', 'of', 'actually', 'coming', 'up', 'with', 'ideas', 'but', 'being', 'frustrated'], ['oncosearch', 'was', 'a', 'good', 'example'], ['a', 'famous', 'example', 'is', 'of', 'course', 'xerox'], ['but', 'we', 'don', 't', 'only', 'see', 'this', 'in', 'companies'], ['we', 'see', 'this', 'in', 'the', 'public', 'sector', 'as', 'well'], ['we', 'all', 'know', 'that', 'any', 'kind', 'of', 'effective', 'reform', 'of', 'education', 'research', 'health', 'care', 'even', 'defense', 'takes', '10', '15', 'maybe', '20', 'years', 'to', 'work'], ['but', 'still', 'we', 'change', 'much', 'more', 'often'], ['we', 'really', 'don', 't', 'give', 'them', 'the', 'chance'], ['another', 'trap', 'is', 'the', 'success', 'trap'], ['facit', 'fell', 'into', 'the', 'success', 'trap'], ['they', 'literally', 'held', 'the', 'future', 'in', 'their', 'hands', 'but', 'they', 'couldn', 't', 'see', 'it'], ['they', 'were', 'simply', 'so', 'good', 'at', 'making', 'what', 'they', 'loved', 'doing', 'that', 'they', 'wouldn', 't', 'change'], ['we', 'are', 'like', 'that', 'too'], ['when', 'we', 'know', 'something', 'well', 'it', 's', 'difficult', 'to', 'change'], ['bill', 'gates', 'has', 'said', 'success', 'is', 'a', 'lousy', 'teacher'], ['it', 'seduces', 'us', 'into', 'thinking', 'we', 'cannot', 'fail'], ['that', 's', 'the', 'challenge', 'with', 'success'], ['so', 'i', 'think', 'there', 'are', 'some', 'lessons', 'and', 'i', 'think', 'they', 'apply', 'to', 'us'], ['and', 'they', 'apply', 'to', 'our', 'companies'], ['the', 'first', 'lesson', 'is', 'get', 'ahead', 'of', 'the', 'crisis'], ['and', 'any', 'company', 'that', 's', 'able', 'to', 'innovate', 'is', 'actually', 'able', 'to', 'also', 'buy', 'an', 'insurance', 'in', 'the', 'future'], ['netflix', 'they', 'could', 'so', 'easily', 'have', 'been', 'content', 'with', 'earlier', 'generations', 'of', 'distribution', 'but', 'they', 'always', 'and', 'i', 'think', 'they', 'will', 'always', 'keep', 'pushing', 'for', 'the', 'next', 'battle'], ['i', 'see', 'other', 'companies', 'that', 'say', 'i', 'll', 'win', 'the', 'next', 'innovation', 'cycle', 'whatever', 'it', 'takes'], ['think', 'in', 'multiple', 'time', 'scales'], ['i', 'll', 'share', 'a', 'chart', 'with', 'you', 'and', 'i', 'think', 'it', 's', 'a', 'wonderful', 'one'], ['any', 'company', 'we', 'look', 'at', 'taking', 'a', 'one', 'year', 'perspective', 'and', 'looking', 'at', 'the', 'valuation', 'of', 'the', 'company', 'innovation', 'typically', 'accounts', 'for', 'only', 'about', '30', 'percent'], ['so', 'when', 'we', 'think', 'one', 'year', 'innovation', 'isn', 't', 'really', 'that', 'important'], ['move', 'ahead', 'take', 'a', '10', 'year', 'perspective', 'on', 'the', 'same', 'company', 'suddenly', 'innovation', 'and', 'ability', 'to', 'renew', 'account', 'for', '70', 'percent'], ['but', 'companies', 'can', 't', 'choose'], ['they', 'need', 'to', 'fund', 'the', 'journey', 'and', 'lead', 'the', 'long', 'term'], ['invite', 'talent'], ['i', 'don', 't', 'think', 'it', 's', 'possible', 'for', 'any', 'of', 'us', 'to', 'be', 'able', 'to', 'balance', 'exploration', 'and', 'exploitation', 'by', 'ourselves'], ['i', 'think', 'it', 's', 'a', 'team', 'sport'], ['i', 'think', 'we', 'need', 'to', 'allow', 'challenging'], ['i', 'think', 'the', 'mark', 'of', 'a', 'great', 'company', 'is', 'being', 'open', 'to', 'be', 'challenged', 'and', 'the', 'mark', 'of', 'a', 'good', 'corporate', 'board', 'is', 'to', 'constructively', 'challenge'], ['i', 'think', 'that', 's', 'also', 'what', 'good', 'parenting', 'is', 'about'], ['be', 'skeptical', 'of', 'success'], ['maybe', 'it', 's', 'useful', 'to', 'think', 'back', 'at', 'the', 'old', 'triumph', 'marches', 'in', 'rome', 'when', 'the', 'generals', 'after', 'a', 'big', 'victory', 'were', 'given', 'their', 'celebration'], ['riding', 'into', 'rome', 'on', 'the', 'carriage', 'they', 'always', 'had', 'a', 'companion', 'whispering', 'in', 'their', 'ear', 'remember', 'you', 're', 'only', 'human'], ['so', 'i', 'hope', 'i', 'made', 'the', 'point', 'balancing', 'exploration', 'and', 'exploitation', 'has', 'a', 'huge', 'payoff'], ['but', 'it', 's', 'difficult', 'and', 'we', 'need', 'to', 'be', 'conscious'], ['i', 'want', 'to', 'just', 'point', 'out', 'two', 'questions', 'that', 'i', 'think', 'are', 'useful'], ['first', 'question', 'is', 'looking', 'at', 'your', 'own', 'company', 'in', 'which', 'areas', 'do', 'you', 'see', 'that', 'the', 'company', 'is', 'at', 'the', 'risk', 'of', 'falling', 'into', 'success', 'traps', 'of', 'just', 'going', 'on', 'autopilot', 'and', 'what', 'can', 'you', 'do', 'to', 'challenge'], ['when', 'did', 'i', 'explore', 'something', 'new', 'last', 'and', 'what', 'kind', 'of', 'effect', 'did', 'it', 'have', 'on', 'me', 'is', 'that', 'something', 'i', 'should', 'do', 'more', 'of', 'in', 'my', 'case', 'yes'], ['so', 'let', 'me', 'leave', 'you', 'with', 'this'], ['whether', 'you', 're', 'an', 'explorer', 'by', 'nature', 'or', 'whether', 'you', 'tend', 'to', 'exploit', 'what', 'you', 'already', 'know', 'don', 't', 'forget', 'the', 'beauty', 'is', 'in', 'the', 'balance'], ['thank', 'you']], 0) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(train_doc[0], '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['here', 'are', 'two', 'reasons', 'companies', 'fail', 'they', 'only', 'do', 'more', 'of', 'the', 'same', 'or', 'they', 'only', 'do', 'what', 's', 'new'], ['to', 'me', 'the', 'real', 'real', 'solution', 'to', 'quality', 'growth', 'is', 'figuring', 'out', 'the', 'balance', 'between', 'two', 'activities', 'exploration', 'and', 'exploitation'], ['both', 'are', 'necessary', 'but', 'it', 'can', 'be', 'too', 'much', 'of', 'a', 'good', 'thing'], ['consider', 'facit'], ['i', 'm', 'actually', 'old', 'enough', 'to', 'remember', 'them'], ['facit', 'was', 'a', 'fantastic', 'company'], ['they', 'were', 'born', 'deep', 'in', 'the', 'swedish', 'forest', 'and', 'they', 'made', 'the', 'best', 'mechanical', 'calculators', 'in', 'the', 'world'], ['everybody', 'used', 'them'], ['and', 'what', 'did', 'facit', 'do', 'when', 'the', 'electronic', 'calculator', 'came', 'along', 'they', 'continued', 'doing', 'exactly', 'the', 'same'], ['in', 'six', 'months', 'they', 'went', 'from', 'maximum', 'revenue'], ['and', 'they', 'were', 'gone'], ['gone'], ['to', 'me', 'the', 'irony', 'about', 'the', 'facit', 'story', 'is', 'hearing', 'about', 'the', 'facit', 'engineers', 'who', 'had', 'bought', 'cheap', 'small', 'electronic', 'calculators', 'in', 'japan', 'that', 'they', 'used', 'to', 'double', 'check', 'their', 'calculators'], ['facit', 'did', 'too', 'much', 'exploitation'], ['but', 'exploration', 'can', 'go', 'wild', 'too'], ['a', 'few', 'years', 'back', 'i', 'worked', 'closely', 'alongside', 'a', 'european', 'biotech', 'company'], ['let', 's', 'call', 'them', 'oncosearch'], ['the', 'company', 'was', 'brilliant'], ['they', 'had', 'applications', 'that', 'promised', 'to', 'diagnose', 'even', 'cure', 'certain', 'forms', 'of', 'blood', 'cancer'], ['every', 'day', 'was', 'about', 'creating', 'something', 'new'], ['they', 'were', 'extremely', 'innovative', 'and', 'the', 'mantra', 'was', 'when', 'we', 'only', 'get', 'it', 'right', 'or', 'even', 'we', 'want', 'it', 'perfect'], ['the', 'sad', 'thing', 'is', 'before', 'they', 'became', 'perfect', 'even', 'good', 'enough', 'they', 'became', 'obsolete'], ['oncosearch', 'did', 'too', 'much', 'exploration'], ['i', 'first', 'heard', 'about', 'exploration', 'and', 'exploitation', 'about', '15', 'years', 'ago', 'when', 'i', 'worked', 'as', 'a', 'visiting', 'scholar', 'at', 'stanford', 'university'], ['the', 'founder', 'of', 'the', 'idea', 'is', 'jim', 'march'], ['and', 'to', 'me', 'the', 'power', 'of', 'the', 'idea', 'is', 'its', 'practicality'], ['exploration'], ['exploration', 'is', 'about', 'coming', 'up', 'with', 'what', 's', 'new'], ['it', 's', 'about', 'search', 'it', 's', 'about', 'discovery', 'it', 's', 'about', 'new', 'products', 'it', 's', 'about', 'new', 'innovations'], ['it', 's', 'about', 'changing', 'our', 'frontiers'], ['our', 'heroes', 'are', 'people', 'who', 'have', 'done', 'exploration', 'madame', 'curie', 'picasso', 'neil', 'armstrong', 'sir', 'edmund', 'hillary', 'etc'], ['i', 'come', 'from', 'norway', 'all', 'our', 'heroes', 'are', 'explorers', 'and', 'they', 'deserve', 'to', 'be'], ['we', 'all', 'know', 'that', 'exploration', 'is', 'risky'], ['we', 'don', 't', 'know', 'the', 'answers', 'we', 'don', 't', 'know', 'if', 'we', 're', 'going', 'to', 'find', 'them', 'and', 'we', 'know', 'that', 'the', 'risks', 'are', 'high'], ['exploitation', 'is', 'the', 'opposite'], ['exploitation', 'is', 'taking', 'the', 'knowledge', 'we', 'have', 'and', 'making', 'good', 'better'], ['exploitation', 'is', 'about', 'making', 'our', 'trains', 'run', 'on', 'time'], ['it', 's', 'about', 'making', 'good', 'products', 'faster', 'and', 'cheaper'], ['exploitation', 'is', 'not', 'risky', 'in', 'the', 'short', 'term'], ['but', 'if', 'we', 'only', 'exploit', 'it', 's', 'very', 'risky', 'in', 'the', 'long', 'term'], ['and', 'i', 'think', 'we', 'all', 'have', 'memories', 'of', 'the', 'famous', 'pop', 'groups', 'who', 'keep', 'singing', 'the', 'same', 'songs', 'again', 'and', 'again', 'until', 'they', 'become', 'obsolete', 'or', 'even', 'pathetic'], ['that', 's', 'the', 'risk', 'of', 'exploitation'], ['so', 'if', 'we', 'take', 'a', 'long', 'term', 'perspective', 'we', 'explore'], ['if', 'we', 'take', 'a', 'short', 'term', 'perspective', 'we', 'exploit'], ['small', 'children', 'they', 'explore', 'all', 'day'], ['all', 'day', 'it', 's', 'about', 'exploration'], ['as', 'we', 'grow', 'older', 'we', 'explore', 'less', 'because', 'we', 'have', 'more', 'knowledge', 'to', 'exploit', 'on'], ['the', 'same', 'goes', 'for', 'companies'], ['companies', 'become', 'by', 'nature', 'less', 'innovative', 'as', 'they', 'become', 'more', 'competent'], ['and', 'this', 'is', 'of', 'course', 'a', 'big', 'worry', 'to', 'ceos'], ['and', 'i', 'hear', 'very', 'often', 'questions', 'phrased', 'in', 'different', 'ways'], ['for', 'example', 'how', 'can', 'i', 'both', 'effectively', 'run', 'and', 'reinvent', 'my', 'company', 'or', 'how', 'can', 'i', 'make', 'sure', 'that', 'our', 'company', 'changes', 'before', 'we', 'become', 'obsolete', 'or', 'are', 'hit', 'by', 'a', 'crisis', 'so', 'doing', 'one', 'well', 'is', 'difficult'], ['doing', 'both', 'well', 'as', 'the', 'same', 'time', 'is', 'art', 'pushing', 'both', 'exploration', 'and', 'exploitation'], ['so', 'one', 'thing', 'we', 've', 'found', 'is', 'only', 'about', 'two', 'percent', 'of', 'companies', 'are', 'able', 'to', 'effectively', 'explore', 'and', 'exploit', 'at', 'the', 'same', 'time', 'in', 'parallel'], ['but', 'when', 'they', 'do', 'the', 'payoffs', 'are', 'huge'], ['so', 'we', 'have', 'lots', 'of', 'great', 'examples'], ['we', 'have', 'nestl', 'creating', 'nespresso', 'we', 'have', 'lego', 'going', 'into', 'animated', 'films', 'toyota', 'creating', 'the', 'hybrids', 'unilever', 'pushing', 'into', 'sustainability', 'there', 'are', 'lots', 'of', 'examples', 'and', 'the', 'benefits', 'are', 'huge'], ['why', 'is', 'balancing', 'so', 'difficult', 'i', 'think', 'it', 's', 'difficult', 'because', 'there', 'are', 'so', 'many', 'traps', 'that', 'keep', 'us', 'where', 'we', 'are'], ['so', 'i', 'll', 'talk', 'about', 'two', 'but', 'there', 'are', 'many'], ['so', 'let', 's', 'talk', 'about', 'the', 'perpetual', 'search', 'trap'], ['we', 'discover', 'something', 'but', 'we', 'don', 't', 'have', 'the', 'patience', 'or', 'the', 'persistence', 'to', 'get', 'at', 'it', 'and', 'make', 'it', 'work'], ['so', 'instead', 'of', 'staying', 'with', 'it', 'we', 'create', 'something', 'new'], ['but', 'the', 'same', 'goes', 'for', 'that', 'then', 'we', 're', 'in', 'the', 'vicious', 'circle', 'of', 'actually', 'coming', 'up', 'with', 'ideas', 'but', 'being', 'frustrated'], ['oncosearch', 'was', 'a', 'good', 'example'], ['a', 'famous', 'example', 'is', 'of', 'course', 'xerox'], ['but', 'we', 'don', 't', 'only', 'see', 'this', 'in', 'companies'], ['we', 'see', 'this', 'in', 'the', 'public', 'sector', 'as', 'well'], ['we', 'all', 'know', 'that', 'any', 'kind', 'of', 'effective', 'reform', 'of', 'education', 'research', 'health', 'care', 'even', 'defense', 'takes', '10', '15', 'maybe', '20', 'years', 'to', 'work'], ['but', 'still', 'we', 'change', 'much', 'more', 'often'], ['we', 'really', 'don', 't', 'give', 'them', 'the', 'chance'], ['another', 'trap', 'is', 'the', 'success', 'trap'], ['facit', 'fell', 'into', 'the', 'success', 'trap'], ['they', 'literally', 'held', 'the', 'future', 'in', 'their', 'hands', 'but', 'they', 'couldn', 't', 'see', 'it'], ['they', 'were', 'simply', 'so', 'good', 'at', 'making', 'what', 'they', 'loved', 'doing', 'that', 'they', 'wouldn', 't', 'change'], ['we', 'are', 'like', 'that', 'too'], ['when', 'we', 'know', 'something', 'well', 'it', 's', 'difficult', 'to', 'change'], ['bill', 'gates', 'has', 'said', 'success', 'is', 'a', 'lousy', 'teacher'], ['it', 'seduces', 'us', 'into', 'thinking', 'we', 'cannot', 'fail'], ['that', 's', 'the', 'challenge', 'with', 'success'], ['so', 'i', 'think', 'there', 'are', 'some', 'lessons', 'and', 'i', 'think', 'they', 'apply', 'to', 'us'], ['and', 'they', 'apply', 'to', 'our', 'companies'], ['the', 'first', 'lesson', 'is', 'get', 'ahead', 'of', 'the', 'crisis'], ['and', 'any', 'company', 'that', 's', 'able', 'to', 'innovate', 'is', 'actually', 'able', 'to', 'also', 'buy', 'an', 'insurance', 'in', 'the', 'future'], ['netflix', 'they', 'could', 'so', 'easily', 'have', 'been', 'content', 'with', 'earlier', 'generations', 'of', 'distribution', 'but', 'they', 'always', 'and', 'i', 'think', 'they', 'will', 'always', 'keep', 'pushing', 'for', 'the', 'next', 'battle'], ['i', 'see', 'other', 'companies', 'that', 'say', 'i', 'll', 'win', 'the', 'next', 'innovation', 'cycle', 'whatever', 'it', 'takes'], ['think', 'in', 'multiple', 'time', 'scales'], ['i', 'll', 'share', 'a', 'chart', 'with', 'you', 'and', 'i', 'think', 'it', 's', 'a', 'wonderful', 'one'], ['any', 'company', 'we', 'look', 'at', 'taking', 'a', 'one', 'year', 'perspective', 'and', 'looking', 'at', 'the', 'valuation', 'of', 'the', 'company', 'innovation', 'typically', 'accounts', 'for', 'only', 'about', '30', 'percent'], ['so', 'when', 'we', 'think', 'one', 'year', 'innovation', 'isn', 't', 'really', 'that', 'important'], ['move', 'ahead', 'take', 'a', '10', 'year', 'perspective', 'on', 'the', 'same', 'company', 'suddenly', 'innovation', 'and', 'ability', 'to', 'renew', 'account', 'for', '70', 'percent'], ['but', 'companies', 'can', 't', 'choose'], ['they', 'need', 'to', 'fund', 'the', 'journey', 'and', 'lead', 'the', 'long', 'term'], ['invite', 'talent'], ['i', 'don', 't', 'think', 'it', 's', 'possible', 'for', 'any', 'of', 'us', 'to', 'be', 'able', 'to', 'balance', 'exploration', 'and', 'exploitation', 'by', 'ourselves'], ['i', 'think', 'it', 's', 'a', 'team', 'sport'], ['i', 'think', 'we', 'need', 'to', 'allow', 'challenging'], ['i', 'think', 'the', 'mark', 'of', 'a', 'great', 'company', 'is', 'being', 'open', 'to', 'be', 'challenged', 'and', 'the', 'mark', 'of', 'a', 'good', 'corporate', 'board', 'is', 'to', 'constructively', 'challenge'], ['i', 'think', 'that', 's', 'also', 'what', 'good', 'parenting', 'is', 'about'], ['be', 'skeptical', 'of', 'success'], ['maybe', 'it', 's', 'useful', 'to', 'think', 'back', 'at', 'the', 'old', 'triumph', 'marches', 'in', 'rome', 'when', 'the', 'generals', 'after', 'a', 'big', 'victory', 'were', 'given', 'their', 'celebration'], ['riding', 'into', 'rome', 'on', 'the', 'carriage', 'they', 'always', 'had', 'a', 'companion', 'whispering', 'in', 'their', 'ear', 'remember', 'you', 're', 'only', 'human'], ['so', 'i', 'hope', 'i', 'made', 'the', 'point', 'balancing', 'exploration', 'and', 'exploitation', 'has', 'a', 'huge', 'payoff'], ['but', 'it', 's', 'difficult', 'and', 'we', 'need', 'to', 'be', 'conscious'], ['i', 'want', 'to', 'just', 'point', 'out', 'two', 'questions', 'that', 'i', 'think', 'are', 'useful'], ['first', 'question', 'is', 'looking', 'at', 'your', 'own', 'company', 'in', 'which', 'areas', 'do', 'you', 'see', 'that', 'the', 'company', 'is', 'at', 'the', 'risk', 'of', 'falling', 'into', 'success', 'traps', 'of', 'just', 'going', 'on', 'autopilot', 'and', 'what', 'can', 'you', 'do', 'to', 'challenge'], ['when', 'did', 'i', 'explore', 'something', 'new', 'last', 'and', 'what', 'kind', 'of', 'effect', 'did', 'it', 'have', 'on', 'me', 'is', 'that', 'something', 'i', 'should', 'do', 'more', 'of', 'in', 'my', 'case', 'yes'], ['so', 'let', 'me', 'leave', 'you', 'with', 'this'], ['whether', 'you', 're', 'an', 'explorer', 'by', 'nature', 'or', 'whether', 'you', 'tend', 'to', 'exploit', 'what', 'you', 'already', 'know', 'don', 't', 'forget', 'the', 'beauty', 'is', 'in', 'the', 'balance'], ['thank', 'you']] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(train_doc[0][0], '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['here', 'are', 'two', 'reasons', 'companies', 'fail', 'they', 'only', 'do', 'more', 'of', 'the', 'same', 'or', 'they', 'only', 'do', 'what', 's', 'new']\n",
      "['to', 'me', 'the', 'real', 'real', 'solution', 'to', 'quality', 'growth', 'is', 'figuring', 'out', 'the', 'balance', 'between', 'two', 'activities', 'exploration', 'and', 'exploitation']\n",
      "['both', 'are', 'necessary', 'but', 'it', 'can', 'be', 'too', 'much', 'of', 'a', 'good', 'thing']\n",
      "['consider', 'facit']\n",
      "['i', 'm', 'actually', 'old', 'enough', 'to', 'remember', 'them']\n",
      "['facit', 'was', 'a', 'fantastic', 'company']\n",
      "['they', 'were', 'born', 'deep', 'in', 'the', 'swedish', 'forest', 'and', 'they', 'made', 'the', 'best', 'mechanical', 'calculators', 'in', 'the', 'world']\n",
      "['everybody', 'used', 'them']\n",
      "['and', 'what', 'did', 'facit', 'do', 'when', 'the', 'electronic', 'calculator', 'came', 'along', 'they', 'continued', 'doing', 'exactly', 'the', 'same']\n",
      "['in', 'six', 'months', 'they', 'went', 'from', 'maximum', 'revenue']\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(train_doc[0][0][i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rebuild the vocabulary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_ted_top100000_new = []\n",
    "            \n",
    "c_new = Counter([word for doc in train_doc for sent in doc[0] for word in sent])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the', 148314), ('and', 106841), ('to', 90699), ('of', 81748), ('a', 75296), ('that', 67989), ('i', 58165), ('in', 56239), ('it', 51467), ('we', 49525)]\n"
     ]
    }
   ],
   "source": [
    "list_most_common_new = c_new.most_common(47001)\n",
    "print(list_most_common_new[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115\n"
     ]
    }
   ],
   "source": [
    "print(c_new['UnknownTK'])\n",
    "list_most_common_new.append(('UnknownTK', 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'and', 'to', 'of', 'a', 'that', 'i', 'in', 'it', 'we']\n"
     ]
    }
   ],
   "source": [
    "words_most_common_new = [ item[0] for item in list_most_common_new]\n",
    "print(words_most_common_new[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[148314, 106841, 90699, 81748, 75296, 67989, 58165, 56239, 51467, 49525]\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "for word, count in list_most_common_new:\n",
    "    counts_ted_top100000_new.append(count)\n",
    "    \n",
    "print(counts_ted_top100000_new[:10])\n",
    "print(counts_ted_top100000_new[-10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentences = [sent for doc in train_doc for sent in doc[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['to',\n",
       " 'me',\n",
       " 'the',\n",
       " 'real',\n",
       " 'real',\n",
       " 'solution',\n",
       " 'to',\n",
       " 'quality',\n",
       " 'growth',\n",
       " 'is',\n",
       " 'figuring',\n",
       " 'out',\n",
       " 'the',\n",
       " 'balance',\n",
       " 'between',\n",
       " 'two',\n",
       " 'activities',\n",
       " 'exploration',\n",
       " 'and',\n",
       " 'exploitation']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Word2Vec "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_trained = Word2Vec(sentences, min_count=1, size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_trained.save(\"word2vec_model_vocab47001_mincount1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Word2Vec.load(\"word2vec_model_vocab47001_mincount1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47001\n"
     ]
    }
   ],
   "source": [
    "print(len(model.wv.vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('nfl', 0.827136754989624),\n",
       " ('italian', 0.825472891330719),\n",
       " ('decimated', 0.825014054775238),\n",
       " ('congenital', 0.8245549201965332),\n",
       " ('l', 0.8221679925918579),\n",
       " ('roald', 0.8216572999954224),\n",
       " ('oculus', 0.8187201023101807),\n",
       " ('thrust', 0.8181350231170654),\n",
       " ('ox', 0.8158272504806519),\n",
       " ('technocrats', 0.815642774105072)]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar('UnknownTK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100,)\n",
      "[ 1.20787346  0.27783382  2.96324563  0.5772866  -0.61856365  0.17629476\n",
      "  0.14164381 -0.35850075  0.950804   -2.22759342  0.62552279  0.93691742\n",
      "  0.63060606 -0.5529179  -0.61665118  0.52841729 -0.23892108 -0.30634585\n",
      " -0.88684738  1.38360262  4.07542324  1.81895471  0.43627098 -0.40864843\n",
      "  0.5563013  -0.15118779 -0.08758353 -0.22335196 -1.57582915  0.56395435\n",
      " -0.44580376  0.45437661 -2.15703321  3.26593924 -0.37317896 -1.11813104\n",
      " -0.45251217 -1.34095895  0.66345918  0.07126807 -0.22967933  0.96616226\n",
      " -0.32106581 -0.10020237  0.09889627 -1.24980712  0.14713278 -1.18839693\n",
      "  0.76698643  1.31079948  1.03377664  0.73085886 -0.0812294   0.50940573\n",
      "  0.5368554  -1.00265169  0.21758187 -1.05759156 -0.20690595  0.21874021\n",
      "  1.55585802  0.07748078 -0.19541292 -1.14609861 -0.57014054 -2.20842385\n",
      "  1.58665299  0.76519334 -1.34158385  1.17245936 -0.23474972  2.02114201\n",
      "  1.10555387 -0.12429544  0.46398905  1.92463505 -0.41800261  1.03551757\n",
      "  1.41510427  0.93166739  1.12278306  0.79231817  2.84922719  2.15049028\n",
      "  1.58294415 -0.09221537  1.13195705  0.92216259 -0.03185309  0.15076515\n",
      " -0.62081587 -2.08728194  0.92028773  0.73323435 -0.36603925 -0.94103944\n",
      " -1.94798851 -0.36272815  1.73746634 -1.75533521]\n"
     ]
    }
   ],
   "source": [
    "print(model.wv['it'].shape)\n",
    "print(model.wv['it'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking the model with t-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'counts_ted_top1000_new' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-53-8c411cd03833>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medges\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistogram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcounts_ted_top1000_new\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdensity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m p = figure(tools=\"pan,wheel_zoom,reset,save\",\n\u001b[1;32m      4\u001b[0m            \u001b[0mtoolbar_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"above\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m            title=\"Top-1000 words distribution\")\n",
      "\u001b[0;31mNameError\u001b[0m: name 'counts_ted_top1000_new' is not defined"
     ]
    }
   ],
   "source": [
    "hist, edges = np.histogram(counts_ted_top1000_new, density=True, bins=100, normed=True)\n",
    "\n",
    "p = figure(tools=\"pan,wheel_zoom,reset,save\",\n",
    "           toolbar_location=\"above\",\n",
    "           title=\"Top-1000 words distribution\")\n",
    "p.quad(top=hist, bottom=0, left=edges[:-1], right=edges[1:], line_color=\"#555555\")\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_top_ted_new = []\n",
    "for word, count in list_most_common_new:\n",
    "    words_top_ted_new.append(word)\n",
    "    \n",
    "print(words_top_ted_new[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This assumes words_top_wiki is a list of strings, the top 1000 words\n",
    "words_top_vec_ted_new = model[words_top_ted_new]\n",
    "\n",
    "tsne = TSNE(n_components=2, random_state=0)\n",
    "words_top_ted_tsne_new = tsne.fit_transform(words_top_vec_ted_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = figure(tools=\"pan,wheel_zoom,reset,save\",\n",
    "           toolbar_location=\"above\",\n",
    "           title=\"word2vec T-SNE for most common words\")\n",
    "\n",
    "source = ColumnDataSource(data=dict(x1=words_top_ted_tsne_new[:,0],\n",
    "                                    x2=words_top_ted_tsne_new[:,1],\n",
    "                                    names=words_top_ted_new))\n",
    "\n",
    "p.scatter(x=\"x1\", y=\"x2\", size=8, source=source)\n",
    "\n",
    "labels = LabelSet(x=\"x1\", y=\"x2\", text=\"names\", y_offset=6,\n",
    "                  text_font_size=\"8pt\", text_color=\"#555555\",\n",
    "                  source=source, text_align='center')\n",
    "p.add_layout(labels)\n",
    "\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Training set \n",
    "train_doc = [(tokenize_and_lowercase_most_common(doc_temp[0]), doc_temp[1]) for doc_temp in train_doc_temp]\n",
    "train_doc = [item for item in train_doc if item[0] != []]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Validation set \n",
    "valid_doc = [(tokenize_and_lowercase_most_common(doc_temp[0]), doc_temp[1]) for doc_temp in valid_doc_temp]\n",
    "valid_doc = [item for item in valid_doc if item[0] != []]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Test set \n",
    "test_doc = [(tokenize_and_lowercase_most_common(doc_temp[0]), doc_temp[1]) for doc_temp in test_doc_temp]\n",
    "test_doc = [item for item in test_doc if item[0] != []]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([['i', 'm', 'extremely', 'excited', 'to', 'be', 'given', 'the', 'opportunity', 'to', 'come', 'and', 'speak', 'to', 'you', 'today', 'about', 'what', 'i', 'consider', 'to', 'be', 'the', 'biggest', 'stunt', 'on', 'earth'], ['or', 'perhaps', 'not', 'quite', 'on', 'earth'], ['a', 'parachute', 'jump', 'from', 'the', 'very', 'edge', 'of', 'space'], ['more', 'about', 'that', 'a', 'bit', 'later', 'on'], ['what', 'i', 'd', 'like', 'to', 'do', 'first', 'is', 'take', 'you', 'through', 'a', 'very', 'brief', 'helicopter', 'ride', 'of', 'stunts', 'and', 'the', 'stunts', 'industry', 'in', 'the', 'movies', 'and', 'in', 'television', 'and', 'show', 'you', 'how', 'technology', 'has', 'started', 'to', 'interface', 'with', 'the', 'physical', 'skills', 'of', 'the', 'stunt', 'performer', 'in', 'a', 'way', 'that', 'makes', 'the', 'stunts', 'bigger', 'and', 'actually', 'makes', 'them', 'safer', 'than', 'they', 've', 'ever', 'been', 'before'], ['i', 've', 'been', 'a', 'professional', 'stunt', 'man', 'for', '13', 'years'], ['i', 'm', 'a', 'stunt', 'coordinator'], ['and', 'as', 'well', 'as', 'perform', 'stunts', 'i', 'often', 'design', 'them'], ['during', 'that', 'time', 'health', 'and', 'safety', 'has', 'become', 'everything', 'about', 'my', 'job'], ['it', 's', 'critical', 'now', 'that', 'when', 'a', 'car', 'crash', 'happens', 'it', 'isn', 't', 'just', 'the', 'stunt', 'person', 'we', 'make', 'safe', 'it', 's', 'the', 'crew'], ['we', 'can', 't', 'be', 'killing', 'camera', 'men'], ['we', 'can', 't', 'be', 'killing', 'stunt', 'men'], ['we', 'can', 't', 'be', 'killing', 'anybody', 'or', 'hurting', 'anybody', 'on', 'set', 'or', 'any', 'passerby'], ['so', 'safety', 'is', 'everything'], ['but', 'it', 'wasn', 't', 'always', 'that', 'way'], ['in', 'the', 'old', 'days', 'of', 'the', 'silent', 'movies', 'harold', 'lloyd', 'here', 'hanging', 'famously', 'from', 'the', 'clock', 'hands', 'a', 'lot', 'of', 'these', 'guys', 'did', 'their', 'own', 'stunts'], ['they', 'were', 'quite', 'remarkable'], ['they', 'had', 'no', 'safety', 'no', 'real', 'technology'], ['what', 'safety', 'they', 'had', 'was', 'very', 'UnknownTK'], ['this', 'is', 'the', 'first', 'stunt', 'woman', 'rosie', 'UnknownTK', 'an', 'amazing', 'woman'], ['you', 'can', 'see', 'from', 'the', 'slide', 'very', 'very', 'strong'], ['she', 'really', 'paved', 'the', 'way', 'at', 'a', 'time', 'when', 'nobody', 'was', 'doing', 'stunts', 'let', 'alone', 'women'], ['my', 'favorite', 'and', 'a', 'real', 'hero', 'of', 'mine', 'is', 'UnknownTK', 'UnknownTK'], ['UnknownTK', 'UnknownTK', 'really', 'formed', 'the', 'stunt', 'fight'], ['he', 'worked', 'with', 'john', 'wayne', 'and', 'most', 'of', 'those', 'old', 'punch', 'ups', 'you', 'see', 'in', 'the', 'UnknownTK'], ['UnknownTK', 'was', 'either', 'there', 'or', 'he', 'stunt', 'coordinated'], ['this', 'is', 'a', 'screen', 'capture', 'from', 'stagecoach', 'where', 'UnknownTK', 'UnknownTK', 'is', 'doing', 'one', 'of', 'the', 'most', 'dangerous', 'stunts', 'i', 've', 'ever', 'seen'], ['there', 'is', 'no', 'safety', 'no', 'back', 'support', 'no', 'pads', 'no', 'crash', 'mats', 'no', 'sand', 'pits', 'in', 'the', 'ground'], ['that', 's', 'one', 'of', 'the', 'most', 'dangerous', 'horse', 'stunts', 'certainly'], ['talking', 'of', 'dangerous', 'stunts', 'and', 'bringing', 'things', 'slightly', 'up', 'to', 'date', 'some', 'of', 'the', 'most', 'dangerous', 'stunts', 'we', 'do', 'as', 'stunt', 'people', 'are', 'fire', 'stunts'], ['we', 'couldn', 't', 'do', 'them', 'without', 'technology'], ['these', 'are', 'particularly', 'dangerous', 'because', 'there', 'is', 'no', 'mask', 'on', 'my', 'face'], ['they', 'were', 'done', 'for', 'a', 'photo', 'shoot'], ['one', 'for', 'the', 'sun', 'newspaper', 'one', 'for', 'UnknownTK', 'magazine'], ['highly', 'dangerous', 'but', 'also', 'you', 'll', 'notice', 'it', 'doesn', 't', 'look', 'as', 'though', 'i', 'm', 'wearing', 'anything', 'underneath', 'the', 'suit'], ['the', 'fire', 'suits', 'of', 'old', 'the', 'bulky', 'suits', 'the', 'thick', 'UnknownTK', 'suits', 'have', 'been', 'replaced', 'with', 'modern', 'materials', 'like', 'UnknownTK', 'or', 'more', 'recently', 'UnknownTK', 'fantastic', 'materials', 'that', 'enable', 'us', 'as', 'stunt', 'professionals', 'to', 'burn', 'for', 'longer', 'look', 'more', 'spectacular', 'and', 'in', 'pure', 'safety'], ['here', 's', 'a', 'bit', 'more'], ['there', 's', 'a', 'guy', 'with', 'a', 'flame', 'UnknownTK', 'there', 'giving', 'me', 'what', 'for'], ['one', 'of', 'the', 'things', 'that', 'a', 'stuntman', 'often', 'does', 'and', 'you', 'll', 'see', 'it', 'every', 'time', 'in', 'the', 'big', 'movies', 'is', 'be', 'blown', 'through', 'the', 'air'], ['well', 'we', 'used', 'to', 'use', 'UnknownTK'], ['in', 'the', 'old', 'days', 'that', 's', 'all', 'they', 'had'], ['and', 'that', 's', 'a', 'ramp'], ['spring', 'off', 'the', 'thing', 'and', 'fly', 'through', 'the', 'air', 'and', 'hopefully', 'you', 'make', 'it', 'look', 'good'], ['now', 'we', 've', 'got', 'technology'], ['this', 'thing', 'is', 'called', 'an', 'air', 'ram'], ['it', 's', 'a', 'frightening', 'piece', 'of', 'equipment', 'for', 'the', 'novice', 'stunt', 'performer', 'because', 'it', 'will', 'break', 'your', 'legs', 'very', 'very', 'quickly', 'if', 'you', 'land', 'on', 'it', 'wrong'], ['having', 'said', 'that', 'it', 'works', 'with', 'compressed', 'nitrogen'], ['and', 'that', 's', 'in', 'the', 'up', 'position'], ['when', 'you', 'step', 'on', 'it', 'either', 'by', 'remote', 'control', 'or', 'with', 'the', 'pressure', 'of', 'your', 'foot', 'it', 'will', 'fire', 'you', 'depending', 'on', 'the', 'gas', 'pressure', 'anything', 'from', 'five', 'feet', 'to', '30', 'feet'], ['i', 'could', 'quite', 'literally', 'fire', 'myself', 'into', 'the', 'gallery'], ['which', 'i', 'm', 'sure', 'you', 'wouldn', 't', 'want'], ['not', 'today'], ['car', 'stunts', 'are', 'another', 'area', 'where', 'technology', 'and', 'engineering', 'advances', 'have', 'made', 'life', 'easier', 'for', 'us', 'and', 'safer'], ['we', 'can', 'do', 'bigger', 'car', 'stunts', 'than', 'ever', 'before', 'now'], ['being', 'run', 'over', 'is', 'never', 'easy'], ['that', 's', 'an', 'old', 'fashioned', 'hard', 'gritty', 'physical', 'stunt'], ['but', 'we', 'have', 'padding', 'and', 'fantastic', 'shock', 'absorbing', 'things', 'like', 'UnknownTK', 'the', 'materials', 'that', 'help', 'us', 'when', 'we', 're', 'hit', 'like', 'this', 'not', 'to', 'hurt', 'ourselves', 'too', 'much'], ['the', 'picture', 'in', 'the', 'bottom', 'right', 'hand', 'corner', 'there', 'is', 'of', 'some', 'crash', 'test', 'dummy', 'work', 'that', 'i', 'was', 'doing'], ['showing', 'how', 'stunts', 'work', 'in', 'different', 'areas', 'really'], ['and', 'testing', 'breakaway', 'UnknownTK', 'pillars'], ['a', 'company', 'makes', 'a', 'UnknownTK', 'pillar', 'which', 'is', 'a', 'network', 'a', 'lattice', 'type', 'pillar', 'that', 'collapses', 'when', 'it', 's', 'hit'], ['the', 'car', 'on', 'the', 'left', 'drove', 'into', 'the', 'steel', 'pillar'], ['and', 'you', 'can', 't', 'see', 'it', 'from', 'there', 'but', 'the', 'engine', 'was', 'in', 'the', 'driver', 's', 'lap'], ['they', 'did', 'it', 'by', 'remote', 'control'], ['i', 'drove', 'the', 'other', 'one', 'at', '60', 'miles', 'an', 'hour', 'exactly', 'the', 'same', 'speed', 'and', 'clearly', 'walked', 'away', 'from', 'it'], ['rolling', 'a', 'car', 'over', 'is', 'another', 'area', 'where', 'we', 'use', 'technology'], ['we', 'used', 'to', 'have', 'to', 'drive', 'up', 'a', 'ramp', 'and', 'we', 'still', 'do', 'sometimes'], ['but', 'now', 'we', 'have', 'a', 'compressed', 'nitrogen', 'cannon'], ['you', 'can', 'just', 'see', 'underneath', 'the', 'car', 'there', 'is', 'a', 'black', 'rod', 'on', 'the', 'floor', 'by', 'the', 'wheel', 'of', 'the', 'other', 'car'], ['that', 's', 'the', 'piston', 'that', 'was', 'fired', 'out', 'of', 'the', 'floor'], ['we', 'can', 'flip', 'UnknownTK', 'coaches', 'buses', 'anything', 'over', 'with', 'a', 'nitrogen', 'cannon', 'with', 'enough', 'power'], ['it', 's', 'a', 'great', 'job', 'really'], ['it', 's', 'such', 'fun', 'you', 'should', 'hear', 'some', 'of', 'the', 'phone', 'conversations', 'that', 'i', 'have', 'with', 'people', 'on', 'my', 'bluetooth', 'in', 'the', 'shop'], ['well', 'we', 'can', 'flip', 'the', 'bus', 'over', 'we', 'can', 'have', 'it', 'burst', 'into', 'flames', 'and', 'how', 'about', 'someone', 'you', 'know', 'big', 'explosion'], ['and', 'people', 'are', 'looking', 'like', 'this'], ['i', 'sort', 'of', 'forget', 'how', 'bizarre', 'some', 'of', 'those', 'conversations', 'are'], ['the', 'next', 'thing', 'that', 'i', 'd', 'like', 'to', 'show', 'you', 'is', 'something', 'that', 'UnknownTK', 'asked', 'me', 'to', 'do', 'earlier', 'this', 'year', 'with', 'our', 'channel', 'five', 's', 'fifth', 'gear', 'show'], ['a', 'loop', 'the', 'loop', 'biggest', 'in', 'the', 'world'], ['only', 'one', 'person', 'had', 'ever', 'done', 'it', 'before'], ['now', 'the', 'stuntman', 'solution', 'to', 'this', 'in', 'the', 'old', 'days', 'would', 'be', 'let', 's', 'hit', 'this', 'as', 'fast', 'as', 'possible'], ['60', 'miles', 'an', 'hour'], ['let', 's', 'just', 'go', 'for', 'it'], ['foot', 'flat', 'to', 'the', 'floor'], ['well', 'you', 'd', 'die', 'if', 'you', 'did', 'that'], ['we', 'went', 'to', 'cambridge', 'university', 'the', 'other', 'university', 'and', 'spoke', 'to', 'a', 'doctor', 'of', 'mechanical', 'engineering', 'there', 'a', 'physicist', 'who', 'taught', 'us', 'that', 'it', 'had', 'to', 'be', '37', 'miles', 'an', 'hour'], ['even', 'then', 'i', 'caught', 'seven', 'g', 'and', 'lost', 'a', 'bit', 'of', 'consciousness', 'on', 'the', 'way', 'in'], ['that', 's', 'a', 'long', 'way', 'to', 'fall', 'if', 'you', 'get', 'it', 'wrong'], ['that', 'was', 'just', 'about', 'right'], ['so', 'again', 'science', 'helps', 'us', 'and', 'with', 'the', 'engineering', 'too', 'the', 'modifications', 'to', 'the', 'car', 'and', 'the', 'wheel'], ['high', 'falls', 'they', 're', 'old', 'fashioned', 'stunts'], ['what', 's', 'interesting', 'about', 'high', 'falls', 'is', 'that', 'although', 'we', 'use', 'airbags', 'and', 'some', 'airbags', 'are', 'quite', 'advanced', 'they', 're', 'designed', 'so', 'you', 'don', 't', 'slip', 'off', 'the', 'side', 'like', 'you', 'used', 'to', 'if', 'you', 'land', 'a', 'bit', 'wrong'], ['so', 'they', 're', 'a', 'much', 'safer', 'proposition'], ['just', 'basically', 'though', 'it', 'is', 'a', 'basic', 'piece', 'of', 'equipment'], ['it', 's', 'a', 'bouncy', 'castle', 'with', 'slats', 'in', 'the', 'side', 'to', 'allow', 'the', 'air', 'to', 'escape'], ['that', 's', 'all', 'it', 'is', 'a', 'bouncy', 'castle'], ['that', 's', 'the', 'only', 'reason', 'we', 'do', 'it'], ['see', 'it', 's', 'all', 'fun', 'this', 'job'], ['what', 's', 'interesting', 'is', 'we', 'still', 'use', 'cardboard', 'boxes'], ['they', 'used', 'to', 'use', 'cardboard', 'boxes', 'years', 'ago', 'and', 'we', 'still', 'use', 'them'], ['and', 'that', 's', 'interesting', 'because', 'they', 'are', 'almost', 'retrospective'], ['they', 're', 'great', 'for', 'catching', 'you', 'up', 'to', 'certain', 'heights'], ['and', 'on', 'the', 'other', 'side', 'of', 'the', 'fence', 'that', 'physical', 'art', 'the', 'physical', 'performance', 'of', 'the', 'stuntman', 'has', 'interfaced', 'with', 'the', 'very', 'highest', 'technology', 'in', 'i'], ['t'], ['and', 'in', 'software'], ['not', 'the', 'cardboard', 'box', 'but', 'the', 'green', 'screen'], ['this', 'is', 'a', 'shot', 'of', 'terminator', 'the', 'movie'], ['two', 'stunt', 'guys', 'doing', 'what', 'i', 'consider', 'to', 'be', 'a', 'rather', 'benign', 'stunt'], ['it', 's', '30', 'feet'], ['it', 's', 'water'], ['it', 's', 'very', 'simple'], ['with', 'the', 'green', 'screen', 'we', 'can', 'put', 'any', 'background', 'in', 'the', 'world', 'on', 'it', 'moving', 'or', 'still', 'and', 'i', 'can', 'assure', 'you', 'nowadays', 'you', 'can', 't', 'see', 'the', 'joint'], ['this', 'is', 'a', 'UnknownTK', 'with', 'another', 'UnknownTK', 'doing', 'exactly', 'the', 'same', 'thing'], ['completely', 'in', 'the', 'safety', 'of', 'a', 'studio', 'and', 'yet', 'with', 'the', 'green', 'screen', 'we', 'can', 'have', 'some', 'moving', 'image', 'that', 'a', 'UnknownTK', 'took', 'and', 'put', 'in', 'the', 'sky', 'moving', 'and', 'the', 'clouds', 'whizzing', 'by'], ['UnknownTK', 'rigs', 'and', 'wires', 'we', 'use', 'them', 'a', 'lot'], ['we', 'fly', 'people', 'on', 'wires', 'like', 'this'], ['this', 'guy', 'is', 'not', 'skydiving'], ['he', 's', 'being', 'flown', 'like', 'a', 'kite', 'or', 'moved', 'around', 'like', 'a', 'kite'], ['and', 'this', 'is', 'a', 'guinness', 'world', 'record', 'attempt'], ['they', 'asked', 'me', 'to', 'open', 'their', '50th', 'anniversary', 'show', 'in', '2004'], ['and', 'again', 'technology', 'meant', 'that', 'i', 'could', 'do', 'the', 'fastest', 'UnknownTK', 'over', '100', 'meters', 'and', 'stop', 'within', 'a', 'couple', 'of', 'feet', 'of', 'the', 'ground', 'without', 'melting', 'the', 'rope', 'with', 'the', 'friction', 'because', 'of', 'the', 'UnknownTK', 'i', 'used', 'in', 'the', 'UnknownTK', 'device'], ['and', 'that', 's', 'centre', 'point', 'in', 'london'], ['we', 'brought', 'oxford', 'street', 'and', 'UnknownTK', 'court', 'road', 'to', 'a', 'standstill'], ['helicopter', 'stunts', 'are', 'always', 'fun', 'hanging', 'out', 'of', 'them', 'whatever'], ['and', 'aerial', 'stunts'], ['no', 'aerial', 'stunt', 'would', 'be', 'the', 'same', 'without', 'skydiving'], ['which', 'brings', 'us', 'quite', 'nicely', 'to', 'why', 'i', 'm', 'really', 'here', 'today', 'project', 'space', 'jump'], ['in', '1960', 'joseph', 'UnknownTK', 'of', 'the', 'united', 'states', 'air', 'force', 'did', 'the', 'most', 'spectacular', 'thing'], ['he', 'did', 'a', 'jump', 'from', '100', '000', 'feet', '102', '000', 'to', 'be', 'precise', 'and', 'he', 'did', 'it', 'to', 'test', 'high', 'altitude', 'systems', 'for', 'military', 'pilots', 'in', 'the', 'new', 'range', 'of', 'aircraft', 'that', 'were', 'going', 'up', 'to', '80', '000', 'feet', 'or', 'so'], ['and', 'i', 'd', 'just', 'like', 'to', 'show', 'you', 'a', 'little', 'footage', 'of', 'what', 'he', 'did', 'back', 'then'], ['and', 'just', 'how', 'brave', 'he', 'was', 'in', '1960', 'bear', 'in', 'mind'], ['project', 'UnknownTK', 'it', 'was', 'called'], ['there', 'were', 'three', 'jumps'], ['they', 'first', 'dropped', 'some', 'dummies'], ['so', 'that', 's', 'the', 'balloon', 'big', 'gas', 'balloon'], ['it', 's', 'that', 'shape', 'because', 'the', 'helium', 'has', 'to', 'expand'], ['my', 'balloon', 'will', 'expand', 'to', '500', 'times', 'and', 'look', 'like', 'a', 'big', 'pumpkin', 'when', 'it', 's', 'at', 'the', 'top'], ['these', 'are', 'the', 'dummies', 'being', 'dropped', 'from', '100', '000', 'feet', 'and', 'there', 'is', 'the', 'camera', 'that', 's', 'strapped', 'to', 'them'], ['you', 'can', 'clearly', 'see', 'the', 'curvature', 'of', 'the', 'earth', 'at', 'that', 'kind', 'of', 'altitude'], ['and', 'i', 'm', 'planning', 'to', 'go', 'from', '120', '000', 'feet', 'which', 'is', 'about', '22', 'miles'], ['you', 're', 'in', 'a', 'near', 'vacuum', 'in', 'that', 'environment', 'which', 'is', 'in', 'minus', '50', 'degrees'], ['so', 'it', 's', 'an', 'extremely', 'hostile', 'place', 'to', 'be'], ['this', 'is', 'joe', 'UnknownTK', 'himself'], ['bear', 'in', 'mind', 'ladies', 'and', 'gents', 'this', 'was', '1960'], ['he', 'didn', 't', 'know', 'if', 'he', 'would', 'live', 'or', 'die'], ['this', 'is', 'an', 'extremely', 'brave', 'man'], ['i', 'spoke', 'with', 'him', 'on', 'the', 'phone', 'a', 'few', 'months', 'ago'], ['he', 's', 'a', 'very', 'humble', 'and', 'wonderful', 'human', 'being'], ['he', 'sent', 'me', 'an', 'email', 'saying', 'if', 'you', 'get', 'this', 'thing', 'off', 'the', 'ground', 'i', 'wish', 'you', 'all', 'the', 'best'], ['and', 'he', 'signed', 'it', 'happy', 'landings', 'which', 'i', 'thought', 'was', 'quite', 'lovely'], ['he', 's', 'in', 'his', '80s', 'and', 'he', 'lives', 'in', 'florida'], ['he', 's', 'a', 'tremendous', 'guy'], ['this', 'is', 'him', 'in', 'a', 'pressure', 'suit'], ['now', 'one', 'of', 'the', 'challenges', 'of', 'going', 'up', 'to', 'altitude', 'is', 'when', 'you', 'get', 'to', '30', '000', 'feet', 'it', 's', 'great', 'isn', 't', 'it', 'when', 'you', 'get', 'to', '30', '000', 'feet', 'you', 'can', 'really', 'only', 'use', 'oxygen'], ['above', '30', '000', 'feet', 'up', 'to', 'nearly', '50', '000', 'feet', 'you', 'need', 'pressure', 'breathing', 'which', 'is', 'where', 'you', 're', 'wearing', 'a', 'g', 'suit'], ['this', 'is', 'him', 'in', 'his', 'old', 'rock', 'and', 'roll', 'jeans', 'there', 'pushing', 'him', 'in', 'those', 'turned', 'up', 'jeans'], ['you', 'need', 'a', 'pressure', 'suit'], ['you', 'need', 'a', 'pressure', 'breathing', 'system', 'with', 'a', 'g', 'suit', 'that', 'squeezes', 'you', 'that', 'helps', 'you', 'to', 'breathe', 'in', 'and', 'helps', 'you', 'to', 'exhale'], ['above', '50', '000', 'feet', 'you', 'need', 'a', 'space', 'suit', 'a', 'pressure', 'suit'], ['certainly', 'at', '100', '000', 'feet', 'no', 'aircraft', 'will', 'fly'], ['not', 'even', 'a', 'jet', 'engine'], ['it', 'needs', 'to', 'be', 'rocket', 'powered', 'or', 'one', 'of', 'these', 'things', 'a', 'great', 'big', 'gas', 'balloon'], ['it', 'took', 'me', 'a', 'while', 'it', 'took', 'me', 'years', 'to', 'find', 'the', 'right', 'balloon', 'team', 'to', 'build', 'the', 'balloon', 'that', 'would', 'do', 'this', 'job'], ['i', 've', 'found', 'that', 'team', 'in', 'america', 'now'], ['and', 'it', 's', 'made', 'of', 'polyethylene', 'so', 'it', 's', 'very', 'thin'], ['we', 'will', 'have', 'two', 'balloons', 'for', 'each', 'of', 'my', 'test', 'jumps', 'and', 'two', 'balloons', 'for', 'the', 'main', 'jump', 'because', 'they', 'notoriously', 'tear', 'on', 'takeoff'], ['they', 're', 'just', 'so', 'so', 'delicate'], ['this', 'is', 'the', 'step', 'off'], ['he', 's', 'written', 'on', 'that', 'thing', 'the', 'highest', 'step', 'in', 'the', 'world'], ['and', 'what', 'must', 'that', 'feel', 'like', 'i', 'm', 'excited', 'and', 'i', 'm', 'scared', 'both', 'at', 'the', 'same', 'time', 'in', 'equal', 'measures'], ['and', 'this', 'is', 'the', 'camera', 'that', 'he', 'had', 'on', 'him', 'as', 'he', 'tumbled', 'before', 'his', 'drogue', 'chute', 'opened', 'to', 'stabilize', 'him'], ['a', 'drogue', 'chute', 'is', 'just', 'a', 'smaller', 'chute', 'which', 'helps', 'to', 'keep', 'your', 'face', 'down'], ['you', 'can', 'just', 'see', 'them', 'there', 'popping', 'open'], ['those', 'are', 'the', 'drogue', 'chutes'], ['he', 'had', 'three', 'of', 'them'], ['i', 'did', 'quite', 'a', 'lot', 'of', 'research'], ['and', 'you', 'll', 'see', 'in', 'a', 'second', 'there', 'he', 'comes', 'back', 'down', 'to', 'the', 'floor'], ['now', 'just', 'to', 'give', 'you', 'some', 'perspective', 'of', 'this', 'balloon', 'the', 'little', 'black', 'dots', 'are', 'people'], ['it', 's', 'hundreds', 'of', 'feet', 'high'], ['it', 's', 'enormous'], ['that', 's', 'in', 'new', 'mexico'], ['that', 's', 'the', 'u'], ['s'], ['air', 'force', 'museum'], ['and', 'they', 've', 'made', 'a', 'dummy', 'of', 'him'], ['that', 's', 'exactly', 'what', 'it', 'looked', 'like'], ['my', 'gondola', 'will', 'be', 'more', 'simple', 'than', 'that'], ['it', 's', 'a', 'three', 'sided', 'box', 'basically'], ['so', 'i', 've', 'had', 'to', 'do', 'quite', 'a', 'lot', 'of', 'training'], ['this', 'is', 'morocco', 'last', 'year', 'in', 'the', 'atlas', 'mountains', 'training', 'in', 'preparation', 'for', 'some', 'high', 'altitude', 'jumps'], ['this', 'is', 'what', 'the', 'view', 'is', 'going', 'to', 'be', 'like', 'at', '90', '000', 'feet', 'for', 'me'], ['now', 'you', 'may', 'think', 'this', 'is', 'just', 'a', 'thrill', 'seeking', 'trip', 'a', 'pleasure', 'ride', 'just', 'the', 'world', 's', 'biggest', 'stunt'], ['well', 'there', 's', 'a', 'little', 'bit', 'more', 'to', 'it', 'than', 'that'], ['trying', 'to', 'find', 'a', 'space', 'suit', 'to', 'do', 'this', 'has', 'led', 'me', 'to', 'an', 'area', 'of', 'technology', 'that', 'i', 'never', 'really', 'expected', 'when', 'i', 'set', 'about', 'doing', 'this'], ['i', 'contacted', 'a', 'company', 'in', 'the', 'states', 'who', 'make', 'suits', 'for', 'nasa'], ['that', 's', 'a', 'current', 'suit'], ['this', 'was', 'me', 'last', 'year', 'with', 'their', 'chief', 'engineer'], ['that', 'suit', 'would', 'cost', 'me', 'about', 'a', 'million', 'and', 'a', 'half', 'dollars'], ['and', 'it', 'weighs', '300', 'pounds', 'and', 'you', 'can', 't', 'UnknownTK', 'in', 'it'], ['so', 'i', 've', 'been', 'stuck'], ['for', 'the', 'past', '15', 'years', 'i', 've', 'been', 'trying', 'to', 'find', 'a', 'space', 'suit', 'that', 'would', 'do', 'this', 'job', 'or', 'someone', 'that', 'will', 'make', 'one'], ['something', 'revolutionary', 'happened', 'a', 'little', 'while', 'ago', 'at', 'the', 'same', 'facility'], ['that', 's', 'the', 'prototype', 'of', 'the', 'parachute'], ['i', 've', 'now', 'had', 'them', 'custom', 'make', 'one', 'the', 'only', 'one', 'of', 'its', 'kind', 'in', 'the', 'world'], ['and', 'that', 's', 'the', 'only', 'suit', 'of', 'its', 'kind', 'in', 'the', 'world'], ['it', 'was', 'made', 'by', 'a', 'russian', 'that', 's', 'designed', 'most', 'of', 'the', 'suits', 'of', 'the', 'past', '18', 'years', 'for', 'the', 'soviets'], ['he', 'left', 'the', 'company', 'because', 'he', 'saw', 'as', 'some', 'other', 'people', 'in', 'the', 'space', 'suit', 'industry', 'an', 'emerging', 'market', 'for', 'space', 'suits', 'for', 'space', 'tourists'], ['you', 'know', 'if', 'you', 'are', 'in', 'an', 'aircraft', 'at', '30', '000', 'feet', 'and', 'the', 'cabin', 'UnknownTK', 'you', 'can', 'have', 'oxygen'], ['if', 'you', 're', 'at', '100', '000', 'feet', 'you', 'die'], ['in', 'six', 'seconds', 'you', 've', 'lost', 'consciousness'], ['in', '10', 'seconds', 'you', 're', 'dead'], ['your', 'blood', 'tries', 'to', 'boil'], ['it', 's', 'called', 'UnknownTK'], ['the', 'body', 'swells', 'up'], ['it', 's', 'awful'], ['and', 'so', 'we', 'expect', 'it', 's', 'not', 'much', 'fun'], ['we', 'expect', 'and', 'others', 'expect', 'that', 'perhaps', 'the', 'faa', 'the', 'UnknownTK', 'might', 'say', 'you', 'need', 'to', 'put', 'someone', 'in', 'a', 'suit', 'that', 's', 'not', 'inflated', 'that', 's', 'connected', 'to', 'the', 'aircraft'], ['then', 'they', 're', 'comfortable', 'they', 'have', 'good', 'vision', 'like', 'this', 'great', 'big', 'visor'], ['and', 'then', 'if', 'the', 'cabin', 'UnknownTK', 'while', 'the', 'aircraft', 'is', 'coming', 'back', 'down', 'in', 'whatever', 'emergency', 'measures', 'everyone', 'is', 'okay'], ['i', 'would', 'like', 'to', 'bring', 'costa', 'on', 'if', 'he', 's', 'here', 'to', 'show', 'you', 'the', 'only', 'one', 'of', 'its', 'kind', 'in', 'the', 'world'], ['i', 'was', 'going', 'to', 'wear', 'it', 'but', 'i', 'thought', 'i', 'd', 'get', 'costa', 'to', 'do', 'it', 'my', 'lovely', 'assistant'], ['thank', 'you'], ['he', 's', 'very', 'hot'], ['thank', 'you', 'costa'], ['this', 'is', 'the', 'communication', 'headset', 'you', 'll', 'see', 'on', 'lots', 'of', 'space', 'suits'], ['it', 's', 'a', 'two', 'layer', 'suit'], ['nasa', 'suits', 'have', 'got', '13', 'layers'], ['this', 'is', 'a', 'very', 'lightweight', 'suit'], ['it', 'weighs', 'about', '15', 'pounds'], ['it', 's', 'next', 'to', 'nothing'], ['especially', 'designed', 'for', 'me'], ['it', 's', 'a', 'working', 'prototype'], ['i', 'will', 'use', 'it', 'for', 'all', 'the', 'jumps'], ['would', 'you', 'just', 'give', 'us', 'a', 'little', 'twirl', 'please', 'costa', 'thank', 'you', 'very', 'much'], ['and', 'it', 'doesn', 't', 'look', 'far', 'different', 'when', 'it', 's', 'inflated', 'as', 'you', 'can', 'see', 'from', 'the', 'picture', 'down', 'there'], ['i', 've', 'even', 'UnknownTK', 'in', 'it', 'in', 'a', 'wind', 'tunnel', 'which', 'means', 'that', 'i', 'can', 'practice', 'everything', 'i', 'need', 'to', 'practice', 'in', 'safety', 'before', 'i', 'ever', 'jump', 'out', 'of', 'anything'], ['thanks', 'very', 'much', 'costa'], ['ladies', 'and', 'gentlemen', 'that', 's', 'just', 'about', 'it', 'from', 'me'], ['the', 'status', 'of', 'my', 'mission', 'at', 'the', 'moment', 'is', 'it', 'still', 'needs', 'a', 'major', 'sponsor'], ['i', 'm', 'confident', 'that', 'we', 'll', 'find', 'one'], ['i', 'think', 'it', 's', 'a', 'great', 'challenge'], ['and', 'i', 'hope', 'that', 'you', 'will', 'agree', 'with', 'me', 'it', 'is', 'the', 'greatest', 'stunt', 'on', 'earth'], ['thank', 'you', 'very', 'much', 'for', 'your', 'time']], 4)\n"
     ]
    }
   ],
   "source": [
    "print(valid_doc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([['i', 'had', 'a', 'fire', 'nine', 'days', 'ago'], ['my', 'archive', '175', 'films', 'my', '16', 'millimeter', 'negative', 'all', 'my', 'books', 'my', 'dad', 's', 'books', 'my', 'photographs'], ['i', 'd', 'collected', 'i', 'was', 'a', 'collector', 'major', 'big', 'time'], ['it', 's', 'gone'], ['i', 'just', 'looked', 'at', 'it', 'and', 'i', 'didn', 't', 'know', 'what', 'to', 'do'], ['i', 'mean', 'this', 'was', 'was', 'i', 'my', 'things', 'i', 'always', 'live', 'in', 'the', 'present', 'i', 'love', 'the', 'present'], ['i', 'cherish', 'the', 'future'], ['and', 'i', 'was', 'taught', 'some', 'strange', 'thing', 'as', 'a', 'kid', 'like', 'you', 've', 'got', 'to', 'make', 'something', 'good', 'out', 'of', 'something', 'bad'], ['you', 've', 'got', 'to', 'make', 'something', 'good', 'out', 'of', 'something', 'bad'], ['this', 'was', 'bad', 'man', 'i', 'was', 'i', 'cough'], ['i', 'was', 'sick'], ['that', 's', 'my', 'camera', 'lens'], ['the', 'first', 'one', 'the', 'one', 'i', 'shot', 'my', 'bob', 'dylan', 'film', 'with', '35', 'years', 'ago'], ['that', 's', 'my', 'feature', 'film'], ['king', 'murray', 'won', 'cannes', 'film', 'festival', '1970', 'the', 'only', 'print', 'i', 'had'], ['that', 's', 'my', 'papers'], ['that', 'was', 'in', 'minutes', '20', 'minutes'], ['epiphany', 'hit', 'me'], ['something', 'hit', 'me'], ['you', 've', 'got', 'to', 'make', 'something', 'good', 'out', 'of', 'something', 'bad', 'i', 'started', 'to', 'say', 'to', 'my', 'friends', 'neighbors', 'my', 'sister'], ['by', 'the', 'way', 'that', 's', 'sputnik'], ['i', 'ran', 'it', 'last', 'year'], ['sputnik', 'was', 'downtown', 'the', 'negative'], ['it', 'wasn', 't', 'touched'], ['these', 'are', 'some', 'pieces', 'of', 'things', 'i', 'used', 'in', 'my', 'sputnik', 'feature', 'film', 'which', 'opens', 'in', 'new', 'york', 'in', 'two', 'weeks', 'downtown'], ['i', 'called', 'my', 'sister'], ['i', 'called', 'my', 'neighbors'], ['i', 'said', 'come', 'dig'], ['that', 's', 'me', 'at', 'my', 'desk'], ['that', 'was', 'a', 'desk', 'took', '40', 'some', 'years', 'to', 'build'], ['you', 'know', 'all', 'the', 'stuff'], ['that', 's', 'my', 'daughter', 'jean'], ['she', 'came'], ['she', 's', 'a', 'nurse', 'in', 'san', 'francisco'], ['dig', 'it', 'up', 'i', 'said'], ['pieces'], ['i', 'want', 'pieces'], ['bits', 'and', 'pieces'], ['i', 'came', 'up', 'with', 'this', 'idea', 'a', 'life', 'of', 'bits', 'and', 'pieces', 'which', 'i', 'm', 'just', 'starting', 'to', 'work', 'on', 'my', 'next', 'project'], ['that', 's', 'my', 'sister'], ['she', 'took', 'care', 'of', 'pictures', 'because', 'i', 'was', 'a', 'big', 'collector', 'of', 'snapshot', 'photography', 'that', 'i', 'believed', 'said', 'a', 'lot'], ['and', 'those', 'are', 'some', 'of', 'the', 'pictures', 'that', 'something', 'was', 'good', 'about', 'the', 'burnt', 'pictures'], ['i', 'didn', 't', 'know'], ['i', 'looked', 'at', 'that', 'i', 'said', 'wow', 'is', 'that', 'better', 'than', 'the', 'that', 's', 'my', 'proposal', 'on', 'jimmy', 'UnknownTK'], ['i', 'made', 'that', 'movie', 'for', 'television'], ['it', 's', 'the', 'only', 'copy', 'i', 'had'], ['pieces', 'of', 'it'], ['idea', 'about', 'women'], ['so', 'i', 'started', 'to', 'say', 'hey', 'man', 'you', 'are', 'too', 'much', 'you', 'could', 'cry', 'about', 'this'], ['i', 'really', 'didn', 't'], ['i', 'just', 'instead', 'said', 'i', 'm', 'going', 'to', 'make', 'something', 'out', 'of', 'it', 'and', 'maybe', 'next', 'year'], ['and', 'i', 'appreciate', 'this', 'moment', 'to', 'come', 'up', 'on', 'this', 'stage', 'with', 'so', 'many', 'people', 'who', 've', 'already', 'given', 'me', 'so', 'much', 'solace', 'and', 'just', 'say', 'to', 'tedsters', 'i', 'm', 'proud', 'of', 'me'], ['that', 'i', 'take', 'something', 'bad', 'i', 'turn', 'it', 'and', 'i', 'm', 'going', 'to', 'make', 'something', 'good', 'out', 'of', 'this', 'all', 'these', 'pieces'], ['that', 's', 'arthur', 'leipzig', 's', 'original', 'photograph', 'i', 'loved'], ['i', 'was', 'a', 'big', 'record', 'collector', 'the', 'records', 'didn', 't', 'make', 'it'], ['boy', 'i', 'tell', 'you', 'film', 'burns'], ['film', 'burns'], ['i', 'mean', 'this', 'was', '16', 'millimeter', 'safety', 'film'], ['the', 'negatives', 'are', 'gone'], ['that', 's', 'my', 'father', 's', 'letter', 'to', 'me', 'telling', 'me', 'to', 'marry', 'the', 'woman', 'i', 'first', 'married', 'when', 'i', 'was', '20'], ['that', 's', 'my', 'daughter', 'and', 'me'], ['she', 's', 'still', 'there'], ['she', 's', 'there', 'this', 'morning', 'actually'], ['that', 's', 'my', 'house'], ['my', 'family', 's', 'living', 'in', 'the', 'hilton', 'hotel', 'in', 'UnknownTK', 'valley'], ['that', 's', 'my', 'wife', 'heidi', 'who', 'didn', 't', 'take', 'it', 'as', 'well', 'as', 'i', 'did'], ['my', 'children', 'UnknownTK', 'and', 'henry'], ['my', 'son', 'UnknownTK', 'in', 'the', 'hotel', 'two', 'nights', 'ago'], ['so', 'my', 'message', 'to', 'you', 'folks', 'from', 'my', 'three', 'minutes', 'is', 'that', 'i', 'appreciate', 'the', 'chance', 'to', 'share', 'this', 'with', 'you'], ['i', 'will', 'be', 'back'], ['i', 'love', 'being', 'at', 'ted'], ['i', 'came', 'to', 'live', 'it', 'and', 'i', 'am', 'living', 'it'], ['that', 's', 'my', 'view', 'from', 'my', 'window', 'outside', 'of', 'santa', 'cruz', 'in', 'UnknownTK', 'UnknownTK', 'just', '35', 'miles', 'from', 'here'], ['thank', 'you', 'everybody']], 0)\n"
     ]
    }
   ],
   "source": [
    "print(test_doc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag of Means "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def embed_text(model, text):\n",
    "    \"\"\" embed the input text as a model vector \n",
    "    \n",
    "    Arguments:\n",
    "        model: Word2Vec model.\n",
    "        text: input text\n",
    "    \n",
    "    Outputs:\n",
    "        embedded vector \n",
    "    \"\"\"\n",
    "    vector_list = [model.wv[word] for sent in text for word in sent]\n",
    "    return sum(vector_list) / len(vector_list)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100,)\n",
      "[ 0.61317599  0.13318765  0.877092    0.30233732  0.50376517  0.04399596\n",
      " -0.08663318 -0.29708579  0.69379228  0.10649608 -0.01964743  0.54565632\n",
      "  0.36889261 -0.32808724  0.20847213 -0.24323185  0.07905903 -0.09735632\n",
      " -0.1074714  -0.13894127  0.41548389  0.45580539  0.04107737  0.11766125\n",
      " -0.16154069  0.333588   -0.02465178  0.18323582  0.3343983   0.4087621\n",
      " -0.1403546   0.34203297 -0.16795711  0.20591733  0.14874336 -0.00501728\n",
      " -0.34611276 -0.30757073  0.300657    0.66527104  0.43257919  0.35578319\n",
      "  0.13519806  0.0440546   0.11838242 -0.35892734  0.13887228 -0.3578656\n",
      "  0.26338345  0.67413014  0.27571344  0.07908486 -0.19135548  0.11566199\n",
      " -0.47183725 -0.15311864 -0.57623869 -0.2464835  -0.13866121  0.28344458\n",
      "  0.38064057  0.271348   -0.4831897   0.31397161 -0.31131256 -0.74351436\n",
      "  0.18034452  0.20382388 -0.21868213  0.49019992 -0.27636632  0.2451379\n",
      "  0.11290224  0.14161813  0.04779363  0.03962253 -0.26890409  0.31561318\n",
      "  0.06359278 -0.53328043  0.68259364 -0.07118181  0.3900525   1.06583881\n",
      "  0.2435196  -1.03466117 -0.2957333   0.30082992 -0.13569207 -0.46230972\n",
      "  0.14959934 -0.30477005 -0.0568489   0.22414809  0.01772393 -0.31880659\n",
      " -0.29290688 -0.16908757  0.64099133 -0.4423787 ]\n"
     ]
    }
   ],
   "source": [
    "test_bom = embed_text(model, train_doc[0][0])\n",
    "print(test_bom.shape)\n",
    "print(test_bom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def embed_corpus(model, corpus):\n",
    "    return np.asarray([embed_text(model, doc[0]) for doc in corpus])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_doc_embedded = embed_corpus(model, train_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1579, 100)\n",
      "[ 0.4802019   0.07306197  0.76076442  0.265679    0.65074688 -0.13978228\n",
      " -0.05084927 -0.55925024  0.7502864   0.10501765  0.0969109   0.55776674\n",
      "  0.47652876 -0.11450881  0.07318046 -0.35512263 -0.04953027 -0.09045479\n",
      " -0.02341042 -0.23051201  0.43806779  0.17775384  0.2505416   0.17436594\n",
      "  0.04472227  0.20244192 -0.07194624  0.1739772   0.22243074  0.13083898\n",
      " -0.23973735  0.36757773 -0.03951558  0.18183237 -0.09743074  0.00374067\n",
      " -0.20940034 -0.46842694  0.24585925  0.71721613  0.3955411   0.33265039\n",
      "  0.16678037  0.03051815 -0.09335352 -0.45025772  0.18648751 -0.37605691\n",
      "  0.23591815  0.50330418  0.18871799  0.13318273 -0.03405144 -0.0985103\n",
      " -0.25906378 -0.11956112 -0.49184349 -0.24498062 -0.12874043  0.18451999\n",
      "  0.30606422  0.39163041 -0.48322365  0.17247336 -0.29539114 -0.55813003\n",
      " -0.0102161   0.22323622 -0.38711059  0.44130534 -0.45928118  0.17236429\n",
      "  0.14857092  0.0618463   0.15777689  0.04661241 -0.23681085  0.37428489\n",
      " -0.08256655 -0.43527746  0.78743666 -0.19866216  0.342666    1.07764053\n",
      "  0.40093002 -0.87844914 -0.36614326  0.2326768   0.02319716 -0.37752286\n",
      "  0.16423868 -0.1847028  -0.03455824  0.19869168 -0.1241148  -0.24102843\n",
      " -0.28810892 -0.23957846  0.57708287 -0.41351196]\n"
     ]
    }
   ],
   "source": [
    "print(train_doc_embedded.shape)\n",
    "print(train_doc_embedded[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def encode_label(label, size):\n",
    "    l = [0]*size\n",
    "    l[label] = 1\n",
    "    return l\n",
    "\n",
    "def encode_class(corpus, size):\n",
    "    return np.asarray([encode_label(doc[1], size) for doc in corpus])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 1, 0, 0, 0, 0, 0]\n",
      "[[1 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0]\n",
      " [0 0 0 1 0 0 0 0]\n",
      " [0 0 0 0 0 1 0 0]]\n"
     ]
    }
   ],
   "source": [
    "print(encode_label(2, 8))\n",
    "print(encode_class(train_doc[:5], 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedded_with_class(model, doc, size):\n",
    "    doc_x = embed_corpus(model, doc)\n",
    "    doc_y = encode_class(doc, size)\n",
    "    return doc_x, doc_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([[ 0.61317599,  0.13318765,  0.877092  ,  0.30233732,  0.50376517,\n",
      "         0.04399596, -0.08663318, -0.29708579,  0.69379228,  0.10649608,\n",
      "        -0.01964743,  0.54565632,  0.36889261, -0.32808724,  0.20847213,\n",
      "        -0.24323185,  0.07905903, -0.09735632, -0.1074714 , -0.13894127,\n",
      "         0.41548389,  0.45580539,  0.04107737,  0.11766125, -0.16154069,\n",
      "         0.333588  , -0.02465178,  0.18323582,  0.3343983 ,  0.4087621 ,\n",
      "        -0.1403546 ,  0.34203297, -0.16795711,  0.20591733,  0.14874336,\n",
      "        -0.00501728, -0.34611276, -0.30757073,  0.300657  ,  0.66527104,\n",
      "         0.43257919,  0.35578319,  0.13519806,  0.0440546 ,  0.11838242,\n",
      "        -0.35892734,  0.13887228, -0.3578656 ,  0.26338345,  0.67413014,\n",
      "         0.27571344,  0.07908486, -0.19135548,  0.11566199, -0.47183725,\n",
      "        -0.15311864, -0.57623869, -0.2464835 , -0.13866121,  0.28344458,\n",
      "         0.38064057,  0.271348  , -0.4831897 ,  0.31397161, -0.31131256,\n",
      "        -0.74351436,  0.18034452,  0.20382388, -0.21868213,  0.49019992,\n",
      "        -0.27636632,  0.2451379 ,  0.11290224,  0.14161813,  0.04779363,\n",
      "         0.03962253, -0.26890409,  0.31561318,  0.06359278, -0.53328043,\n",
      "         0.68259364, -0.07118181,  0.3900525 ,  1.06583881,  0.2435196 ,\n",
      "        -1.03466117, -0.2957333 ,  0.30082992, -0.13569207, -0.46230972,\n",
      "         0.14959934, -0.30477005, -0.0568489 ,  0.22414809,  0.01772393,\n",
      "        -0.31880659, -0.29290688, -0.16908757,  0.64099133, -0.4423787 ],\n",
      "       [ 0.4802019 ,  0.07306197,  0.76076442,  0.265679  ,  0.65074688,\n",
      "        -0.13978228, -0.05084927, -0.55925024,  0.7502864 ,  0.10501765,\n",
      "         0.0969109 ,  0.55776674,  0.47652876, -0.11450881,  0.07318046,\n",
      "        -0.35512263, -0.04953027, -0.09045479, -0.02341042, -0.23051201,\n",
      "         0.43806779,  0.17775384,  0.2505416 ,  0.17436594,  0.04472227,\n",
      "         0.20244192, -0.07194624,  0.1739772 ,  0.22243074,  0.13083898,\n",
      "        -0.23973735,  0.36757773, -0.03951558,  0.18183237, -0.09743074,\n",
      "         0.00374067, -0.20940034, -0.46842694,  0.24585925,  0.71721613,\n",
      "         0.3955411 ,  0.33265039,  0.16678037,  0.03051815, -0.09335352,\n",
      "        -0.45025772,  0.18648751, -0.37605691,  0.23591815,  0.50330418,\n",
      "         0.18871799,  0.13318273, -0.03405144, -0.0985103 , -0.25906378,\n",
      "        -0.11956112, -0.49184349, -0.24498062, -0.12874043,  0.18451999,\n",
      "         0.30606422,  0.39163041, -0.48322365,  0.17247336, -0.29539114,\n",
      "        -0.55813003, -0.0102161 ,  0.22323622, -0.38711059,  0.44130534,\n",
      "        -0.45928118,  0.17236429,  0.14857092,  0.0618463 ,  0.15777689,\n",
      "         0.04661241, -0.23681085,  0.37428489, -0.08256655, -0.43527746,\n",
      "         0.78743666, -0.19866216,  0.342666  ,  1.07764053,  0.40093002,\n",
      "        -0.87844914, -0.36614326,  0.2326768 ,  0.02319716, -0.37752286,\n",
      "         0.16423868, -0.1847028 , -0.03455824,  0.19869168, -0.1241148 ,\n",
      "        -0.24102843, -0.28810892, -0.23957846,  0.57708287, -0.41351196],\n",
      "       [ 0.56784266, -0.03369169,  0.87067646,  0.28770992,  0.48140737,\n",
      "         0.07183719, -0.16212113, -0.33635968,  0.65838468,  0.19739625,\n",
      "         0.14740387,  0.53340602,  0.32432252, -0.28570414,  0.15646064,\n",
      "        -0.18126126,  0.01500085, -0.01550249, -0.02406458, -0.10285675,\n",
      "         0.37288973,  0.37276605,  0.17142642,  0.17335655, -0.08948126,\n",
      "         0.11093854, -0.1023456 ,  0.19505531,  0.2813327 ,  0.28676876,\n",
      "        -0.17835031,  0.3415769 , -0.12347327,  0.26780102,  0.08047664,\n",
      "         0.09122863, -0.27255738, -0.27005535,  0.22761105,  0.61300451,\n",
      "         0.30829921,  0.36530074,  0.07277932,  0.13362518,  0.09992354,\n",
      "        -0.33652204, -0.01607254, -0.42045707,  0.23537734,  0.65276092,\n",
      "         0.29725316,  0.06515066, -0.2914035 ,  0.0960599 , -0.46407911,\n",
      "        -0.13039982, -0.45922446, -0.28208196, -0.15296221,  0.21296252,\n",
      "         0.44979921,  0.23202164, -0.48042238,  0.26533604, -0.25701448,\n",
      "        -0.59561282,  0.10288984,  0.11791867, -0.29025549,  0.40895903,\n",
      "        -0.33879575,  0.11966529,  0.022401  ,  0.06909722, -0.01472008,\n",
      "         0.09888519, -0.27579358,  0.25858748, -0.10090258, -0.36980024,\n",
      "         0.67238158, -0.08407854,  0.24175638,  0.89434642,  0.13439624,\n",
      "        -0.98308259, -0.27683869,  0.28609183, -0.04701421, -0.34091491,\n",
      "         0.16137508, -0.42661449,  0.02478007,  0.1396028 , -0.04986203,\n",
      "        -0.31817052, -0.28306532, -0.21189107,  0.62699628, -0.41352344],\n",
      "       [ 0.22942297,  0.1007096 ,  0.93944365,  0.18696962,  0.52426976,\n",
      "         0.21758424, -0.01061045, -0.30589014,  0.72142571,  0.12760662,\n",
      "         0.30479592,  0.41162285,  0.33318534, -0.25175479,  0.22479258,\n",
      "        -0.02219029,  0.11273441, -0.10838407, -0.0746613 , -0.05572761,\n",
      "         0.23955572,  0.33315837,  0.03968376, -0.00722572, -0.02494582,\n",
      "        -0.15870428, -0.11330084,  0.28521019,  0.36279964,  0.31220347,\n",
      "        -0.19945513,  0.44644687, -0.16522987,  0.28703138,  0.03894982,\n",
      "         0.30261335, -0.08407578, -0.15542926,  0.22938114,  0.49404734,\n",
      "         0.16534016,  0.36061928,  0.04058028,  0.20629291,  0.00480215,\n",
      "        -0.53355008, -0.11424208, -0.53487921,  0.3237173 ,  0.69337785,\n",
      "         0.20661259, -0.03316949, -0.31412309, -0.05051542, -0.30458653,\n",
      "         0.03163867, -0.35777593, -0.24201921,  0.02527397,  0.02569288,\n",
      "         0.59028548, -0.01200236, -0.61694694,  0.2426319 , -0.12171607,\n",
      "        -0.33442068,  0.17046109,  0.11003902, -0.14254306,  0.47984168,\n",
      "        -0.38428149,  0.05775167,  0.16368356, -0.05090833, -0.07863026,\n",
      "         0.2390072 , -0.39950973,  0.27623582,  0.05244525, -0.50983661,\n",
      "         0.77026004, -0.12394817, -0.01895812,  0.61608022, -0.05821717,\n",
      "        -1.00401521,  0.07041328,  0.40766999, -0.01116733, -0.24719784,\n",
      "         0.27450392, -0.33754176,  0.05049731, -0.03220817, -0.00224689,\n",
      "        -0.33404535, -0.16615203, -0.11042561,  0.6544615 , -0.4579992 ],\n",
      "       [ 0.50083929,  0.12902775,  0.92809981,  0.27916893,  0.41948402,\n",
      "         0.02994223,  0.019295  , -0.36748528,  0.74763018,  0.04698614,\n",
      "         0.03669887,  0.62554723,  0.37257832, -0.20756318,  0.0589094 ,\n",
      "        -0.24491622,  0.11672446, -0.09401352,  0.02623449, -0.13336779,\n",
      "         0.394238  ,  0.40982962,  0.0988454 ,  0.11226743,  0.0311634 ,\n",
      "         0.25301135,  0.03182531,  0.37334132,  0.38326621,  0.38548514,\n",
      "        -0.1488304 ,  0.33453965, -0.16707049,  0.21505271,  0.05872982,\n",
      "         0.08879977, -0.30543557, -0.37064883,  0.32922634,  0.77147645,\n",
      "         0.41201198,  0.49856001,  0.22929776,  0.1234467 , -0.05779435,\n",
      "        -0.3655546 ,  0.01938181, -0.40276003,  0.384372  ,  0.62198788,\n",
      "         0.2209428 , -0.13767722, -0.14469615,  0.09401594, -0.39908752,\n",
      "        -0.08500246, -0.47951457, -0.30920738, -0.17888367,  0.13287392,\n",
      "         0.44739276,  0.29634643, -0.57849997,  0.3324585 , -0.34387824,\n",
      "        -0.52736801,  0.13280402,  0.34804633, -0.37221333,  0.55702913,\n",
      "        -0.417593  ,  0.28202176,  0.08732862,  0.16386841,  0.01304388,\n",
      "         0.15619442, -0.32070538,  0.38329723, -0.00137927, -0.39124331,\n",
      "         0.8490817 , -0.02608717,  0.19594222,  1.10098517,  0.24047835,\n",
      "        -0.95876479, -0.25266272,  0.29466712,  0.02709019, -0.44242498,\n",
      "         0.09601619, -0.1754975 , -0.04877402,  0.04445221, -0.04757081,\n",
      "        -0.32369667, -0.29481032, -0.34837797,  0.64450961, -0.37809622]], dtype=float32), array([[1, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [1, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [1, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 1, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 1, 0, 0]]))\n"
     ]
    }
   ],
   "source": [
    "print(embedded_with_class(model, train_doc[:5], 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([[ 0.61317599,  0.13318765,  0.877092  , ..., -0.16908757,\n",
      "         0.64099133, -0.4423787 ],\n",
      "       [ 0.4802019 ,  0.07306197,  0.76076442, ..., -0.23957846,\n",
      "         0.57708287, -0.41351196],\n",
      "       [ 0.56784266, -0.03369169,  0.87067646, ..., -0.21189107,\n",
      "         0.62699628, -0.41352344],\n",
      "       ..., \n",
      "       [ 0.56456327,  0.00430289,  1.02511215, ..., -0.39203775,\n",
      "         0.66593307, -0.41639647],\n",
      "       [ 0.59195858,  0.09241927,  0.98085636, ..., -0.22513945,\n",
      "         0.75796807, -0.4565427 ],\n",
      "       [ 0.5245719 ,  0.01454974,  0.80657387, ..., -0.32598445,\n",
      "         0.69195735, -0.32277915]], dtype=float32), array([[1, 0, 0, ..., 0, 0, 0],\n",
      "       [1, 0, 0, ..., 0, 0, 0],\n",
      "       [1, 0, 0, ..., 0, 0, 0],\n",
      "       ..., \n",
      "       [0, 1, 0, ..., 0, 0, 0],\n",
      "       [1, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 1, 0, ..., 0, 0, 0]]))\n"
     ]
    }
   ],
   "source": [
    "train_doc_embed_with_class = embedded_with_class(model, train_doc, len(label_dict))\n",
    "print(train_doc_embed_with_class[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "(1579, 100)\n",
      "(1579, 8)\n"
     ]
    }
   ],
   "source": [
    "print(len(label_dict))\n",
    "print(train_doc_embed_with_class[0].shape)\n",
    "print(train_doc_embed_with_class[1].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorFlow model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31\n"
     ]
    }
   ],
   "source": [
    "epoch = 2000\n",
    "learning_rate = 0.1\n",
    "batch_size = 50\n",
    "total_batch = int(train_doc_embedded.shape[0] / batch_size)\n",
    "print(total_batch)\n",
    "index = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape=[None, 100])\n",
    "y = tf.placeholder(tf.int64, shape=[None, 8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W = tf.Variable(tf.truncated_normal(shape=[100, 256]))\n",
    "b = tf.Variable(tf.constant(0.0, shape=[256]))\n",
    "\n",
    "V = tf.Variable(tf.truncated_normal(shape=[256, 8]))\n",
    "c = tf.Variable(tf.constant(0.0, shape=[8]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = tf.tanh(tf.matmul(x, W) + b)\n",
    "u = tf.matmul(h, V) + c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 256)\n",
      "(?, 8)\n"
     ]
    }
   ],
   "source": [
    "print(h.shape)\n",
    "print(u.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 8)\n"
     ]
    }
   ],
   "source": [
    "p = tf.nn.softmax(u)\n",
    "print(p.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = tf.argmax(p, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?,)\n"
     ]
    }
   ],
   "source": [
    "print(pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean(tf.reduce_sum(-tf.cast(y, tf.float32)*tf.log(tf.clip_by_value(p, 1e-10, 1.0)), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# loss = tf.reduce_mean(tf.reduce_sum(-tf.cast(y, tf.float32)*tf.log(p), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(learning_rate).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_batch(data, index, size):\n",
    "    \"\"\" return next batch in format: index, x batch, y batch\n",
    "    \"\"\"\n",
    "    if index + size <= data[0].shape[0]:\n",
    "        return index+size, data[0][index:index+size], data[1][index:index+size]\n",
    "    else:\n",
    "        return index+size-data[0].shape[0], np.concatenate((data[0][index:],data[0][:index+size-data[0].shape[0]]), 0), np.concatenate((data[1][index:],data[1][:index+size-data[1].shape[0]]), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "121\n",
      "(200, 100)\n",
      "(200, 8)\n"
     ]
    }
   ],
   "source": [
    "k, t, q = next_batch(train_doc_embed_with_class, 1500, 200)\n",
    "print(k)\n",
    "print(t.shape)\n",
    "print(q.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, run 0, loss 16.8623\n",
      "epoch 0, run 10, loss 2.7631\n",
      "epoch 0, run 20, loss 8.74982\n",
      "epoch 0, run 30, loss 10.1314\n",
      "epoch 1, run 0, loss 12.434\n",
      "epoch 1, run 10, loss 3.68414\n",
      "epoch 1, run 20, loss 8.74982\n",
      "epoch 1, run 30, loss 11.0524\n",
      "epoch 2, run 0, loss 11.5129\n",
      "epoch 2, run 10, loss 7.36827\n",
      "epoch 2, run 20, loss 8.28931\n",
      "epoch 2, run 30, loss 12.434\n",
      "epoch 3, run 0, loss 10.5919\n",
      "epoch 3, run 10, loss 9.67086\n",
      "epoch 3, run 20, loss 10.5919\n",
      "epoch 3, run 30, loss 12.8945\n",
      "epoch 4, run 0, loss 11.5129\n",
      "epoch 4, run 10, loss 8.74982\n",
      "epoch 4, run 20, loss 9.67086\n",
      "epoch 4, run 30, loss 10.1314\n",
      "epoch 5, run 0, loss 13.355\n",
      "epoch 5, run 10, loss 10.1314\n",
      "epoch 5, run 20, loss 7.36827\n",
      "epoch 5, run 30, loss 10.5919\n",
      "epoch 6, run 0, loss 12.8945\n",
      "epoch 6, run 10, loss 13.8155\n",
      "epoch 6, run 20, loss 4.60517\n",
      "epoch 6, run 30, loss 11.5129\n",
      "epoch 7, run 0, loss 8.74982\n",
      "epoch 7, run 10, loss 11.5129\n",
      "epoch 7, run 20, loss 5.5262\n",
      "epoch 7, run 30, loss 10.1314\n",
      "epoch 8, run 0, loss 11.5129\n",
      "epoch 8, run 10, loss 10.5919\n",
      "epoch 8, run 20, loss 4.60517\n",
      "epoch 8, run 30, loss 9.21034\n",
      "epoch 9, run 0, loss 12.434\n",
      "epoch 9, run 10, loss 11.5129\n",
      "epoch 9, run 20, loss 5.98672\n",
      "epoch 9, run 30, loss 11.5129\n",
      "epoch 10, run 0, loss 9.21034\n",
      "epoch 10, run 10, loss 9.21034\n",
      "epoch 10, run 20, loss 4.60517\n",
      "epoch 10, run 30, loss 9.67086\n",
      "epoch 11, run 0, loss 10.5919\n",
      "epoch 11, run 10, loss 9.21034\n",
      "epoch 11, run 20, loss 5.5262\n",
      "epoch 11, run 30, loss 9.67086\n",
      "epoch 12, run 0, loss 11.0524\n",
      "epoch 12, run 10, loss 11.0524\n",
      "epoch 12, run 20, loss 4.60517\n",
      "epoch 12, run 30, loss 7.36827\n",
      "epoch 13, run 0, loss 8.74982\n",
      "epoch 13, run 10, loss 11.5129\n",
      "epoch 13, run 20, loss 5.98672\n",
      "epoch 13, run 30, loss 6.90775\n",
      "epoch 14, run 0, loss 7.82879\n",
      "epoch 14, run 10, loss 10.5919\n",
      "epoch 14, run 20, loss 8.74982\n",
      "epoch 14, run 30, loss 6.90775\n",
      "epoch 15, run 0, loss 5.98672\n",
      "epoch 15, run 10, loss 10.5919\n",
      "epoch 15, run 20, loss 7.36827\n",
      "epoch 15, run 30, loss 11.0524\n",
      "epoch 16, run 0, loss 5.98672\n",
      "epoch 16, run 10, loss 11.5129\n",
      "epoch 16, run 20, loss 5.06569\n",
      "epoch 16, run 30, loss 10.5919\n",
      "epoch 17, run 0, loss 7.82879\n",
      "epoch 17, run 10, loss 9.21034\n",
      "epoch 17, run 20, loss 3.68414\n",
      "epoch 17, run 30, loss 9.21034\n",
      "epoch 18, run 0, loss 11.9734\n",
      "epoch 18, run 10, loss 12.8945\n",
      "epoch 18, run 20, loss 3.22362\n",
      "epoch 18, run 30, loss 7.82879\n",
      "epoch 19, run 0, loss 9.67086\n",
      "epoch 19, run 10, loss 12.8945\n",
      "epoch 19, run 20, loss 5.98672\n",
      "epoch 19, run 30, loss 8.28931\n",
      "epoch 20, run 0, loss 9.21034\n",
      "epoch 20, run 10, loss 10.1314\n",
      "epoch 20, run 20, loss 8.74982\n",
      "epoch 20, run 30, loss 9.67086\n",
      "epoch 21, run 0, loss 8.28931\n",
      "epoch 21, run 10, loss 11.5129\n",
      "epoch 21, run 20, loss 9.67086\n",
      "epoch 21, run 30, loss 9.21034\n",
      "epoch 22, run 0, loss 8.28931\n",
      "epoch 22, run 10, loss 12.8945\n",
      "epoch 22, run 20, loss 10.1314\n",
      "epoch 22, run 30, loss 7.36827\n",
      "epoch 23, run 0, loss 10.5919\n",
      "epoch 23, run 10, loss 12.434\n",
      "epoch 23, run 20, loss 11.9734\n",
      "epoch 23, run 30, loss 5.5262\n",
      "epoch 24, run 0, loss 9.21034\n",
      "epoch 24, run 10, loss 9.67086\n",
      "epoch 24, run 20, loss 11.9734\n",
      "epoch 24, run 30, loss 5.5262\n",
      "epoch 25, run 0, loss 6.90775\n",
      "epoch 25, run 10, loss 10.1314\n",
      "epoch 25, run 20, loss 9.67086\n",
      "epoch 25, run 30, loss 5.06569\n",
      "epoch 26, run 0, loss 5.06569\n",
      "epoch 26, run 10, loss 11.5129\n",
      "epoch 26, run 20, loss 11.5129\n",
      "epoch 26, run 30, loss 6.44724\n",
      "epoch 27, run 0, loss 5.5262\n",
      "epoch 27, run 10, loss 10.1314\n",
      "epoch 27, run 20, loss 9.21034\n",
      "epoch 27, run 30, loss 5.06569\n",
      "epoch 28, run 0, loss 5.06569\n",
      "epoch 28, run 10, loss 9.67086\n",
      "epoch 28, run 20, loss 9.67086\n",
      "epoch 28, run 30, loss 5.06569\n",
      "epoch 29, run 0, loss 5.98672\n",
      "epoch 29, run 10, loss 11.0524\n",
      "epoch 29, run 20, loss 11.0524\n",
      "epoch 29, run 30, loss 5.06569\n",
      "epoch 30, run 0, loss 4.14465\n",
      "epoch 30, run 10, loss 9.67086\n",
      "epoch 30, run 20, loss 11.9734\n",
      "epoch 30, run 30, loss 4.14465\n",
      "epoch 31, run 0, loss 5.5262\n",
      "epoch 31, run 10, loss 9.67086\n",
      "epoch 31, run 20, loss 11.9734\n",
      "epoch 31, run 30, loss 8.28931\n",
      "epoch 32, run 0, loss 4.60517\n",
      "epoch 32, run 10, loss 7.36827\n",
      "epoch 32, run 20, loss 10.5919\n",
      "epoch 32, run 30, loss 8.28931\n",
      "epoch 33, run 0, loss 6.44724\n",
      "epoch 33, run 10, loss 6.90775\n",
      "epoch 33, run 20, loss 11.5129\n",
      "epoch 33, run 30, loss 5.98672\n",
      "epoch 34, run 0, loss 8.74982\n",
      "epoch 34, run 10, loss 6.90775\n",
      "epoch 34, run 20, loss 10.5919\n",
      "epoch 34, run 30, loss 4.14465\n",
      "epoch 35, run 0, loss 7.82879\n",
      "epoch 35, run 10, loss 11.5129\n",
      "epoch 35, run 20, loss 11.0524\n",
      "epoch 35, run 30, loss 2.7631\n",
      "epoch 36, run 0, loss 5.06569\n",
      "epoch 36, run 10, loss 10.5919\n",
      "epoch 36, run 20, loss 13.355\n",
      "epoch 36, run 30, loss 4.14465\n",
      "epoch 37, run 0, loss 3.68414\n",
      "epoch 37, run 10, loss 9.21034\n",
      "epoch 37, run 20, loss 10.1314\n",
      "epoch 37, run 30, loss 9.21034\n",
      "epoch 38, run 0, loss 3.68414\n",
      "epoch 38, run 10, loss 8.28931\n",
      "epoch 38, run 20, loss 10.5919\n",
      "epoch 38, run 30, loss 10.1314\n",
      "epoch 39, run 0, loss 5.98672\n",
      "epoch 39, run 10, loss 8.74982\n",
      "epoch 39, run 20, loss 11.5129\n",
      "epoch 39, run 30, loss 9.67086\n",
      "epoch 40, run 0, loss 8.74982\n",
      "epoch 40, run 10, loss 9.21034\n",
      "epoch 40, run 20, loss 14.276\n",
      "epoch 40, run 30, loss 11.0524\n",
      "epoch 41, run 0, loss 9.21034\n",
      "epoch 41, run 10, loss 9.21034\n",
      "epoch 41, run 20, loss 11.0524\n",
      "epoch 41, run 30, loss 12.8945\n",
      "epoch 42, run 0, loss 9.67086\n",
      "epoch 42, run 10, loss 7.36827\n",
      "epoch 42, run 20, loss 10.1314\n",
      "epoch 42, run 30, loss 10.1314\n",
      "epoch 43, run 0, loss 12.434\n",
      "epoch 43, run 10, loss 5.5262\n",
      "epoch 43, run 20, loss 11.9734\n",
      "epoch 43, run 30, loss 12.8945\n",
      "epoch 44, run 0, loss 11.5129\n",
      "epoch 44, run 10, loss 5.06569\n",
      "epoch 44, run 20, loss 11.0524\n",
      "epoch 44, run 30, loss 10.1314\n",
      "epoch 45, run 0, loss 9.67086\n",
      "epoch 45, run 10, loss 4.60517\n",
      "epoch 45, run 20, loss 9.67086\n",
      "epoch 45, run 30, loss 8.74982\n",
      "epoch 46, run 0, loss 11.5129\n",
      "epoch 46, run 10, loss 6.44724\n",
      "epoch 46, run 20, loss 11.9734\n",
      "epoch 46, run 30, loss 10.5919\n",
      "epoch 47, run 0, loss 9.67086\n",
      "epoch 47, run 10, loss 5.06569\n",
      "epoch 47, run 20, loss 10.1314\n",
      "epoch 47, run 30, loss 11.9734\n",
      "epoch 48, run 0, loss 9.67086\n",
      "epoch 48, run 10, loss 5.06569\n",
      "epoch 48, run 20, loss 8.74982\n",
      "epoch 48, run 30, loss 11.5129\n",
      "epoch 49, run 0, loss 10.5919\n",
      "epoch 49, run 10, loss 4.60517\n",
      "epoch 49, run 20, loss 7.82879\n",
      "epoch 49, run 30, loss 10.5919\n",
      "epoch 50, run 0, loss 11.5129\n",
      "epoch 50, run 10, loss 4.14465\n",
      "epoch 50, run 20, loss 5.98672\n",
      "epoch 50, run 30, loss 11.5129\n",
      "epoch 51, run 0, loss 11.5129\n",
      "epoch 51, run 10, loss 8.28931\n",
      "epoch 51, run 20, loss 6.44724\n",
      "epoch 51, run 30, loss 10.1314\n",
      "epoch 52, run 0, loss 10.5919\n",
      "epoch 52, run 10, loss 8.28931\n",
      "epoch 52, run 20, loss 9.21034\n",
      "epoch 52, run 30, loss 10.1314\n",
      "epoch 53, run 0, loss 11.0524\n",
      "epoch 53, run 10, loss 5.98672\n",
      "epoch 53, run 20, loss 11.0524\n",
      "epoch 53, run 30, loss 12.434\n",
      "epoch 54, run 0, loss 10.1314\n",
      "epoch 54, run 10, loss 4.14465\n",
      "epoch 54, run 20, loss 8.28931\n",
      "epoch 54, run 30, loss 11.0524\n",
      "epoch 55, run 0, loss 11.5129\n",
      "epoch 55, run 10, loss 2.30259\n",
      "epoch 55, run 20, loss 8.74982\n",
      "epoch 55, run 30, loss 10.5919\n",
      "epoch 56, run 0, loss 12.8945\n",
      "epoch 56, run 10, loss 4.14465\n",
      "epoch 56, run 20, loss 7.36827\n",
      "epoch 56, run 30, loss 11.5129\n",
      "epoch 57, run 0, loss 10.1314\n",
      "epoch 57, run 10, loss 9.67086\n",
      "epoch 57, run 20, loss 10.1314\n",
      "epoch 57, run 30, loss 14.7365\n",
      "epoch 58, run 0, loss 10.1314\n",
      "epoch 58, run 10, loss 10.1314\n",
      "epoch 58, run 20, loss 8.28931\n",
      "epoch 58, run 30, loss 11.9734\n",
      "epoch 59, run 0, loss 11.9734\n",
      "epoch 59, run 10, loss 9.21034\n",
      "epoch 59, run 20, loss 8.74982\n",
      "epoch 59, run 30, loss 8.74982\n",
      "epoch 60, run 0, loss 13.8155\n",
      "epoch 60, run 10, loss 11.0524\n",
      "epoch 60, run 20, loss 5.98672\n",
      "epoch 60, run 30, loss 11.9734\n",
      "epoch 61, run 0, loss 10.5919\n",
      "epoch 61, run 10, loss 13.355\n",
      "epoch 61, run 20, loss 5.5262\n",
      "epoch 61, run 30, loss 11.0524\n",
      "epoch 62, run 0, loss 10.5919\n",
      "epoch 62, run 10, loss 10.1314\n",
      "epoch 62, run 20, loss 5.06569\n",
      "epoch 62, run 30, loss 9.21034\n",
      "epoch 63, run 0, loss 11.5129\n",
      "epoch 63, run 10, loss 12.434\n",
      "epoch 63, run 20, loss 6.90775\n",
      "epoch 63, run 30, loss 11.0524\n",
      "epoch 64, run 0, loss 11.0524\n",
      "epoch 64, run 10, loss 9.67086\n",
      "epoch 64, run 20, loss 5.5262\n",
      "epoch 64, run 30, loss 11.5129\n",
      "epoch 65, run 0, loss 9.67086\n",
      "epoch 65, run 10, loss 8.74982\n",
      "epoch 65, run 20, loss 5.06569\n",
      "epoch 65, run 30, loss 7.82879\n",
      "epoch 66, run 0, loss 12.434\n",
      "epoch 66, run 10, loss 11.0524\n",
      "epoch 66, run 20, loss 4.60517\n",
      "epoch 66, run 30, loss 9.21034\n",
      "epoch 67, run 0, loss 9.67086\n",
      "epoch 67, run 10, loss 11.9734\n",
      "epoch 67, run 20, loss 4.14465\n",
      "epoch 67, run 30, loss 6.44724\n",
      "epoch 68, run 0, loss 8.74982\n",
      "epoch 68, run 10, loss 11.5129\n",
      "epoch 68, run 20, loss 7.82879\n",
      "epoch 68, run 30, loss 5.98672\n",
      "epoch 69, run 0, loss 7.36827\n",
      "epoch 69, run 10, loss 10.1314\n",
      "epoch 69, run 20, loss 9.21034\n",
      "epoch 69, run 30, loss 9.67086\n",
      "epoch 70, run 0, loss 5.98672\n",
      "epoch 70, run 10, loss 11.5129\n",
      "epoch 70, run 20, loss 5.98672\n",
      "epoch 70, run 30, loss 11.0524\n",
      "epoch 71, run 0, loss 6.44724\n",
      "epoch 71, run 10, loss 9.67086\n",
      "epoch 71, run 20, loss 4.14465\n",
      "epoch 71, run 30, loss 10.1314\n",
      "epoch 72, run 0, loss 9.21034\n",
      "epoch 72, run 10, loss 10.5919\n",
      "epoch 72, run 20, loss 2.30259\n",
      "epoch 72, run 30, loss 9.67086\n",
      "epoch 73, run 0, loss 10.5919\n",
      "epoch 73, run 10, loss 12.8945\n",
      "epoch 73, run 20, loss 3.68414\n",
      "epoch 73, run 30, loss 7.36827\n",
      "epoch 74, run 0, loss 8.28931\n",
      "epoch 74, run 10, loss 11.0524\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 74, run 20, loss 9.21034\n",
      "epoch 74, run 30, loss 8.74982\n",
      "epoch 75, run 0, loss 8.74982\n",
      "epoch 75, run 10, loss 10.5919\n",
      "epoch 75, run 20, loss 10.1314\n",
      "epoch 75, run 30, loss 9.67086\n",
      "epoch 76, run 0, loss 7.82879\n",
      "epoch 76, run 10, loss 11.5129\n",
      "epoch 76, run 20, loss 8.74982\n",
      "epoch 76, run 30, loss 8.74982\n",
      "epoch 77, run 0, loss 9.67086\n",
      "epoch 77, run 10, loss 14.7365\n",
      "epoch 77, run 20, loss 11.0524\n",
      "epoch 77, run 30, loss 6.44724\n",
      "epoch 78, run 0, loss 8.74982\n",
      "epoch 78, run 10, loss 11.9734\n",
      "epoch 78, run 20, loss 13.8155\n",
      "epoch 78, run 30, loss 5.06569\n",
      "epoch 79, run 0, loss 8.74982\n",
      "epoch 79, run 10, loss 9.21034\n",
      "epoch 79, run 20, loss 11.0524\n",
      "epoch 79, run 30, loss 5.06569\n",
      "epoch 80, run 0, loss 5.98672\n",
      "epoch 80, run 10, loss 11.5129\n",
      "epoch 80, run 20, loss 11.5129\n",
      "epoch 80, run 30, loss 5.98672\n",
      "epoch 81, run 0, loss 5.5262\n",
      "epoch 81, run 10, loss 11.5129\n",
      "epoch 81, run 20, loss 11.0524\n",
      "epoch 81, run 30, loss 5.5262\n",
      "epoch 82, run 0, loss 4.60517\n",
      "epoch 82, run 10, loss 9.21034\n",
      "epoch 82, run 20, loss 9.21034\n",
      "epoch 82, run 30, loss 3.68414\n",
      "epoch 83, run 0, loss 6.90775\n",
      "epoch 83, run 10, loss 11.5129\n",
      "epoch 83, run 20, loss 10.5919\n",
      "epoch 83, run 30, loss 4.14465\n",
      "epoch 84, run 0, loss 5.5262\n",
      "epoch 84, run 10, loss 11.0524\n",
      "epoch 84, run 20, loss 11.9734\n",
      "epoch 84, run 30, loss 3.68414\n",
      "epoch 85, run 0, loss 5.06569\n",
      "epoch 85, run 10, loss 8.28931\n",
      "epoch 85, run 20, loss 11.0524\n",
      "epoch 85, run 30, loss 6.44724\n",
      "epoch 86, run 0, loss 4.60517\n",
      "epoch 86, run 10, loss 8.74982\n",
      "epoch 86, run 20, loss 10.1314\n",
      "epoch 86, run 30, loss 8.74982\n",
      "epoch 87, run 0, loss 4.14465\n",
      "epoch 87, run 10, loss 6.44724\n",
      "epoch 87, run 20, loss 11.5129\n",
      "epoch 87, run 30, loss 5.5262\n",
      "epoch 88, run 0, loss 8.28931\n",
      "epoch 88, run 10, loss 5.98672\n",
      "epoch 88, run 20, loss 10.1314\n",
      "epoch 88, run 30, loss 4.60517\n",
      "epoch 89, run 0, loss 8.74982\n",
      "epoch 89, run 10, loss 9.67086\n",
      "epoch 89, run 20, loss 9.21034\n",
      "epoch 89, run 30, loss 2.30258\n",
      "epoch 90, run 0, loss 6.44724\n",
      "epoch 90, run 10, loss 11.0524\n",
      "epoch 90, run 20, loss 12.8945\n",
      "epoch 90, run 30, loss 4.14465\n",
      "epoch 91, run 0, loss 4.14465\n",
      "epoch 91, run 10, loss 9.67086\n",
      "epoch 91, run 20, loss 10.5919\n",
      "epoch 91, run 30, loss 8.28931\n",
      "epoch 92, run 0, loss 2.30259\n",
      "epoch 92, run 10, loss 9.21034\n",
      "epoch 92, run 20, loss 10.5919\n",
      "epoch 92, run 30, loss 10.1314\n",
      "epoch 93, run 0, loss 3.68414\n",
      "epoch 93, run 10, loss 7.36827\n",
      "epoch 93, run 20, loss 12.434\n",
      "epoch 93, run 30, loss 8.74982\n",
      "epoch 94, run 0, loss 9.21034\n",
      "epoch 94, run 10, loss 9.21034\n",
      "epoch 94, run 20, loss 13.8155\n",
      "epoch 94, run 30, loss 10.1314\n",
      "epoch 95, run 0, loss 10.1314\n",
      "epoch 95, run 10, loss 9.67086\n",
      "epoch 95, run 20, loss 12.8945\n",
      "epoch 95, run 30, loss 14.276\n",
      "epoch 96, run 0, loss 8.28931\n",
      "epoch 96, run 10, loss 8.74982\n",
      "epoch 96, run 20, loss 7.82879\n",
      "epoch 96, run 30, loss 11.0524\n",
      "epoch 97, run 0, loss 11.5129\n",
      "epoch 97, run 10, loss 5.98672\n",
      "epoch 97, run 20, loss 11.9734\n",
      "epoch 97, run 30, loss 10.5919\n",
      "epoch 98, run 0, loss 14.276\n",
      "epoch 98, run 10, loss 5.06569\n",
      "epoch 98, run 20, loss 11.5129\n",
      "epoch 98, run 30, loss 11.5129\n",
      "epoch 99, run 0, loss 10.5919\n",
      "epoch 99, run 10, loss 5.06569\n",
      "epoch 99, run 20, loss 9.21034\n",
      "epoch 99, run 30, loss 9.21034\n",
      "epoch 100, run 0, loss 11.9734\n",
      "epoch 100, run 10, loss 6.44724\n",
      "epoch 100, run 20, loss 11.0524\n",
      "epoch 100, run 30, loss 9.67086\n",
      "epoch 101, run 0, loss 10.5919\n",
      "epoch 101, run 10, loss 5.98672\n",
      "epoch 101, run 20, loss 11.0524\n",
      "epoch 101, run 30, loss 11.5129\n",
      "epoch 102, run 0, loss 8.74982\n",
      "epoch 102, run 10, loss 3.68414\n",
      "epoch 102, run 20, loss 8.28931\n",
      "epoch 102, run 30, loss 11.0524\n",
      "epoch 103, run 0, loss 10.5919\n",
      "epoch 103, run 10, loss 4.14465\n",
      "epoch 103, run 20, loss 8.28931\n",
      "epoch 103, run 30, loss 11.5129\n",
      "epoch 104, run 0, loss 11.5129\n",
      "epoch 104, run 10, loss 3.22362\n",
      "epoch 104, run 20, loss 5.98672\n",
      "epoch 104, run 30, loss 10.5919\n",
      "epoch 105, run 0, loss 11.0524\n",
      "epoch 105, run 10, loss 6.90775\n",
      "epoch 105, run 20, loss 5.98672\n",
      "epoch 105, run 30, loss 11.0524\n",
      "epoch 106, run 0, loss 10.1314\n",
      "epoch 106, run 10, loss 8.74982\n",
      "epoch 106, run 20, loss 8.28931\n",
      "epoch 106, run 30, loss 9.21034\n",
      "epoch 107, run 0, loss 11.0524\n",
      "epoch 107, run 10, loss 5.5262\n",
      "epoch 107, run 20, loss 11.9734\n",
      "epoch 107, run 30, loss 12.434\n",
      "epoch 108, run 0, loss 10.1314\n",
      "epoch 108, run 10, loss 4.14465\n",
      "epoch 108, run 20, loss 9.67086\n",
      "epoch 108, run 30, loss 12.434\n",
      "epoch 109, run 0, loss 9.67086\n",
      "epoch 109, run 10, loss 2.30258\n",
      "epoch 109, run 20, loss 8.74982\n",
      "epoch 109, run 30, loss 10.1314\n",
      "epoch 110, run 0, loss 12.434\n",
      "epoch 110, run 10, loss 3.68414\n",
      "epoch 110, run 20, loss 8.74982\n",
      "epoch 110, run 30, loss 11.5129\n",
      "epoch 111, run 0, loss 11.0524\n",
      "epoch 111, run 10, loss 8.74982\n",
      "epoch 111, run 20, loss 8.28931\n",
      "epoch 111, run 30, loss 13.355\n",
      "epoch 112, run 0, loss 10.5919\n",
      "epoch 112, run 10, loss 10.5919\n",
      "epoch 112, run 20, loss 10.1314\n",
      "epoch 112, run 30, loss 11.9734\n",
      "epoch 113, run 0, loss 12.434\n",
      "epoch 113, run 10, loss 8.28931\n",
      "epoch 113, run 20, loss 8.28931\n",
      "epoch 113, run 30, loss 9.67086\n",
      "epoch 114, run 0, loss 13.8155\n",
      "epoch 114, run 10, loss 10.5919\n",
      "epoch 114, run 20, loss 7.36827\n",
      "epoch 114, run 30, loss 10.5919\n",
      "epoch 115, run 0, loss 13.355\n",
      "epoch 115, run 10, loss 14.276\n",
      "epoch 115, run 20, loss 5.06569\n",
      "epoch 115, run 30, loss 11.9734\n",
      "epoch 116, run 0, loss 7.82879\n",
      "epoch 116, run 10, loss 11.5129\n",
      "epoch 116, run 20, loss 5.5262\n",
      "epoch 116, run 30, loss 9.67086\n",
      "epoch 117, run 0, loss 11.9734\n",
      "epoch 117, run 10, loss 11.0524\n",
      "epoch 117, run 20, loss 5.06569\n",
      "epoch 117, run 30, loss 10.1314\n",
      "epoch 118, run 0, loss 11.5129\n",
      "epoch 118, run 10, loss 11.5129\n",
      "epoch 118, run 20, loss 5.98672\n",
      "epoch 118, run 30, loss 11.5129\n",
      "epoch 119, run 0, loss 8.74982\n",
      "epoch 119, run 10, loss 8.74982\n",
      "epoch 119, run 20, loss 3.68414\n",
      "epoch 119, run 30, loss 9.67086\n",
      "epoch 120, run 0, loss 10.5919\n",
      "epoch 120, run 10, loss 9.21034\n",
      "epoch 120, run 20, loss 5.06569\n",
      "epoch 120, run 30, loss 8.74982\n",
      "epoch 121, run 0, loss 11.5129\n",
      "epoch 121, run 10, loss 11.9734\n",
      "epoch 121, run 20, loss 4.14465\n",
      "epoch 121, run 30, loss 7.36827\n",
      "epoch 122, run 0, loss 8.28931\n",
      "epoch 122, run 10, loss 11.5129\n",
      "epoch 122, run 20, loss 5.98672\n",
      "epoch 122, run 30, loss 6.90775\n",
      "epoch 123, run 0, loss 8.28931\n",
      "epoch 123, run 10, loss 11.0524\n",
      "epoch 123, run 20, loss 8.28931\n",
      "epoch 123, run 30, loss 6.90775\n",
      "epoch 124, run 0, loss 6.44724\n",
      "epoch 124, run 10, loss 10.5919\n",
      "epoch 124, run 20, loss 7.36827\n",
      "epoch 124, run 30, loss 11.9734\n",
      "epoch 125, run 0, loss 5.98672\n",
      "epoch 125, run 10, loss 10.5919\n",
      "epoch 125, run 20, loss 5.5262\n",
      "epoch 125, run 30, loss 10.5919\n",
      "epoch 126, run 0, loss 7.82879\n",
      "epoch 126, run 10, loss 9.67086\n",
      "epoch 126, run 20, loss 3.22362\n",
      "epoch 126, run 30, loss 8.74982\n",
      "epoch 127, run 0, loss 11.9734\n",
      "epoch 127, run 10, loss 12.434\n",
      "epoch 127, run 20, loss 4.14465\n",
      "epoch 127, run 30, loss 8.28931\n",
      "epoch 128, run 0, loss 9.21034\n",
      "epoch 128, run 10, loss 12.434\n",
      "epoch 128, run 20, loss 6.44724\n",
      "epoch 128, run 30, loss 9.21034\n",
      "epoch 129, run 0, loss 8.74982\n",
      "epoch 129, run 10, loss 10.1314\n",
      "epoch 129, run 20, loss 9.67086\n",
      "epoch 129, run 30, loss 9.21034\n",
      "epoch 130, run 0, loss 8.28931\n",
      "epoch 130, run 10, loss 11.5129\n",
      "epoch 130, run 20, loss 9.21034\n",
      "epoch 130, run 30, loss 8.74982\n",
      "epoch 131, run 0, loss 8.28931\n",
      "epoch 131, run 10, loss 13.355\n",
      "epoch 131, run 20, loss 9.21034\n",
      "epoch 131, run 30, loss 7.36827\n",
      "epoch 132, run 0, loss 9.67086\n",
      "epoch 132, run 10, loss 11.9734\n",
      "epoch 132, run 20, loss 13.355\n",
      "epoch 132, run 30, loss 5.98672\n",
      "epoch 133, run 0, loss 8.28931\n",
      "epoch 133, run 10, loss 9.67086\n",
      "epoch 133, run 20, loss 11.5129\n",
      "epoch 133, run 30, loss 5.06569\n",
      "epoch 134, run 0, loss 7.36827\n",
      "epoch 134, run 10, loss 10.5919\n",
      "epoch 134, run 20, loss 10.5919\n",
      "epoch 134, run 30, loss 5.06569\n",
      "epoch 135, run 0, loss 4.60517\n",
      "epoch 135, run 10, loss 11.9734\n",
      "epoch 135, run 20, loss 11.9734\n",
      "epoch 135, run 30, loss 5.98672\n",
      "epoch 136, run 0, loss 5.5262\n",
      "epoch 136, run 10, loss 9.21034\n",
      "epoch 136, run 20, loss 8.74982\n",
      "epoch 136, run 30, loss 4.60517\n",
      "epoch 137, run 0, loss 5.5262\n",
      "epoch 137, run 10, loss 10.1314\n",
      "epoch 137, run 20, loss 9.21034\n",
      "epoch 137, run 30, loss 5.06569\n",
      "epoch 138, run 0, loss 5.98672\n",
      "epoch 138, run 10, loss 11.0524\n",
      "epoch 138, run 20, loss 10.5919\n",
      "epoch 138, run 30, loss 4.60517\n",
      "epoch 139, run 0, loss 3.68414\n",
      "epoch 139, run 10, loss 9.67086\n",
      "epoch 139, run 20, loss 11.9734\n",
      "epoch 139, run 30, loss 4.60517\n",
      "epoch 140, run 0, loss 4.60517\n",
      "epoch 140, run 10, loss 8.74982\n",
      "epoch 140, run 20, loss 11.5129\n",
      "epoch 140, run 30, loss 8.28931\n",
      "epoch 141, run 0, loss 4.14465\n",
      "epoch 141, run 10, loss 7.36827\n",
      "epoch 141, run 20, loss 10.5919\n",
      "epoch 141, run 30, loss 7.82879\n",
      "epoch 142, run 0, loss 6.44724\n",
      "epoch 142, run 10, loss 6.44724\n",
      "epoch 142, run 20, loss 11.5129\n",
      "epoch 142, run 30, loss 5.98672\n",
      "epoch 143, run 0, loss 8.28931\n",
      "epoch 143, run 10, loss 6.90775\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 143, run 20, loss 10.1314\n",
      "epoch 143, run 30, loss 3.68414\n",
      "epoch 144, run 0, loss 6.90775\n",
      "epoch 144, run 10, loss 11.5129\n",
      "epoch 144, run 20, loss 11.9734\n",
      "epoch 144, run 30, loss 2.7631\n",
      "epoch 145, run 0, loss 5.5262\n",
      "epoch 145, run 10, loss 10.1314\n",
      "epoch 145, run 20, loss 13.355\n",
      "epoch 145, run 30, loss 5.06569\n",
      "epoch 146, run 0, loss 3.22362\n",
      "epoch 146, run 10, loss 8.74982\n",
      "epoch 146, run 20, loss 10.5919\n",
      "epoch 146, run 30, loss 9.67086\n",
      "epoch 147, run 0, loss 3.68414\n",
      "epoch 147, run 10, loss 8.74982\n",
      "epoch 147, run 20, loss 10.1314\n",
      "epoch 147, run 30, loss 9.67086\n",
      "epoch 148, run 0, loss 6.90775\n",
      "epoch 148, run 10, loss 9.21034\n",
      "epoch 148, run 20, loss 11.9734\n",
      "epoch 148, run 30, loss 8.74982\n",
      "epoch 149, run 0, loss 9.67086\n",
      "epoch 149, run 10, loss 9.21034\n",
      "epoch 149, run 20, loss 13.355\n",
      "epoch 149, run 30, loss 11.9734\n",
      "epoch 150, run 0, loss 9.21034\n",
      "epoch 150, run 10, loss 8.74982\n",
      "epoch 150, run 20, loss 10.1314\n",
      "epoch 150, run 30, loss 13.355\n",
      "epoch 151, run 0, loss 9.21034\n",
      "epoch 151, run 10, loss 7.36827\n",
      "epoch 151, run 20, loss 10.5919\n",
      "epoch 151, run 30, loss 10.1314\n",
      "epoch 152, run 0, loss 13.355\n",
      "epoch 152, run 10, loss 5.5262\n",
      "epoch 152, run 20, loss 11.0524\n",
      "epoch 152, run 30, loss 12.8945\n",
      "epoch 153, run 0, loss 11.0524\n",
      "epoch 153, run 10, loss 5.5262\n",
      "epoch 153, run 20, loss 10.5919\n",
      "epoch 153, run 30, loss 9.21034\n",
      "epoch 154, run 0, loss 11.0524\n",
      "epoch 154, run 10, loss 4.60517\n",
      "epoch 154, run 20, loss 9.67086\n",
      "epoch 154, run 30, loss 8.74982\n",
      "epoch 155, run 0, loss 11.9734\n",
      "epoch 155, run 10, loss 5.98672\n",
      "epoch 155, run 20, loss 12.434\n",
      "epoch 155, run 30, loss 11.0524\n",
      "epoch 156, run 0, loss 9.21034\n",
      "epoch 156, run 10, loss 5.06569\n",
      "epoch 156, run 20, loss 10.1314\n",
      "epoch 156, run 30, loss 12.434\n",
      "epoch 157, run 0, loss 8.74982\n",
      "epoch 157, run 10, loss 5.5262\n",
      "epoch 157, run 20, loss 9.21034\n",
      "epoch 157, run 30, loss 12.434\n",
      "epoch 158, run 0, loss 10.1314\n",
      "epoch 158, run 10, loss 4.60517\n",
      "epoch 158, run 20, loss 7.36827\n",
      "epoch 158, run 30, loss 10.1314\n",
      "epoch 159, run 0, loss 11.9734\n",
      "epoch 159, run 10, loss 5.06569\n",
      "epoch 159, run 20, loss 6.44724\n",
      "epoch 159, run 30, loss 11.0524\n",
      "epoch 160, run 0, loss 11.9734\n",
      "epoch 160, run 10, loss 8.74982\n",
      "epoch 160, run 20, loss 6.44724\n",
      "epoch 160, run 30, loss 10.1314\n",
      "epoch 161, run 0, loss 11.0524\n",
      "epoch 161, run 10, loss 7.82879\n",
      "epoch 161, run 20, loss 10.1314\n",
      "epoch 161, run 30, loss 10.1314\n",
      "epoch 162, run 0, loss 11.9734\n",
      "epoch 162, run 10, loss 5.5262\n",
      "epoch 162, run 20, loss 11.5129\n",
      "epoch 162, run 30, loss 12.434\n",
      "epoch 163, run 0, loss 10.1314\n",
      "epoch 163, run 10, loss 3.68414\n",
      "epoch 163, run 20, loss 8.28931\n",
      "epoch 163, run 30, loss 10.1314\n",
      "epoch 164, run 0, loss 12.434\n",
      "epoch 164, run 10, loss 2.7631\n",
      "epoch 164, run 20, loss 8.74982\n",
      "epoch 164, run 30, loss 10.1314\n",
      "epoch 165, run 0, loss 13.355\n",
      "epoch 165, run 10, loss 5.5262\n",
      "epoch 165, run 20, loss 7.82879\n",
      "epoch 165, run 30, loss 11.5129\n",
      "epoch 166, run 0, loss 10.1314\n",
      "epoch 166, run 10, loss 9.67086\n",
      "epoch 166, run 20, loss 10.1314\n",
      "epoch 166, run 30, loss 15.1971\n",
      "epoch 167, run 0, loss 10.1314\n",
      "epoch 167, run 10, loss 9.67086\n",
      "epoch 167, run 20, loss 8.74982\n",
      "epoch 167, run 30, loss 11.5129\n",
      "epoch 168, run 0, loss 12.434\n",
      "epoch 168, run 10, loss 9.21034\n",
      "epoch 168, run 20, loss 8.28931\n",
      "epoch 168, run 30, loss 9.21034\n",
      "epoch 169, run 0, loss 13.355\n",
      "epoch 169, run 10, loss 12.434\n",
      "epoch 169, run 20, loss 5.5262\n",
      "epoch 169, run 30, loss 12.434\n",
      "epoch 170, run 0, loss 9.67086\n",
      "epoch 170, run 10, loss 12.8945\n",
      "epoch 170, run 20, loss 5.5262\n",
      "epoch 170, run 30, loss 11.5129\n",
      "epoch 171, run 0, loss 10.5919\n",
      "epoch 171, run 10, loss 10.1314\n",
      "epoch 171, run 20, loss 4.60517\n",
      "epoch 171, run 30, loss 9.21034\n",
      "epoch 172, run 0, loss 11.5129\n",
      "epoch 172, run 10, loss 12.8945\n",
      "epoch 172, run 20, loss 6.44724\n",
      "epoch 172, run 30, loss 11.9734\n",
      "epoch 173, run 0, loss 10.1314\n",
      "epoch 173, run 10, loss 9.21034\n",
      "epoch 173, run 20, loss 5.98672\n",
      "epoch 173, run 30, loss 10.5919\n",
      "epoch 174, run 0, loss 9.67086\n",
      "epoch 174, run 10, loss 9.21034\n",
      "epoch 174, run 20, loss 5.5262\n",
      "epoch 174, run 30, loss 8.74982\n",
      "epoch 175, run 0, loss 11.9734\n",
      "epoch 175, run 10, loss 11.0524\n",
      "epoch 175, run 20, loss 4.60517\n",
      "epoch 175, run 30, loss 7.82879\n",
      "epoch 176, run 0, loss 10.1314\n",
      "epoch 176, run 10, loss 12.8945\n",
      "epoch 176, run 20, loss 3.68414\n",
      "epoch 176, run 30, loss 5.98672\n",
      "epoch 177, run 0, loss 9.67086\n",
      "epoch 177, run 10, loss 12.434\n",
      "epoch 177, run 20, loss 8.74982\n",
      "epoch 177, run 30, loss 5.98672\n",
      "epoch 178, run 0, loss 7.36827\n",
      "epoch 178, run 10, loss 10.1314\n",
      "epoch 178, run 20, loss 8.74982\n",
      "epoch 178, run 30, loss 9.67086\n",
      "epoch 179, run 0, loss 6.90775\n",
      "epoch 179, run 10, loss 11.5129\n",
      "epoch 179, run 20, loss 5.98672\n",
      "epoch 179, run 30, loss 11.5129\n",
      "epoch 180, run 0, loss 6.44724\n",
      "epoch 180, run 10, loss 10.5919\n",
      "epoch 180, run 20, loss 4.60517\n",
      "epoch 180, run 30, loss 9.21034\n",
      "epoch 181, run 0, loss 10.5919\n",
      "epoch 181, run 10, loss 10.1314\n",
      "epoch 181, run 20, loss 2.7631\n",
      "epoch 181, run 30, loss 9.21034\n",
      "epoch 182, run 0, loss 11.5129\n",
      "epoch 182, run 10, loss 12.434\n",
      "epoch 182, run 20, loss 3.68414\n",
      "epoch 182, run 30, loss 7.36827\n",
      "epoch 183, run 0, loss 8.74982\n",
      "epoch 183, run 10, loss 10.5919\n",
      "epoch 183, run 20, loss 9.67086\n",
      "epoch 183, run 30, loss 9.67086\n",
      "epoch 184, run 0, loss 8.28931\n",
      "epoch 184, run 10, loss 10.1314\n",
      "epoch 184, run 20, loss 9.67086\n",
      "epoch 184, run 30, loss 9.21034\n",
      "epoch 185, run 0, loss 8.28931\n",
      "epoch 185, run 10, loss 11.9734\n",
      "epoch 185, run 20, loss 8.74982\n",
      "epoch 185, run 30, loss 8.28931\n",
      "epoch 186, run 0, loss 10.1314\n",
      "epoch 186, run 10, loss 14.7365\n",
      "epoch 186, run 20, loss 11.0524\n",
      "epoch 186, run 30, loss 5.98672\n",
      "epoch 187, run 0, loss 9.21034\n",
      "epoch 187, run 10, loss 11.0524\n",
      "epoch 187, run 20, loss 13.8155\n",
      "epoch 187, run 30, loss 5.06569\n",
      "epoch 188, run 0, loss 7.82879\n",
      "epoch 188, run 10, loss 9.21034\n",
      "epoch 188, run 20, loss 10.5919\n",
      "epoch 188, run 30, loss 4.60517\n",
      "epoch 189, run 0, loss 5.5262\n",
      "epoch 189, run 10, loss 11.9734\n",
      "epoch 189, run 20, loss 12.434\n",
      "epoch 189, run 30, loss 6.90775\n",
      "epoch 190, run 0, loss 5.06569\n",
      "epoch 190, run 10, loss 11.5129\n",
      "epoch 190, run 20, loss 10.5919\n",
      "epoch 190, run 30, loss 5.98672\n",
      "epoch 191, run 0, loss 5.06569\n",
      "epoch 191, run 10, loss 9.67086\n",
      "epoch 191, run 20, loss 8.28931\n",
      "epoch 191, run 30, loss 4.14465\n",
      "epoch 192, run 0, loss 6.44724\n",
      "epoch 192, run 10, loss 12.434\n",
      "epoch 192, run 20, loss 10.1314\n",
      "epoch 192, run 30, loss 4.14465\n",
      "epoch 193, run 0, loss 5.98672\n",
      "epoch 193, run 10, loss 10.5919\n",
      "epoch 193, run 20, loss 11.9734\n",
      "epoch 193, run 30, loss 3.68414\n",
      "epoch 194, run 0, loss 5.06569\n",
      "epoch 194, run 10, loss 8.74982\n",
      "epoch 194, run 20, loss 11.0524\n",
      "epoch 194, run 30, loss 7.36827\n",
      "epoch 195, run 0, loss 4.60517\n",
      "epoch 195, run 10, loss 7.82879\n",
      "epoch 195, run 20, loss 10.1314\n",
      "epoch 195, run 30, loss 8.28931\n",
      "epoch 196, run 0, loss 4.14465\n",
      "epoch 196, run 10, loss 5.98672\n",
      "epoch 196, run 20, loss 11.0524\n",
      "epoch 196, run 30, loss 5.5262\n",
      "epoch 197, run 0, loss 8.74982\n",
      "epoch 197, run 10, loss 6.44724\n",
      "epoch 197, run 20, loss 10.1314\n",
      "epoch 197, run 30, loss 4.14465\n",
      "epoch 198, run 0, loss 8.28931\n",
      "epoch 198, run 10, loss 9.67086\n",
      "epoch 198, run 20, loss 9.67086\n",
      "epoch 198, run 30, loss 2.30258\n",
      "epoch 199, run 0, loss 5.98672\n",
      "epoch 199, run 10, loss 11.5129\n",
      "epoch 199, run 20, loss 12.434\n",
      "epoch 199, run 30, loss 3.68414\n",
      "epoch 200, run 0, loss 4.60517\n",
      "epoch 200, run 10, loss 8.74982\n",
      "epoch 200, run 20, loss 11.5129\n",
      "epoch 200, run 30, loss 8.28931\n",
      "epoch 201, run 0, loss 2.7631\n",
      "epoch 201, run 10, loss 9.21034\n",
      "epoch 201, run 20, loss 10.1314\n",
      "epoch 201, run 30, loss 10.5919\n",
      "epoch 202, run 0, loss 3.68414\n",
      "epoch 202, run 10, loss 6.90775\n",
      "epoch 202, run 20, loss 11.5129\n",
      "epoch 202, run 30, loss 8.74982\n",
      "epoch 203, run 0, loss 9.21034\n",
      "epoch 203, run 10, loss 10.1314\n",
      "epoch 203, run 20, loss 14.276\n",
      "epoch 203, run 30, loss 10.5919\n",
      "epoch 204, run 0, loss 10.1314\n",
      "epoch 204, run 10, loss 9.21034\n",
      "epoch 204, run 20, loss 13.355\n",
      "epoch 204, run 30, loss 13.355\n",
      "epoch 205, run 0, loss 9.21034\n",
      "epoch 205, run 10, loss 8.28931\n",
      "epoch 205, run 20, loss 8.74982\n",
      "epoch 205, run 30, loss 11.5129\n",
      "epoch 206, run 0, loss 11.0524\n",
      "epoch 206, run 10, loss 5.98672\n",
      "epoch 206, run 20, loss 12.434\n",
      "epoch 206, run 30, loss 11.5129\n",
      "epoch 207, run 0, loss 13.355\n",
      "epoch 207, run 10, loss 5.06569\n",
      "epoch 207, run 20, loss 11.5129\n",
      "epoch 207, run 30, loss 11.9734\n",
      "epoch 208, run 0, loss 10.5919\n",
      "epoch 208, run 10, loss 5.06569\n",
      "epoch 208, run 20, loss 9.21034\n",
      "epoch 208, run 30, loss 9.21034\n",
      "epoch 209, run 0, loss 12.434\n",
      "epoch 209, run 10, loss 7.36827\n",
      "epoch 209, run 20, loss 10.5919\n",
      "epoch 209, run 30, loss 9.67086\n",
      "epoch 210, run 0, loss 10.5919\n",
      "epoch 210, run 10, loss 5.98672\n",
      "epoch 210, run 20, loss 11.0524\n",
      "epoch 210, run 30, loss 11.9734\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 211, run 0, loss 8.28931\n",
      "epoch 211, run 10, loss 4.14465\n",
      "epoch 211, run 20, loss 7.82879\n",
      "epoch 211, run 30, loss 11.0524\n",
      "epoch 212, run 0, loss 10.1314\n",
      "epoch 212, run 10, loss 4.14465\n",
      "epoch 212, run 20, loss 8.28931\n",
      "epoch 212, run 30, loss 10.1314\n",
      "epoch 213, run 0, loss 11.9734\n",
      "epoch 213, run 10, loss 3.68414\n",
      "epoch 213, run 20, loss 6.44724\n",
      "epoch 213, run 30, loss 10.1314\n",
      "epoch 214, run 0, loss 11.5129\n",
      "epoch 214, run 10, loss 7.36827\n",
      "epoch 214, run 20, loss 6.44724\n",
      "epoch 214, run 30, loss 10.5919\n",
      "epoch 215, run 0, loss 10.1314\n",
      "epoch 215, run 10, loss 8.74982\n",
      "epoch 215, run 20, loss 8.28931\n",
      "epoch 215, run 30, loss 9.21034\n",
      "epoch 216, run 0, loss 10.5919\n",
      "epoch 216, run 10, loss 5.5262\n",
      "epoch 216, run 20, loss 11.5129\n",
      "epoch 216, run 30, loss 12.8945\n",
      "epoch 217, run 0, loss 9.67086\n",
      "epoch 217, run 10, loss 3.68414\n",
      "epoch 217, run 20, loss 9.21034\n",
      "epoch 217, run 30, loss 11.9734\n",
      "epoch 218, run 0, loss 10.1314\n",
      "epoch 218, run 10, loss 2.30258\n",
      "epoch 218, run 20, loss 8.28931\n",
      "epoch 218, run 30, loss 10.1314\n",
      "epoch 219, run 0, loss 11.9734\n",
      "epoch 219, run 10, loss 3.68414\n",
      "epoch 219, run 20, loss 8.28931\n",
      "epoch 219, run 30, loss 11.0524\n",
      "epoch 220, run 0, loss 11.5129\n",
      "epoch 220, run 10, loss 8.28931\n",
      "epoch 220, run 20, loss 8.28931\n",
      "epoch 220, run 30, loss 13.8155\n",
      "epoch 221, run 0, loss 10.1314\n",
      "epoch 221, run 10, loss 10.1314\n",
      "epoch 221, run 20, loss 9.21034\n",
      "epoch 221, run 30, loss 12.434\n",
      "epoch 222, run 0, loss 11.5129\n",
      "epoch 222, run 10, loss 8.74982\n",
      "epoch 222, run 20, loss 8.74982\n",
      "epoch 222, run 30, loss 9.21034\n",
      "epoch 223, run 0, loss 14.276\n",
      "epoch 223, run 10, loss 10.5919\n",
      "epoch 223, run 20, loss 6.90775\n",
      "epoch 223, run 30, loss 11.0524\n",
      "epoch 224, run 0, loss 12.8945\n",
      "epoch 224, run 10, loss 13.355\n",
      "epoch 224, run 20, loss 5.06569\n",
      "epoch 224, run 30, loss 11.9734\n",
      "epoch 225, run 0, loss 8.74982\n",
      "epoch 225, run 10, loss 11.0524\n",
      "epoch 225, run 20, loss 5.06569\n",
      "epoch 225, run 30, loss 9.21034\n",
      "epoch 226, run 0, loss 11.9734\n",
      "epoch 226, run 10, loss 11.9734\n",
      "epoch 226, run 20, loss 5.5262\n",
      "epoch 226, run 30, loss 10.5919\n",
      "epoch 227, run 0, loss 11.5129\n",
      "epoch 227, run 10, loss 12.434\n",
      "epoch 227, run 20, loss 5.5262\n",
      "epoch 227, run 30, loss 11.0524\n",
      "epoch 228, run 0, loss 9.21034\n",
      "epoch 228, run 10, loss 9.21034\n",
      "epoch 228, run 20, loss 3.22362\n",
      "epoch 228, run 30, loss 9.67086\n",
      "epoch 229, run 0, loss 10.5919\n",
      "epoch 229, run 10, loss 10.1314\n",
      "epoch 229, run 20, loss 4.60517\n",
      "epoch 229, run 30, loss 8.28931\n",
      "epoch 230, run 0, loss 11.0524\n",
      "epoch 230, run 10, loss 11.9734\n",
      "epoch 230, run 20, loss 3.68414\n",
      "epoch 230, run 30, loss 6.44724\n",
      "epoch 231, run 0, loss 7.82879\n",
      "epoch 231, run 10, loss 11.0524\n",
      "epoch 231, run 20, loss 6.44724\n",
      "epoch 231, run 30, loss 6.44724\n",
      "epoch 232, run 0, loss 8.28931\n",
      "epoch 232, run 10, loss 9.67086\n",
      "epoch 232, run 20, loss 8.74982\n",
      "epoch 232, run 30, loss 7.36827\n",
      "epoch 233, run 0, loss 5.98672\n",
      "epoch 233, run 10, loss 10.5919\n",
      "epoch 233, run 20, loss 6.44724\n",
      "epoch 233, run 30, loss 11.9734\n",
      "epoch 234, run 0, loss 6.44724\n",
      "epoch 234, run 10, loss 10.5919\n",
      "epoch 234, run 20, loss 4.60517\n",
      "epoch 234, run 30, loss 10.1314\n",
      "epoch 235, run 0, loss 8.74982\n",
      "epoch 235, run 10, loss 9.21034\n",
      "epoch 235, run 20, loss 3.22362\n",
      "epoch 235, run 30, loss 8.74982\n",
      "epoch 236, run 0, loss 11.0524\n",
      "epoch 236, run 10, loss 12.8945\n",
      "epoch 236, run 20, loss 3.68414\n",
      "epoch 236, run 30, loss 8.74982\n",
      "epoch 237, run 0, loss 9.21034\n",
      "epoch 237, run 10, loss 11.5129\n",
      "epoch 237, run 20, loss 7.36827\n",
      "epoch 237, run 30, loss 8.74982\n",
      "epoch 238, run 0, loss 8.74982\n",
      "epoch 238, run 10, loss 10.5919\n",
      "epoch 238, run 20, loss 9.67086\n",
      "epoch 238, run 30, loss 10.1314\n",
      "epoch 239, run 0, loss 8.28931\n",
      "epoch 239, run 10, loss 11.0524\n",
      "epoch 239, run 20, loss 8.74982\n",
      "epoch 239, run 30, loss 9.67086\n",
      "epoch 240, run 0, loss 8.28931\n",
      "epoch 240, run 10, loss 13.355\n",
      "epoch 240, run 20, loss 10.1314\n",
      "epoch 240, run 30, loss 7.36827\n",
      "epoch 241, run 0, loss 9.67086\n",
      "epoch 241, run 10, loss 12.434\n",
      "epoch 241, run 20, loss 13.355\n",
      "epoch 241, run 30, loss 5.06569\n",
      "epoch 242, run 0, loss 8.74982\n",
      "epoch 242, run 10, loss 8.74982\n",
      "epoch 242, run 20, loss 11.5129\n",
      "epoch 242, run 30, loss 5.5262\n",
      "epoch 243, run 0, loss 6.90775\n",
      "epoch 243, run 10, loss 11.0524\n",
      "epoch 243, run 20, loss 10.5919\n",
      "epoch 243, run 30, loss 4.14465\n",
      "epoch 244, run 0, loss 5.06569\n",
      "epoch 244, run 10, loss 12.434\n",
      "epoch 244, run 20, loss 11.5129\n",
      "epoch 244, run 30, loss 5.98672\n",
      "epoch 245, run 0, loss 5.06569\n",
      "epoch 245, run 10, loss 9.21034\n",
      "epoch 245, run 20, loss 9.21034\n",
      "epoch 245, run 30, loss 4.60517\n",
      "epoch 246, run 0, loss 5.5262\n",
      "epoch 246, run 10, loss 11.0524\n",
      "epoch 246, run 20, loss 8.74982\n",
      "epoch 246, run 30, loss 5.5262\n",
      "epoch 247, run 0, loss 5.5262\n",
      "epoch 247, run 10, loss 11.0524\n",
      "epoch 247, run 20, loss 11.0524\n",
      "epoch 247, run 30, loss 4.60517\n",
      "epoch 248, run 0, loss 3.22362\n",
      "epoch 248, run 10, loss 9.21034\n",
      "epoch 248, run 20, loss 11.9734\n",
      "epoch 248, run 30, loss 5.98672\n",
      "epoch 249, run 0, loss 4.14465\n",
      "epoch 249, run 10, loss 7.82879\n",
      "epoch 249, run 20, loss 11.0524\n",
      "epoch 249, run 30, loss 8.74982\n",
      "epoch 250, run 0, loss 3.22362\n",
      "epoch 250, run 10, loss 5.98672\n",
      "epoch 250, run 20, loss 10.5919\n",
      "epoch 250, run 30, loss 7.36827\n",
      "epoch 251, run 0, loss 6.44724\n",
      "epoch 251, run 10, loss 5.98672\n",
      "epoch 251, run 20, loss 11.9734\n",
      "epoch 251, run 30, loss 5.5262\n",
      "epoch 252, run 0, loss 8.28931\n",
      "epoch 252, run 10, loss 7.36827\n",
      "epoch 252, run 20, loss 9.67086\n",
      "epoch 252, run 30, loss 3.68414\n",
      "epoch 253, run 0, loss 6.44724\n",
      "epoch 253, run 10, loss 11.9734\n",
      "epoch 253, run 20, loss 12.434\n",
      "epoch 253, run 30, loss 3.22362\n",
      "epoch 254, run 0, loss 4.60517\n",
      "epoch 254, run 10, loss 9.67086\n",
      "epoch 254, run 20, loss 12.8945\n",
      "epoch 254, run 30, loss 5.5262\n",
      "epoch 255, run 0, loss 2.7631\n",
      "epoch 255, run 10, loss 8.74982\n",
      "epoch 255, run 20, loss 10.1314\n",
      "epoch 255, run 30, loss 9.21034\n",
      "epoch 256, run 0, loss 3.68414\n",
      "epoch 256, run 10, loss 8.74982\n",
      "epoch 256, run 20, loss 11.0524\n",
      "epoch 256, run 30, loss 9.67086\n",
      "epoch 257, run 0, loss 7.36827\n",
      "epoch 257, run 10, loss 8.28931\n",
      "epoch 257, run 20, loss 12.434\n",
      "epoch 257, run 30, loss 9.67086\n",
      "epoch 258, run 0, loss 9.67086\n",
      "epoch 258, run 10, loss 10.5919\n",
      "epoch 258, run 20, loss 12.8945\n",
      "epoch 258, run 30, loss 11.9734\n",
      "epoch 259, run 0, loss 8.74982\n",
      "epoch 259, run 10, loss 9.67086\n",
      "epoch 259, run 20, loss 10.1314\n",
      "epoch 259, run 30, loss 11.9734\n",
      "epoch 260, run 0, loss 10.1314\n",
      "epoch 260, run 10, loss 7.36827\n",
      "epoch 260, run 20, loss 10.5919\n",
      "epoch 260, run 30, loss 10.1314\n",
      "epoch 261, run 0, loss 13.8155\n",
      "epoch 261, run 10, loss 4.60517\n",
      "epoch 261, run 20, loss 11.5129\n",
      "epoch 261, run 30, loss 11.9734\n",
      "epoch 262, run 0, loss 11.5129\n",
      "epoch 262, run 10, loss 5.5262\n",
      "epoch 262, run 20, loss 10.1314\n",
      "epoch 262, run 30, loss 9.67086\n",
      "epoch 263, run 0, loss 10.5919\n",
      "epoch 263, run 10, loss 4.60517\n",
      "epoch 263, run 20, loss 9.21034\n",
      "epoch 263, run 30, loss 9.21034\n",
      "epoch 264, run 0, loss 11.5129\n",
      "epoch 264, run 10, loss 5.98672\n",
      "epoch 264, run 20, loss 11.5129\n",
      "epoch 264, run 30, loss 11.0524\n",
      "epoch 265, run 0, loss 9.21034\n",
      "epoch 265, run 10, loss 4.60517\n",
      "epoch 265, run 20, loss 9.67086\n",
      "epoch 265, run 30, loss 11.9734\n",
      "epoch 266, run 0, loss 9.21034\n",
      "epoch 266, run 10, loss 5.5262\n",
      "epoch 266, run 20, loss 9.67086\n",
      "epoch 266, run 30, loss 12.434\n",
      "epoch 267, run 0, loss 11.0524\n",
      "epoch 267, run 10, loss 4.60517\n",
      "epoch 267, run 20, loss 7.36827\n",
      "epoch 267, run 30, loss 10.1314\n",
      "epoch 268, run 0, loss 11.5129\n",
      "epoch 268, run 10, loss 5.98672\n",
      "epoch 268, run 20, loss 6.90775\n",
      "epoch 268, run 30, loss 11.5129\n",
      "epoch 269, run 0, loss 10.5919\n",
      "epoch 269, run 10, loss 8.74982\n",
      "epoch 269, run 20, loss 6.90775\n",
      "epoch 269, run 30, loss 10.5919\n",
      "epoch 270, run 0, loss 10.5919\n",
      "epoch 270, run 10, loss 7.36827\n",
      "epoch 270, run 20, loss 11.0524\n",
      "epoch 270, run 30, loss 11.0524\n",
      "epoch 271, run 0, loss 11.5129\n",
      "epoch 271, run 10, loss 5.06569\n",
      "epoch 271, run 20, loss 10.5919\n",
      "epoch 271, run 30, loss 13.355\n",
      "epoch 272, run 0, loss 9.21034\n",
      "epoch 272, run 10, loss 3.68414\n",
      "epoch 272, run 20, loss 9.21034\n",
      "epoch 272, run 30, loss 10.5919\n",
      "epoch 273, run 0, loss 12.8945\n",
      "epoch 273, run 10, loss 3.22362\n",
      "epoch 273, run 20, loss 7.82879\n",
      "epoch 273, run 30, loss 10.1314\n",
      "epoch 274, run 0, loss 12.8945\n",
      "epoch 274, run 10, loss 5.98672\n",
      "epoch 274, run 20, loss 8.28931\n",
      "epoch 274, run 30, loss 11.5129\n",
      "epoch 275, run 0, loss 10.1314\n",
      "epoch 275, run 10, loss 8.74982\n",
      "epoch 275, run 20, loss 9.67086\n",
      "epoch 275, run 30, loss 13.8155\n",
      "epoch 276, run 0, loss 11.5129\n",
      "epoch 276, run 10, loss 9.67086\n",
      "epoch 276, run 20, loss 9.21034\n",
      "epoch 276, run 30, loss 11.0524\n",
      "epoch 277, run 0, loss 12.8945\n",
      "epoch 277, run 10, loss 10.1314\n",
      "epoch 277, run 20, loss 7.36827\n",
      "epoch 277, run 30, loss 9.67086\n",
      "epoch 278, run 0, loss 12.434\n",
      "epoch 278, run 10, loss 11.9734\n",
      "epoch 278, run 20, loss 5.5262\n",
      "epoch 278, run 30, loss 11.9734\n",
      "epoch 279, run 0, loss 9.67086\n",
      "epoch 279, run 10, loss 11.9734\n",
      "epoch 279, run 20, loss 5.5262\n",
      "epoch 279, run 30, loss 11.5129\n",
      "epoch 280, run 0, loss 10.1314\n",
      "epoch 280, run 10, loss 9.67086\n",
      "epoch 280, run 20, loss 5.06569\n",
      "epoch 280, run 30, loss 9.67086\n",
      "epoch 281, run 0, loss 11.5129\n",
      "epoch 281, run 10, loss 11.5129\n",
      "epoch 281, run 20, loss 6.44724\n",
      "epoch 281, run 30, loss 12.434\n",
      "epoch 282, run 0, loss 10.1314\n",
      "epoch 282, run 10, loss 9.21034\n",
      "epoch 282, run 20, loss 5.06569\n",
      "epoch 282, run 30, loss 10.1314\n",
      "epoch 283, run 0, loss 9.67086\n",
      "epoch 283, run 10, loss 9.67086\n",
      "epoch 283, run 20, loss 5.06569\n",
      "epoch 283, run 30, loss 9.21034\n",
      "epoch 284, run 0, loss 11.0524\n",
      "epoch 284, run 10, loss 11.0524\n",
      "epoch 284, run 20, loss 5.06569\n",
      "epoch 284, run 30, loss 7.36827\n",
      "epoch 285, run 0, loss 9.67086\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 285, run 10, loss 11.9734\n",
      "epoch 285, run 20, loss 4.14465\n",
      "epoch 285, run 30, loss 5.98672\n",
      "epoch 286, run 0, loss 9.67086\n",
      "epoch 286, run 10, loss 11.9734\n",
      "epoch 286, run 20, loss 8.28931\n",
      "epoch 286, run 30, loss 6.90775\n",
      "epoch 287, run 0, loss 7.36827\n",
      "epoch 287, run 10, loss 10.5919\n",
      "epoch 287, run 20, loss 8.28931\n",
      "epoch 287, run 30, loss 9.21034\n",
      "epoch 288, run 0, loss 6.90775\n",
      "epoch 288, run 10, loss 11.5129\n",
      "epoch 288, run 20, loss 5.98672\n",
      "epoch 288, run 30, loss 11.5129\n",
      "epoch 289, run 0, loss 6.90775\n",
      "epoch 289, run 10, loss 10.5919\n",
      "epoch 289, run 20, loss 4.14465\n",
      "epoch 289, run 30, loss 7.82879\n",
      "epoch 290, run 0, loss 11.5129\n",
      "epoch 290, run 10, loss 11.0524\n",
      "epoch 290, run 20, loss 2.7631\n",
      "epoch 290, run 30, loss 8.74982\n",
      "epoch 291, run 0, loss 10.5919\n",
      "epoch 291, run 10, loss 13.355\n",
      "epoch 291, run 20, loss 4.14465\n",
      "epoch 291, run 30, loss 7.36827\n",
      "epoch 292, run 0, loss 9.21034\n",
      "epoch 292, run 10, loss 10.1314\n",
      "epoch 292, run 20, loss 9.21034\n",
      "epoch 292, run 30, loss 9.67086\n",
      "epoch 293, run 0, loss 8.28931\n",
      "epoch 293, run 10, loss 10.5919\n",
      "epoch 293, run 20, loss 10.1314\n",
      "epoch 293, run 30, loss 8.74982\n",
      "epoch 294, run 0, loss 8.74982\n",
      "epoch 294, run 10, loss 11.5129\n",
      "epoch 294, run 20, loss 9.67086\n",
      "epoch 294, run 30, loss 8.74982\n",
      "epoch 295, run 0, loss 9.21034\n",
      "epoch 295, run 10, loss 14.276\n",
      "epoch 295, run 20, loss 11.0524\n",
      "epoch 295, run 30, loss 5.98672\n",
      "epoch 296, run 0, loss 9.21034\n",
      "epoch 296, run 10, loss 11.0524\n",
      "epoch 296, run 20, loss 12.8945\n",
      "epoch 296, run 30, loss 5.5262\n",
      "epoch 297, run 0, loss 7.36827\n",
      "epoch 297, run 10, loss 10.1314\n",
      "epoch 297, run 20, loss 10.1314\n",
      "epoch 297, run 30, loss 5.06569\n",
      "epoch 298, run 0, loss 5.5262\n",
      "epoch 298, run 10, loss 11.9734\n",
      "epoch 298, run 20, loss 12.8945\n",
      "epoch 298, run 30, loss 6.90775\n",
      "epoch 299, run 0, loss 5.06569\n",
      "epoch 299, run 10, loss 11.0524\n",
      "epoch 299, run 20, loss 10.1314\n",
      "epoch 299, run 30, loss 5.98672\n",
      "epoch 300, run 0, loss 4.60517\n",
      "epoch 300, run 10, loss 9.67086\n",
      "epoch 300, run 20, loss 8.74982\n",
      "epoch 300, run 30, loss 5.06569\n",
      "epoch 301, run 0, loss 6.44724\n",
      "epoch 301, run 10, loss 11.9734\n",
      "epoch 301, run 20, loss 10.5919\n",
      "epoch 301, run 30, loss 4.60517\n",
      "epoch 302, run 0, loss 5.06569\n",
      "epoch 302, run 10, loss 10.1314\n",
      "epoch 302, run 20, loss 11.9734\n",
      "epoch 302, run 30, loss 4.14465\n",
      "epoch 303, run 0, loss 5.06569\n",
      "epoch 303, run 10, loss 8.74982\n",
      "epoch 303, run 20, loss 11.5129\n",
      "epoch 303, run 30, loss 7.36827\n",
      "epoch 304, run 0, loss 4.60517\n",
      "epoch 304, run 10, loss 7.82879\n",
      "epoch 304, run 20, loss 10.5919\n",
      "epoch 304, run 30, loss 9.21034\n",
      "epoch 305, run 0, loss 4.14465\n",
      "epoch 305, run 10, loss 5.98672\n",
      "epoch 305, run 20, loss 11.5129\n",
      "epoch 305, run 30, loss 5.98672\n",
      "epoch 306, run 0, loss 8.28931\n",
      "epoch 306, run 10, loss 6.44724\n",
      "epoch 306, run 20, loss 10.1314\n",
      "epoch 306, run 30, loss 4.14465\n",
      "epoch 307, run 0, loss 8.28931\n",
      "epoch 307, run 10, loss 9.21034\n",
      "epoch 307, run 20, loss 10.1314\n",
      "epoch 307, run 30, loss 2.30259\n",
      "epoch 308, run 0, loss 5.98672\n",
      "epoch 308, run 10, loss 11.0524\n",
      "epoch 308, run 20, loss 12.434\n",
      "epoch 308, run 30, loss 3.68414\n",
      "epoch 309, run 0, loss 4.14465\n",
      "epoch 309, run 10, loss 8.28931\n",
      "epoch 309, run 20, loss 11.0524\n",
      "epoch 309, run 30, loss 9.21034\n",
      "epoch 310, run 0, loss 2.30259\n",
      "epoch 310, run 10, loss 8.74982\n",
      "epoch 310, run 20, loss 10.5919\n",
      "epoch 310, run 30, loss 10.5919\n",
      "epoch 311, run 0, loss 4.14465\n",
      "epoch 311, run 10, loss 7.36827\n",
      "epoch 311, run 20, loss 11.5129\n",
      "epoch 311, run 30, loss 8.28931\n",
      "epoch 312, run 0, loss 9.67086\n",
      "epoch 312, run 10, loss 10.1314\n",
      "epoch 312, run 20, loss 14.7365\n",
      "epoch 312, run 30, loss 11.0524\n",
      "epoch 313, run 0, loss 10.1314\n",
      "epoch 313, run 10, loss 8.28931\n",
      "epoch 313, run 20, loss 11.9734\n",
      "epoch 313, run 30, loss 13.8155\n",
      "epoch 314, run 0, loss 9.21034\n",
      "epoch 314, run 10, loss 8.74982\n",
      "epoch 314, run 20, loss 8.74982\n",
      "epoch 314, run 30, loss 11.5129\n",
      "epoch 315, run 0, loss 11.0524\n",
      "epoch 315, run 10, loss 5.98672\n",
      "epoch 315, run 20, loss 11.9734\n",
      "epoch 315, run 30, loss 11.5129\n",
      "epoch 316, run 0, loss 13.355\n",
      "epoch 316, run 10, loss 5.5262\n",
      "epoch 316, run 20, loss 11.0524\n",
      "epoch 316, run 30, loss 11.5129\n",
      "epoch 317, run 0, loss 10.1314\n",
      "epoch 317, run 10, loss 5.06569\n",
      "epoch 317, run 20, loss 9.21034\n",
      "epoch 317, run 30, loss 8.74982\n",
      "epoch 318, run 0, loss 12.434\n",
      "epoch 318, run 10, loss 6.90775\n",
      "epoch 318, run 20, loss 11.0524\n",
      "epoch 318, run 30, loss 10.5919\n",
      "epoch 319, run 0, loss 9.67086\n",
      "epoch 319, run 10, loss 5.5262\n",
      "epoch 319, run 20, loss 11.5129\n",
      "epoch 319, run 30, loss 12.434\n",
      "epoch 320, run 0, loss 8.74982\n",
      "epoch 320, run 10, loss 5.06569\n",
      "epoch 320, run 20, loss 7.82879\n",
      "epoch 320, run 30, loss 11.0524\n",
      "epoch 321, run 0, loss 11.0524\n",
      "epoch 321, run 10, loss 4.60517\n",
      "epoch 321, run 20, loss 9.21034\n",
      "epoch 321, run 30, loss 10.1314\n",
      "epoch 322, run 0, loss 11.9734\n",
      "epoch 322, run 10, loss 4.14465\n",
      "epoch 322, run 20, loss 6.44724\n",
      "epoch 322, run 30, loss 11.5129\n",
      "epoch 323, run 0, loss 11.5129\n",
      "epoch 323, run 10, loss 7.82879\n",
      "epoch 323, run 20, loss 5.98672\n",
      "epoch 323, run 30, loss 10.1314\n",
      "epoch 324, run 0, loss 10.1314\n",
      "epoch 324, run 10, loss 9.21034\n",
      "epoch 324, run 20, loss 9.67086\n",
      "epoch 324, run 30, loss 9.21034\n",
      "epoch 325, run 0, loss 11.5129\n",
      "epoch 325, run 10, loss 5.98672\n",
      "epoch 325, run 20, loss 11.0524\n",
      "epoch 325, run 30, loss 12.8945\n",
      "epoch 326, run 0, loss 9.67086\n",
      "epoch 326, run 10, loss 4.14465\n",
      "epoch 326, run 20, loss 10.1314\n",
      "epoch 326, run 30, loss 11.0524\n",
      "epoch 327, run 0, loss 10.5919\n",
      "epoch 327, run 10, loss 2.30259\n",
      "epoch 327, run 20, loss 9.67086\n",
      "epoch 327, run 30, loss 10.1314\n",
      "epoch 328, run 0, loss 12.8945\n",
      "epoch 328, run 10, loss 3.68414\n",
      "epoch 328, run 20, loss 7.36827\n",
      "epoch 328, run 30, loss 11.9734\n",
      "epoch 329, run 0, loss 11.0524\n",
      "epoch 329, run 10, loss 9.21034\n",
      "epoch 329, run 20, loss 8.74982\n",
      "epoch 329, run 30, loss 13.355\n",
      "epoch 330, run 0, loss 10.5919\n",
      "epoch 330, run 10, loss 10.1314\n",
      "epoch 330, run 20, loss 9.67086\n",
      "epoch 330, run 30, loss 13.355\n",
      "epoch 331, run 0, loss 11.5129\n",
      "epoch 331, run 10, loss 8.74982\n",
      "epoch 331, run 20, loss 8.74982\n",
      "epoch 331, run 30, loss 8.28931\n",
      "epoch 332, run 0, loss 14.7365\n",
      "epoch 332, run 10, loss 11.0524\n",
      "epoch 332, run 20, loss 6.44724\n",
      "epoch 332, run 30, loss 11.5129\n",
      "epoch 333, run 0, loss 11.9734\n",
      "epoch 333, run 10, loss 13.8155\n",
      "epoch 333, run 20, loss 5.06569\n",
      "epoch 333, run 30, loss 11.9734\n",
      "epoch 334, run 0, loss 9.21034\n",
      "epoch 334, run 10, loss 11.0524\n",
      "epoch 334, run 20, loss 5.06569\n",
      "epoch 334, run 30, loss 9.67086\n",
      "epoch 335, run 0, loss 11.5129\n",
      "epoch 335, run 10, loss 11.5129\n",
      "epoch 335, run 20, loss 5.98672\n",
      "epoch 335, run 30, loss 10.5919\n",
      "epoch 336, run 0, loss 11.5129\n",
      "epoch 336, run 10, loss 11.0524\n",
      "epoch 336, run 20, loss 5.5262\n",
      "epoch 336, run 30, loss 11.0524\n",
      "epoch 337, run 0, loss 9.21034\n",
      "epoch 337, run 10, loss 9.21034\n",
      "epoch 337, run 20, loss 3.68414\n",
      "epoch 337, run 30, loss 8.28931\n",
      "epoch 338, run 0, loss 11.5129\n",
      "epoch 338, run 10, loss 10.5919\n",
      "epoch 338, run 20, loss 4.14465\n",
      "epoch 338, run 30, loss 8.28931\n",
      "epoch 339, run 0, loss 11.0524\n",
      "epoch 339, run 10, loss 11.9734\n",
      "epoch 339, run 20, loss 3.68414\n",
      "epoch 339, run 30, loss 5.98672\n",
      "epoch 340, run 0, loss 8.28931\n",
      "epoch 340, run 10, loss 11.0524\n",
      "epoch 340, run 20, loss 6.44724\n",
      "epoch 340, run 30, loss 5.98672\n",
      "epoch 341, run 0, loss 8.74982\n",
      "epoch 341, run 10, loss 10.1314\n",
      "epoch 341, run 20, loss 8.74982\n",
      "epoch 341, run 30, loss 8.28931\n",
      "epoch 342, run 0, loss 6.44724\n",
      "epoch 342, run 10, loss 11.5129\n",
      "epoch 342, run 20, loss 5.5262\n",
      "epoch 342, run 30, loss 11.9734\n",
      "epoch 343, run 0, loss 5.98672\n",
      "epoch 343, run 10, loss 10.1314\n",
      "epoch 343, run 20, loss 4.60517\n",
      "epoch 343, run 30, loss 9.21034\n",
      "epoch 344, run 0, loss 9.67086\n",
      "epoch 344, run 10, loss 9.21034\n",
      "epoch 344, run 20, loss 2.30258\n",
      "epoch 344, run 30, loss 9.21034\n",
      "epoch 345, run 0, loss 11.0524\n",
      "epoch 345, run 10, loss 12.8945\n",
      "epoch 345, run 20, loss 4.14465\n",
      "epoch 345, run 30, loss 8.74982\n",
      "epoch 346, run 0, loss 9.67086\n",
      "epoch 346, run 10, loss 10.5919\n",
      "epoch 346, run 20, loss 8.28931\n",
      "epoch 346, run 30, loss 8.74982\n",
      "epoch 347, run 0, loss 9.21034\n",
      "epoch 347, run 10, loss 10.5919\n",
      "epoch 347, run 20, loss 10.1314\n",
      "epoch 347, run 30, loss 10.1314\n",
      "epoch 348, run 0, loss 7.36827\n",
      "epoch 348, run 10, loss 12.434\n",
      "epoch 348, run 20, loss 8.74982\n",
      "epoch 348, run 30, loss 8.74982\n",
      "epoch 349, run 0, loss 9.21034\n",
      "epoch 349, run 10, loss 13.8155\n",
      "epoch 349, run 20, loss 10.1314\n",
      "epoch 349, run 30, loss 7.36827\n",
      "epoch 350, run 0, loss 9.67086\n",
      "epoch 350, run 10, loss 12.8945\n",
      "epoch 350, run 20, loss 14.276\n",
      "epoch 350, run 30, loss 5.06569\n",
      "epoch 351, run 0, loss 8.74982\n",
      "epoch 351, run 10, loss 7.82879\n",
      "epoch 351, run 20, loss 11.0524\n",
      "epoch 351, run 30, loss 5.5262\n",
      "epoch 352, run 0, loss 5.98672\n",
      "epoch 352, run 10, loss 11.9734\n",
      "epoch 352, run 20, loss 10.5919\n",
      "epoch 352, run 30, loss 5.06569\n",
      "epoch 353, run 0, loss 5.06569\n",
      "epoch 353, run 10, loss 11.5129\n",
      "epoch 353, run 20, loss 11.5129\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 353, run 30, loss 5.98672\n",
      "epoch 354, run 0, loss 5.06569\n",
      "epoch 354, run 10, loss 9.21034\n",
      "epoch 354, run 20, loss 9.21034\n",
      "epoch 354, run 30, loss 4.14465\n",
      "epoch 355, run 0, loss 6.44724\n",
      "epoch 355, run 10, loss 11.0524\n",
      "epoch 355, run 20, loss 9.67086\n",
      "epoch 355, run 30, loss 5.06569\n",
      "epoch 356, run 0, loss 5.98672\n",
      "epoch 356, run 10, loss 11.0524\n",
      "epoch 356, run 20, loss 11.5129\n",
      "epoch 356, run 30, loss 4.60517\n",
      "epoch 357, run 0, loss 3.68414\n",
      "epoch 357, run 10, loss 8.28931\n",
      "epoch 357, run 20, loss 11.0524\n",
      "epoch 357, run 30, loss 5.98672\n",
      "epoch 358, run 0, loss 4.14465\n",
      "epoch 358, run 10, loss 8.28931\n",
      "epoch 358, run 20, loss 11.5129\n",
      "epoch 358, run 30, loss 8.74982\n",
      "epoch 359, run 0, loss 3.22362\n",
      "epoch 359, run 10, loss 5.98672\n",
      "epoch 359, run 20, loss 10.5919\n",
      "epoch 359, run 30, loss 7.36827\n",
      "epoch 360, run 0, loss 6.90775\n",
      "epoch 360, run 10, loss 5.98672\n",
      "epoch 360, run 20, loss 11.0524\n",
      "epoch 360, run 30, loss 5.5262\n",
      "epoch 361, run 0, loss 8.74982\n",
      "epoch 361, run 10, loss 8.28931\n",
      "epoch 361, run 20, loss 9.21034\n",
      "epoch 361, run 30, loss 3.22362\n",
      "epoch 362, run 0, loss 5.5262\n",
      "epoch 362, run 10, loss 11.9734\n",
      "epoch 362, run 20, loss 12.434\n",
      "epoch 362, run 30, loss 3.68414\n",
      "epoch 363, run 0, loss 4.14465\n",
      "epoch 363, run 10, loss 9.67086\n",
      "epoch 363, run 20, loss 12.434\n",
      "epoch 363, run 30, loss 5.98672\n",
      "epoch 364, run 0, loss 2.30258\n",
      "epoch 364, run 10, loss 8.74982\n",
      "epoch 364, run 20, loss 10.1314\n",
      "epoch 364, run 30, loss 9.21034\n",
      "epoch 365, run 0, loss 3.68414\n",
      "epoch 365, run 10, loss 8.74982\n",
      "epoch 365, run 20, loss 11.5129\n",
      "epoch 365, run 30, loss 9.21034\n",
      "epoch 366, run 0, loss 8.74982\n",
      "epoch 366, run 10, loss 8.28931\n",
      "epoch 366, run 20, loss 13.355\n",
      "epoch 366, run 30, loss 9.21034\n",
      "epoch 367, run 0, loss 10.5919\n",
      "epoch 367, run 10, loss 10.1314\n",
      "epoch 367, run 20, loss 11.9734\n",
      "epoch 367, run 30, loss 12.8945\n",
      "epoch 368, run 0, loss 8.28931\n",
      "epoch 368, run 10, loss 8.28931\n",
      "epoch 368, run 20, loss 9.67086\n",
      "epoch 368, run 30, loss 11.5129\n",
      "epoch 369, run 0, loss 10.5919\n",
      "epoch 369, run 10, loss 7.36827\n",
      "epoch 369, run 20, loss 10.5919\n",
      "epoch 369, run 30, loss 10.1314\n",
      "epoch 370, run 0, loss 14.276\n",
      "epoch 370, run 10, loss 5.06569\n",
      "epoch 370, run 20, loss 11.9734\n",
      "epoch 370, run 30, loss 11.5129\n",
      "epoch 371, run 0, loss 11.5129\n",
      "epoch 371, run 10, loss 5.5262\n",
      "epoch 371, run 20, loss 9.67086\n",
      "epoch 371, run 30, loss 9.21034\n",
      "epoch 372, run 0, loss 11.0524\n",
      "epoch 372, run 10, loss 5.06569\n",
      "epoch 372, run 20, loss 10.1314\n",
      "epoch 372, run 30, loss 9.67086\n",
      "epoch 373, run 0, loss 11.5129\n",
      "epoch 373, run 10, loss 5.98672\n",
      "epoch 373, run 20, loss 11.5129\n",
      "epoch 373, run 30, loss 10.5919\n",
      "epoch 374, run 0, loss 8.74982\n",
      "epoch 374, run 10, loss 3.68414\n",
      "epoch 374, run 20, loss 9.67086\n",
      "epoch 374, run 30, loss 11.9734\n",
      "epoch 375, run 0, loss 9.21034\n",
      "epoch 375, run 10, loss 5.06569\n",
      "epoch 375, run 20, loss 8.74982\n",
      "epoch 375, run 30, loss 11.0524\n",
      "epoch 376, run 0, loss 11.9734\n",
      "epoch 376, run 10, loss 4.14465\n",
      "epoch 376, run 20, loss 7.36827\n",
      "epoch 376, run 30, loss 10.5919\n",
      "epoch 377, run 0, loss 11.5129\n",
      "epoch 377, run 10, loss 5.98672\n",
      "epoch 377, run 20, loss 6.90775\n",
      "epoch 377, run 30, loss 11.0524\n",
      "epoch 378, run 0, loss 11.0524\n",
      "epoch 378, run 10, loss 8.28931\n",
      "epoch 378, run 20, loss 6.90775\n",
      "epoch 378, run 30, loss 10.1314\n",
      "epoch 379, run 0, loss 10.5919\n",
      "epoch 379, run 10, loss 7.36827\n",
      "epoch 379, run 20, loss 11.9734\n",
      "epoch 379, run 30, loss 11.5129\n",
      "epoch 380, run 0, loss 10.5919\n",
      "epoch 380, run 10, loss 5.5262\n",
      "epoch 380, run 20, loss 10.5919\n",
      "epoch 380, run 30, loss 12.8945\n",
      "epoch 381, run 0, loss 9.67086\n",
      "epoch 381, run 10, loss 3.22362\n",
      "epoch 381, run 20, loss 8.74982\n",
      "epoch 381, run 30, loss 10.1314\n",
      "epoch 382, run 0, loss 12.434\n",
      "epoch 382, run 10, loss 4.14465\n",
      "epoch 382, run 20, loss 8.28931\n",
      "epoch 382, run 30, loss 10.5919\n",
      "epoch 383, run 0, loss 12.434\n",
      "epoch 383, run 10, loss 6.44724\n",
      "epoch 383, run 20, loss 9.21034\n",
      "epoch 383, run 30, loss 11.9734\n",
      "epoch 384, run 0, loss 10.1314\n",
      "epoch 384, run 10, loss 9.67086\n",
      "epoch 384, run 20, loss 9.21034\n",
      "epoch 384, run 30, loss 13.355\n",
      "epoch 385, run 0, loss 11.5129\n",
      "epoch 385, run 10, loss 9.21034\n",
      "epoch 385, run 20, loss 8.74982\n",
      "epoch 385, run 30, loss 10.5919\n",
      "epoch 386, run 0, loss 13.355\n",
      "epoch 386, run 10, loss 9.21034\n",
      "epoch 386, run 20, loss 7.36827\n",
      "epoch 386, run 30, loss 10.5919\n",
      "epoch 387, run 0, loss 11.9734\n",
      "epoch 387, run 10, loss 13.355\n",
      "epoch 387, run 20, loss 5.98672\n",
      "epoch 387, run 30, loss 11.5129\n",
      "epoch 388, run 0, loss 9.67086\n",
      "epoch 388, run 10, loss 11.5129\n",
      "epoch 388, run 20, loss 5.06569\n",
      "epoch 388, run 30, loss 11.0524\n",
      "epoch 389, run 0, loss 10.5919\n",
      "epoch 389, run 10, loss 10.5919\n",
      "epoch 389, run 20, loss 5.06569\n",
      "epoch 389, run 30, loss 9.67086\n",
      "epoch 390, run 0, loss 11.9734\n",
      "epoch 390, run 10, loss 11.9734\n",
      "epoch 390, run 20, loss 5.98672\n",
      "epoch 390, run 30, loss 12.434\n",
      "epoch 391, run 0, loss 9.21034\n",
      "epoch 391, run 10, loss 8.74982\n",
      "epoch 391, run 20, loss 4.60517\n",
      "epoch 391, run 30, loss 9.67086\n",
      "epoch 392, run 0, loss 10.1314\n",
      "epoch 392, run 10, loss 9.21034\n",
      "epoch 392, run 20, loss 5.06569\n",
      "epoch 392, run 30, loss 8.74982\n",
      "epoch 393, run 0, loss 11.0524\n",
      "epoch 393, run 10, loss 10.5919\n",
      "epoch 393, run 20, loss 4.60517\n",
      "epoch 393, run 30, loss 7.36827\n",
      "epoch 394, run 0, loss 9.67086\n",
      "epoch 394, run 10, loss 11.9734\n",
      "epoch 394, run 20, loss 4.60517\n",
      "epoch 394, run 30, loss 6.44724\n",
      "epoch 395, run 0, loss 8.74982\n",
      "epoch 395, run 10, loss 11.5129\n",
      "epoch 395, run 20, loss 8.28931\n",
      "epoch 395, run 30, loss 6.44724\n",
      "epoch 396, run 0, loss 7.36827\n",
      "epoch 396, run 10, loss 10.5919\n",
      "epoch 396, run 20, loss 7.82879\n",
      "epoch 396, run 30, loss 9.67086\n",
      "epoch 397, run 0, loss 6.44724\n",
      "epoch 397, run 10, loss 11.5129\n",
      "epoch 397, run 20, loss 5.98672\n",
      "epoch 397, run 30, loss 11.0524\n",
      "epoch 398, run 0, loss 6.90775\n",
      "epoch 398, run 10, loss 10.1314\n",
      "epoch 398, run 20, loss 3.68414\n",
      "epoch 398, run 30, loss 8.74982\n",
      "epoch 399, run 0, loss 11.5129\n",
      "epoch 399, run 10, loss 11.9734\n",
      "epoch 399, run 20, loss 2.7631\n",
      "epoch 399, run 30, loss 8.74982\n",
      "epoch 400, run 0, loss 10.1314\n",
      "epoch 400, run 10, loss 13.355\n",
      "epoch 400, run 20, loss 5.06569\n",
      "epoch 400, run 30, loss 7.82879\n",
      "epoch 401, run 0, loss 8.74982\n",
      "epoch 401, run 10, loss 10.5919\n",
      "epoch 401, run 20, loss 9.67086\n",
      "epoch 401, run 30, loss 9.67086\n",
      "epoch 402, run 0, loss 8.74982\n",
      "epoch 402, run 10, loss 10.1314\n",
      "epoch 402, run 20, loss 9.67086\n",
      "epoch 402, run 30, loss 8.74982\n",
      "epoch 403, run 0, loss 9.21034\n",
      "epoch 403, run 10, loss 11.9734\n",
      "epoch 403, run 20, loss 8.74982\n",
      "epoch 403, run 30, loss 8.74982\n",
      "epoch 404, run 0, loss 9.21034\n",
      "epoch 404, run 10, loss 13.355\n",
      "epoch 404, run 20, loss 11.9734\n",
      "epoch 404, run 30, loss 5.98672\n",
      "epoch 405, run 0, loss 8.74982\n",
      "epoch 405, run 10, loss 10.1314\n",
      "epoch 405, run 20, loss 13.355\n",
      "epoch 405, run 30, loss 5.5262\n",
      "epoch 406, run 0, loss 7.36827\n",
      "epoch 406, run 10, loss 10.5919\n",
      "epoch 406, run 20, loss 10.1314\n",
      "epoch 406, run 30, loss 4.60517\n",
      "epoch 407, run 0, loss 5.5262\n",
      "epoch 407, run 10, loss 11.0524\n",
      "epoch 407, run 20, loss 12.8945\n",
      "epoch 407, run 30, loss 6.44724\n",
      "epoch 408, run 0, loss 5.5262\n",
      "epoch 408, run 10, loss 10.5919\n",
      "epoch 408, run 20, loss 9.21034\n",
      "epoch 408, run 30, loss 5.98672\n",
      "epoch 409, run 0, loss 4.60517\n",
      "epoch 409, run 10, loss 9.67086\n",
      "epoch 409, run 20, loss 8.74982\n",
      "epoch 409, run 30, loss 5.5262\n",
      "epoch 410, run 0, loss 5.98672\n",
      "epoch 410, run 10, loss 12.434\n",
      "epoch 410, run 20, loss 11.0524\n",
      "epoch 410, run 30, loss 4.14465\n",
      "epoch 411, run 0, loss 5.06569\n",
      "epoch 411, run 10, loss 10.1314\n",
      "epoch 411, run 20, loss 12.434\n",
      "epoch 411, run 30, loss 3.68414\n",
      "epoch 412, run 0, loss 5.5262\n",
      "epoch 412, run 10, loss 9.21034\n",
      "epoch 412, run 20, loss 12.434\n",
      "epoch 412, run 30, loss 8.74982\n",
      "epoch 413, run 0, loss 4.60517\n",
      "epoch 413, run 10, loss 7.36827\n",
      "epoch 413, run 20, loss 10.1314\n",
      "epoch 413, run 30, loss 8.74982\n",
      "epoch 414, run 0, loss 5.06569\n",
      "epoch 414, run 10, loss 6.44724\n",
      "epoch 414, run 20, loss 11.0524\n",
      "epoch 414, run 30, loss 5.98672\n",
      "epoch 415, run 0, loss 8.74982\n",
      "epoch 415, run 10, loss 6.44724\n",
      "epoch 415, run 20, loss 10.1314\n",
      "epoch 415, run 30, loss 4.60517\n",
      "epoch 416, run 0, loss 7.82879\n",
      "epoch 416, run 10, loss 10.1314\n",
      "epoch 416, run 20, loss 10.1314\n",
      "epoch 416, run 30, loss 2.30259\n",
      "epoch 417, run 0, loss 5.5262\n",
      "epoch 417, run 10, loss 11.5129\n",
      "epoch 417, run 20, loss 12.434\n",
      "epoch 417, run 30, loss 3.68414\n",
      "epoch 418, run 0, loss 3.68414\n",
      "epoch 418, run 10, loss 8.28931\n",
      "epoch 418, run 20, loss 10.1314\n",
      "epoch 418, run 30, loss 9.67086\n",
      "epoch 419, run 0, loss 2.7631\n",
      "epoch 419, run 10, loss 8.74982\n",
      "epoch 419, run 20, loss 10.1314\n",
      "epoch 419, run 30, loss 9.67086\n",
      "epoch 420, run 0, loss 5.5262\n",
      "epoch 420, run 10, loss 7.82879\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 420, run 20, loss 11.5129\n",
      "epoch 420, run 30, loss 8.28931\n",
      "epoch 421, run 0, loss 9.67086\n",
      "epoch 421, run 10, loss 10.1314\n",
      "epoch 421, run 20, loss 15.1971\n",
      "epoch 421, run 30, loss 11.5129\n",
      "epoch 422, run 0, loss 9.67086\n",
      "epoch 422, run 10, loss 8.74982\n",
      "epoch 422, run 20, loss 11.5129\n",
      "epoch 422, run 30, loss 13.8155\n",
      "epoch 423, run 0, loss 9.21034\n",
      "epoch 423, run 10, loss 8.28931\n",
      "epoch 423, run 20, loss 9.21034\n",
      "epoch 423, run 30, loss 10.1314\n",
      "epoch 424, run 0, loss 12.434\n",
      "epoch 424, run 10, loss 5.5262\n",
      "epoch 424, run 20, loss 12.434\n",
      "epoch 424, run 30, loss 12.434\n",
      "epoch 425, run 0, loss 12.8945\n",
      "epoch 425, run 10, loss 5.5262\n",
      "epoch 425, run 20, loss 11.5129\n",
      "epoch 425, run 30, loss 10.5919\n",
      "epoch 426, run 0, loss 10.1314\n",
      "epoch 426, run 10, loss 4.60517\n",
      "epoch 426, run 20, loss 9.21034\n",
      "epoch 426, run 30, loss 8.28931\n",
      "epoch 427, run 0, loss 12.8945\n",
      "epoch 427, run 10, loss 6.44724\n",
      "epoch 427, run 20, loss 11.9734\n",
      "epoch 427, run 30, loss 10.5919\n",
      "epoch 428, run 0, loss 9.21034\n",
      "epoch 428, run 10, loss 5.98672\n",
      "epoch 428, run 20, loss 10.5919\n",
      "epoch 428, run 30, loss 11.5129\n",
      "epoch 429, run 0, loss 9.21034\n",
      "epoch 429, run 10, loss 5.5262\n",
      "epoch 429, run 20, loss 8.74982\n",
      "epoch 429, run 30, loss 10.5919\n",
      "epoch 430, run 0, loss 11.0524\n",
      "epoch 430, run 10, loss 4.60517\n",
      "epoch 430, run 20, loss 7.82879\n",
      "epoch 430, run 30, loss 10.1314\n",
      "epoch 431, run 0, loss 12.8945\n",
      "epoch 431, run 10, loss 3.68414\n",
      "epoch 431, run 20, loss 5.98672\n",
      "epoch 431, run 30, loss 10.5919\n",
      "epoch 432, run 0, loss 12.434\n",
      "epoch 432, run 10, loss 8.74982\n",
      "epoch 432, run 20, loss 5.98672\n",
      "epoch 432, run 30, loss 10.1314\n",
      "epoch 433, run 0, loss 10.1314\n",
      "epoch 433, run 10, loss 8.74982\n",
      "epoch 433, run 20, loss 9.67086\n",
      "epoch 433, run 30, loss 9.21034\n",
      "epoch 434, run 0, loss 11.5129\n",
      "epoch 434, run 10, loss 5.98672\n",
      "epoch 434, run 20, loss 11.5129\n",
      "epoch 434, run 30, loss 12.434\n",
      "epoch 435, run 0, loss 10.5919\n",
      "epoch 435, run 10, loss 4.60517\n",
      "epoch 435, run 20, loss 9.21034\n",
      "epoch 435, run 30, loss 11.5129\n",
      "epoch 436, run 0, loss 10.1314\n",
      "epoch 436, run 10, loss 2.7631\n",
      "epoch 436, run 20, loss 9.21034\n",
      "epoch 436, run 30, loss 10.5919\n",
      "epoch 437, run 0, loss 12.434\n",
      "epoch 437, run 10, loss 3.68414\n",
      "epoch 437, run 20, loss 7.36827\n",
      "epoch 437, run 30, loss 11.9734\n",
      "epoch 438, run 0, loss 10.5919\n",
      "epoch 438, run 10, loss 9.67086\n",
      "epoch 438, run 20, loss 9.67086\n",
      "epoch 438, run 30, loss 13.8155\n",
      "epoch 439, run 0, loss 10.1314\n",
      "epoch 439, run 10, loss 9.67086\n",
      "epoch 439, run 20, loss 9.21034\n",
      "epoch 439, run 30, loss 12.8945\n",
      "epoch 440, run 0, loss 11.9734\n",
      "epoch 440, run 10, loss 8.74982\n",
      "epoch 440, run 20, loss 8.28931\n",
      "epoch 440, run 30, loss 8.28931\n",
      "epoch 441, run 0, loss 14.7365\n",
      "epoch 441, run 10, loss 11.0524\n",
      "epoch 441, run 20, loss 5.98672\n",
      "epoch 441, run 30, loss 12.434\n",
      "epoch 442, run 0, loss 11.0524\n",
      "epoch 442, run 10, loss 13.8155\n",
      "epoch 442, run 20, loss 5.06569\n",
      "epoch 442, run 30, loss 11.9734\n",
      "epoch 443, run 0, loss 9.21034\n",
      "epoch 443, run 10, loss 10.5919\n",
      "epoch 443, run 20, loss 4.60517\n",
      "epoch 443, run 30, loss 9.21034\n",
      "epoch 444, run 0, loss 11.9734\n",
      "epoch 444, run 10, loss 12.434\n",
      "epoch 444, run 20, loss 6.90775\n",
      "epoch 444, run 30, loss 10.5919\n",
      "epoch 445, run 0, loss 11.5129\n",
      "epoch 445, run 10, loss 10.5919\n",
      "epoch 445, run 20, loss 5.98672\n",
      "epoch 445, run 30, loss 11.0524\n",
      "epoch 446, run 0, loss 9.67086\n",
      "epoch 446, run 10, loss 8.28931\n",
      "epoch 446, run 20, loss 4.14465\n",
      "epoch 446, run 30, loss 7.82879\n",
      "epoch 447, run 0, loss 12.434\n",
      "epoch 447, run 10, loss 10.1314\n",
      "epoch 447, run 20, loss 4.14465\n",
      "epoch 447, run 30, loss 8.28931\n",
      "epoch 448, run 0, loss 10.5919\n",
      "epoch 448, run 10, loss 11.9734\n",
      "epoch 448, run 20, loss 3.68414\n",
      "epoch 448, run 30, loss 6.44724\n",
      "epoch 449, run 0, loss 8.74982\n",
      "epoch 449, run 10, loss 11.0524\n",
      "epoch 449, run 20, loss 7.36827\n",
      "epoch 449, run 30, loss 6.44724\n",
      "epoch 450, run 0, loss 7.82879\n",
      "epoch 450, run 10, loss 10.1314\n",
      "epoch 450, run 20, loss 8.28931\n",
      "epoch 450, run 30, loss 8.28931\n",
      "epoch 451, run 0, loss 5.98672\n",
      "epoch 451, run 10, loss 11.0524\n",
      "epoch 451, run 20, loss 5.5262\n",
      "epoch 451, run 30, loss 11.5129\n",
      "epoch 452, run 0, loss 6.44724\n",
      "epoch 452, run 10, loss 10.1314\n",
      "epoch 452, run 20, loss 4.14465\n",
      "epoch 452, run 30, loss 8.74982\n",
      "epoch 453, run 0, loss 9.67086\n",
      "epoch 453, run 10, loss 9.67086\n",
      "epoch 453, run 20, loss 2.30258\n",
      "epoch 453, run 30, loss 8.74982\n",
      "epoch 454, run 0, loss 11.5129\n",
      "epoch 454, run 10, loss 12.434\n",
      "epoch 454, run 20, loss 3.68414\n",
      "epoch 454, run 30, loss 8.28931\n",
      "epoch 455, run 0, loss 8.74982\n",
      "epoch 455, run 10, loss 11.5129\n",
      "epoch 455, run 20, loss 8.28931\n",
      "epoch 455, run 30, loss 8.28931\n",
      "epoch 456, run 0, loss 9.21034\n",
      "epoch 456, run 10, loss 10.1314\n",
      "epoch 456, run 20, loss 10.5919\n",
      "epoch 456, run 30, loss 9.67086\n",
      "epoch 457, run 0, loss 6.90775\n",
      "epoch 457, run 10, loss 11.5129\n",
      "epoch 457, run 20, loss 8.74982\n",
      "epoch 457, run 30, loss 8.28931\n",
      "epoch 458, run 0, loss 10.1314\n",
      "epoch 458, run 10, loss 14.276\n",
      "epoch 458, run 20, loss 10.5919\n",
      "epoch 458, run 30, loss 6.90775\n",
      "epoch 459, run 0, loss 9.21034\n",
      "epoch 459, run 10, loss 13.355\n",
      "epoch 459, run 20, loss 13.355\n",
      "epoch 459, run 30, loss 5.06569\n",
      "epoch 460, run 0, loss 8.28931\n",
      "epoch 460, run 10, loss 8.74982\n",
      "epoch 460, run 20, loss 11.5129\n",
      "epoch 460, run 30, loss 5.5262\n",
      "epoch 461, run 0, loss 5.98672\n",
      "epoch 461, run 10, loss 12.434\n",
      "epoch 461, run 20, loss 11.5129\n",
      "epoch 461, run 30, loss 5.5262\n",
      "epoch 462, run 0, loss 5.06569\n",
      "epoch 462, run 10, loss 11.5129\n",
      "epoch 462, run 20, loss 11.9734\n",
      "epoch 462, run 30, loss 5.5262\n",
      "epoch 463, run 0, loss 5.06569\n",
      "epoch 463, run 10, loss 9.21034\n",
      "epoch 463, run 20, loss 9.21034\n",
      "epoch 463, run 30, loss 3.22362\n",
      "epoch 464, run 0, loss 7.36827\n",
      "epoch 464, run 10, loss 10.5919\n",
      "epoch 464, run 20, loss 9.67086\n",
      "epoch 464, run 30, loss 4.60517\n",
      "epoch 465, run 0, loss 5.98672\n",
      "epoch 465, run 10, loss 11.0524\n",
      "epoch 465, run 20, loss 11.9734\n",
      "epoch 465, run 30, loss 4.14465\n",
      "epoch 466, run 0, loss 4.14465\n",
      "epoch 466, run 10, loss 7.82879\n",
      "epoch 466, run 20, loss 11.0524\n",
      "epoch 466, run 30, loss 6.44724\n",
      "epoch 467, run 0, loss 4.14465\n",
      "epoch 467, run 10, loss 8.28931\n",
      "epoch 467, run 20, loss 10.1314\n",
      "epoch 467, run 30, loss 8.74982\n",
      "epoch 468, run 0, loss 3.68414\n",
      "epoch 468, run 10, loss 6.44724\n",
      "epoch 468, run 20, loss 10.1314\n",
      "epoch 468, run 30, loss 6.44724\n",
      "epoch 469, run 0, loss 7.36827\n",
      "epoch 469, run 10, loss 6.44724\n",
      "epoch 469, run 20, loss 10.5919\n",
      "epoch 469, run 30, loss 5.06569\n",
      "epoch 470, run 0, loss 8.74982\n",
      "epoch 470, run 10, loss 8.28931\n",
      "epoch 470, run 20, loss 9.21034\n",
      "epoch 470, run 30, loss 3.22362\n",
      "epoch 471, run 0, loss 5.5262\n",
      "epoch 471, run 10, loss 11.5129\n",
      "epoch 471, run 20, loss 12.8945\n",
      "epoch 471, run 30, loss 3.68414\n",
      "epoch 472, run 0, loss 3.68414\n",
      "epoch 472, run 10, loss 9.21034\n",
      "epoch 472, run 20, loss 11.9734\n",
      "epoch 472, run 30, loss 6.90775\n",
      "epoch 473, run 0, loss 2.30258\n",
      "epoch 473, run 10, loss 8.28931\n",
      "epoch 473, run 20, loss 10.1314\n",
      "epoch 473, run 30, loss 9.67086\n",
      "epoch 474, run 0, loss 3.68414\n",
      "epoch 474, run 10, loss 8.28931\n",
      "epoch 474, run 20, loss 11.0524\n",
      "epoch 474, run 30, loss 9.21034\n",
      "epoch 475, run 0, loss 8.28931\n",
      "epoch 475, run 10, loss 8.28931\n",
      "epoch 475, run 20, loss 13.8155\n",
      "epoch 475, run 30, loss 9.67086\n",
      "epoch 476, run 0, loss 10.1314\n",
      "epoch 476, run 10, loss 9.21034\n",
      "epoch 476, run 20, loss 12.434\n",
      "epoch 476, run 30, loss 13.8155\n",
      "epoch 477, run 0, loss 8.74982\n",
      "epoch 477, run 10, loss 8.74982\n",
      "epoch 477, run 20, loss 9.21034\n",
      "epoch 477, run 30, loss 11.5129\n",
      "epoch 478, run 0, loss 10.5919\n",
      "epoch 478, run 10, loss 6.90775\n",
      "epoch 478, run 20, loss 11.0524\n",
      "epoch 478, run 30, loss 10.5919\n",
      "epoch 479, run 0, loss 13.355\n",
      "epoch 479, run 10, loss 5.06569\n",
      "epoch 479, run 20, loss 11.9734\n",
      "epoch 479, run 30, loss 11.9734\n",
      "epoch 480, run 0, loss 11.0524\n",
      "epoch 480, run 10, loss 5.06569\n",
      "epoch 480, run 20, loss 9.21034\n",
      "epoch 480, run 30, loss 9.21034\n",
      "epoch 481, run 0, loss 11.9734\n",
      "epoch 481, run 10, loss 5.5262\n",
      "epoch 481, run 20, loss 10.5919\n",
      "epoch 481, run 30, loss 8.28931\n",
      "epoch 482, run 0, loss 12.434\n",
      "epoch 482, run 10, loss 5.5262\n",
      "epoch 482, run 20, loss 11.0524\n",
      "epoch 482, run 30, loss 10.5919\n",
      "epoch 483, run 0, loss 9.21034\n",
      "epoch 483, run 10, loss 3.22362\n",
      "epoch 483, run 20, loss 9.67086\n",
      "epoch 483, run 30, loss 11.5129\n",
      "epoch 484, run 0, loss 10.1314\n",
      "epoch 484, run 10, loss 4.60517\n",
      "epoch 484, run 20, loss 8.28931\n",
      "epoch 484, run 30, loss 11.5129\n",
      "epoch 485, run 0, loss 11.9734\n",
      "epoch 485, run 10, loss 3.68414\n",
      "epoch 485, run 20, loss 6.44724\n",
      "epoch 485, run 30, loss 10.5919\n",
      "epoch 486, run 0, loss 11.0524\n",
      "epoch 486, run 10, loss 6.44724\n",
      "epoch 486, run 20, loss 6.44724\n",
      "epoch 486, run 30, loss 11.9734\n",
      "epoch 487, run 0, loss 9.67086\n",
      "epoch 487, run 10, loss 8.74982\n",
      "epoch 487, run 20, loss 7.36827\n",
      "epoch 487, run 30, loss 10.1314\n",
      "epoch 488, run 0, loss 10.5919\n",
      "epoch 488, run 10, loss 6.44724\n",
      "epoch 488, run 20, loss 11.9734\n",
      "epoch 488, run 30, loss 12.434\n",
      "epoch 489, run 0, loss 10.5919\n",
      "epoch 489, run 10, loss 4.60517\n",
      "epoch 489, run 20, loss 10.1314\n",
      "epoch 489, run 30, loss 12.8945\n",
      "epoch 490, run 0, loss 9.21034\n",
      "epoch 490, run 10, loss 3.22362\n",
      "epoch 490, run 20, loss 8.74982\n",
      "epoch 490, run 30, loss 9.67086\n",
      "epoch 491, run 0, loss 12.8945\n",
      "epoch 491, run 10, loss 3.68414\n",
      "epoch 491, run 20, loss 8.74982\n",
      "epoch 491, run 30, loss 10.5919\n",
      "epoch 492, run 0, loss 11.5129\n",
      "epoch 492, run 10, loss 7.36827\n",
      "epoch 492, run 20, loss 8.74982\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 492, run 30, loss 12.434\n",
      "epoch 493, run 0, loss 10.5919\n",
      "epoch 493, run 10, loss 9.67086\n",
      "epoch 493, run 20, loss 10.1314\n",
      "epoch 493, run 30, loss 13.355\n",
      "epoch 494, run 0, loss 11.0524\n",
      "epoch 494, run 10, loss 8.74982\n",
      "epoch 494, run 20, loss 9.67086\n",
      "epoch 494, run 30, loss 10.1314\n",
      "epoch 495, run 0, loss 13.355\n",
      "epoch 495, run 10, loss 10.1314\n",
      "epoch 495, run 20, loss 7.36827\n",
      "epoch 495, run 30, loss 10.5919\n",
      "epoch 496, run 0, loss 12.434\n",
      "epoch 496, run 10, loss 13.355\n",
      "epoch 496, run 20, loss 5.06569\n",
      "epoch 496, run 30, loss 11.5129\n",
      "epoch 497, run 0, loss 8.74982\n",
      "epoch 497, run 10, loss 11.5129\n",
      "epoch 497, run 20, loss 5.5262\n",
      "epoch 497, run 30, loss 10.1314\n",
      "epoch 498, run 0, loss 11.0524\n",
      "epoch 498, run 10, loss 10.5919\n",
      "epoch 498, run 20, loss 4.14465\n",
      "epoch 498, run 30, loss 9.67086\n",
      "epoch 499, run 0, loss 12.434\n",
      "epoch 499, run 10, loss 11.5129\n",
      "epoch 499, run 20, loss 5.98672\n",
      "epoch 499, run 30, loss 11.5129\n",
      "epoch 500, run 0, loss 9.21034\n",
      "epoch 500, run 10, loss 9.21034\n",
      "epoch 500, run 20, loss 4.60517\n",
      "epoch 500, run 30, loss 9.67086\n",
      "epoch 501, run 0, loss 11.0524\n",
      "epoch 501, run 10, loss 8.74982\n",
      "epoch 501, run 20, loss 5.5262\n",
      "epoch 501, run 30, loss 9.67086\n",
      "epoch 502, run 0, loss 11.0524\n",
      "epoch 502, run 10, loss 11.0524\n",
      "epoch 502, run 20, loss 4.60517\n",
      "epoch 502, run 30, loss 7.36827\n",
      "epoch 503, run 0, loss 9.21034\n",
      "epoch 503, run 10, loss 11.9734\n",
      "epoch 503, run 20, loss 5.98672\n",
      "epoch 503, run 30, loss 7.36827\n",
      "epoch 504, run 0, loss 7.82879\n",
      "epoch 504, run 10, loss 11.0524\n",
      "epoch 504, run 20, loss 8.74982\n",
      "epoch 504, run 30, loss 6.90775\n",
      "epoch 505, run 0, loss 5.98672\n",
      "epoch 505, run 10, loss 10.5919\n",
      "epoch 505, run 20, loss 7.36827\n",
      "epoch 505, run 30, loss 11.0524\n",
      "epoch 506, run 0, loss 5.98672\n",
      "epoch 506, run 10, loss 11.9734\n",
      "epoch 506, run 20, loss 5.5262\n",
      "epoch 506, run 30, loss 11.0524\n",
      "epoch 507, run 0, loss 7.36827\n",
      "epoch 507, run 10, loss 9.67086\n",
      "epoch 507, run 20, loss 3.68414\n",
      "epoch 507, run 30, loss 9.21034\n",
      "epoch 508, run 0, loss 11.9734\n",
      "epoch 508, run 10, loss 12.434\n",
      "epoch 508, run 20, loss 3.22362\n",
      "epoch 508, run 30, loss 8.28931\n",
      "epoch 509, run 0, loss 9.67086\n",
      "epoch 509, run 10, loss 12.8945\n",
      "epoch 509, run 20, loss 5.5262\n",
      "epoch 509, run 30, loss 8.74982\n",
      "epoch 510, run 0, loss 8.74982\n",
      "epoch 510, run 10, loss 10.1314\n",
      "epoch 510, run 20, loss 9.21034\n",
      "epoch 510, run 30, loss 9.67086\n",
      "epoch 511, run 0, loss 8.74982\n",
      "epoch 511, run 10, loss 11.0524\n",
      "epoch 511, run 20, loss 9.67086\n",
      "epoch 511, run 30, loss 9.21034\n",
      "epoch 512, run 0, loss 8.28931\n",
      "epoch 512, run 10, loss 12.434\n",
      "epoch 512, run 20, loss 9.67086\n",
      "epoch 512, run 30, loss 7.36827\n",
      "epoch 513, run 0, loss 10.5919\n",
      "epoch 513, run 10, loss 12.8945\n",
      "epoch 513, run 20, loss 11.9734\n",
      "epoch 513, run 30, loss 5.5262\n",
      "epoch 514, run 0, loss 9.67086\n",
      "epoch 514, run 10, loss 10.1314\n",
      "epoch 514, run 20, loss 11.9734\n",
      "epoch 514, run 30, loss 5.06569\n",
      "epoch 515, run 0, loss 7.36827\n",
      "epoch 515, run 10, loss 10.5919\n",
      "epoch 515, run 20, loss 10.1314\n",
      "epoch 515, run 30, loss 5.06569\n",
      "epoch 516, run 0, loss 4.60517\n",
      "epoch 516, run 10, loss 11.5129\n",
      "epoch 516, run 20, loss 11.9734\n",
      "epoch 516, run 30, loss 6.44724\n",
      "epoch 517, run 0, loss 5.5262\n",
      "epoch 517, run 10, loss 10.1314\n",
      "epoch 517, run 20, loss 9.67086\n",
      "epoch 517, run 30, loss 5.5262\n",
      "epoch 518, run 0, loss 4.60517\n",
      "epoch 518, run 10, loss 9.21034\n",
      "epoch 518, run 20, loss 9.21034\n",
      "epoch 518, run 30, loss 5.06569\n",
      "epoch 519, run 0, loss 5.98672\n",
      "epoch 519, run 10, loss 11.5129\n",
      "epoch 519, run 20, loss 11.0524\n",
      "epoch 519, run 30, loss 5.06569\n",
      "epoch 520, run 0, loss 4.60517\n",
      "epoch 520, run 10, loss 9.67086\n",
      "epoch 520, run 20, loss 11.9734\n",
      "epoch 520, run 30, loss 4.14465\n",
      "epoch 521, run 0, loss 5.5262\n",
      "epoch 521, run 10, loss 9.67086\n",
      "epoch 521, run 20, loss 12.434\n",
      "epoch 521, run 30, loss 8.74982\n",
      "epoch 522, run 0, loss 4.60517\n",
      "epoch 522, run 10, loss 7.36827\n",
      "epoch 522, run 20, loss 10.1314\n",
      "epoch 522, run 30, loss 8.74982\n",
      "epoch 523, run 0, loss 5.98672\n",
      "epoch 523, run 10, loss 6.90775\n",
      "epoch 523, run 20, loss 11.5129\n",
      "epoch 523, run 30, loss 5.5262\n",
      "epoch 524, run 0, loss 8.74982\n",
      "epoch 524, run 10, loss 6.90775\n",
      "epoch 524, run 20, loss 10.5919\n",
      "epoch 524, run 30, loss 4.60517\n",
      "epoch 525, run 0, loss 7.36827\n",
      "epoch 525, run 10, loss 11.0524\n",
      "epoch 525, run 20, loss 11.0524\n",
      "epoch 525, run 30, loss 2.7631\n",
      "epoch 526, run 0, loss 5.06569\n",
      "epoch 526, run 10, loss 10.5919\n",
      "epoch 526, run 20, loss 13.355\n",
      "epoch 526, run 30, loss 4.14465\n",
      "epoch 527, run 0, loss 3.68414\n",
      "epoch 527, run 10, loss 9.21034\n",
      "epoch 527, run 20, loss 10.5919\n",
      "epoch 527, run 30, loss 9.21034\n",
      "epoch 528, run 0, loss 3.22362\n",
      "epoch 528, run 10, loss 7.82879\n",
      "epoch 528, run 20, loss 10.1314\n",
      "epoch 528, run 30, loss 9.67086\n",
      "epoch 529, run 0, loss 5.98672\n",
      "epoch 529, run 10, loss 8.28931\n",
      "epoch 529, run 20, loss 11.5129\n",
      "epoch 529, run 30, loss 9.67086\n",
      "epoch 530, run 0, loss 8.74982\n",
      "epoch 530, run 10, loss 9.67086\n",
      "epoch 530, run 20, loss 13.8155\n",
      "epoch 530, run 30, loss 11.0524\n",
      "epoch 531, run 0, loss 9.67086\n",
      "epoch 531, run 10, loss 9.21034\n",
      "epoch 531, run 20, loss 11.0524\n",
      "epoch 531, run 30, loss 12.8945\n",
      "epoch 532, run 0, loss 10.1314\n",
      "epoch 532, run 10, loss 7.36827\n",
      "epoch 532, run 20, loss 9.67086\n",
      "epoch 532, run 30, loss 10.1314\n",
      "epoch 533, run 0, loss 11.9734\n",
      "epoch 533, run 10, loss 5.5262\n",
      "epoch 533, run 20, loss 11.9734\n",
      "epoch 533, run 30, loss 12.434\n",
      "epoch 534, run 0, loss 11.9734\n",
      "epoch 534, run 10, loss 5.5262\n",
      "epoch 534, run 20, loss 11.5129\n",
      "epoch 534, run 30, loss 10.5919\n",
      "epoch 535, run 0, loss 9.67086\n",
      "epoch 535, run 10, loss 5.06569\n",
      "epoch 535, run 20, loss 9.67086\n",
      "epoch 535, run 30, loss 8.74982\n",
      "epoch 536, run 0, loss 11.5129\n",
      "epoch 536, run 10, loss 6.44724\n",
      "epoch 536, run 20, loss 12.434\n",
      "epoch 536, run 30, loss 10.5919\n",
      "epoch 537, run 0, loss 9.21034\n",
      "epoch 537, run 10, loss 5.06569\n",
      "epoch 537, run 20, loss 10.1314\n",
      "epoch 537, run 30, loss 11.9734\n",
      "epoch 538, run 0, loss 9.67086\n",
      "epoch 538, run 10, loss 5.06569\n",
      "epoch 538, run 20, loss 9.21034\n",
      "epoch 538, run 30, loss 11.5129\n",
      "epoch 539, run 0, loss 11.0524\n",
      "epoch 539, run 10, loss 5.06569\n",
      "epoch 539, run 20, loss 7.36827\n",
      "epoch 539, run 30, loss 10.1314\n",
      "epoch 540, run 0, loss 11.9734\n",
      "epoch 540, run 10, loss 4.14465\n",
      "epoch 540, run 20, loss 5.98672\n",
      "epoch 540, run 30, loss 11.0524\n",
      "epoch 541, run 0, loss 11.9734\n",
      "epoch 541, run 10, loss 8.28931\n",
      "epoch 541, run 20, loss 6.90775\n",
      "epoch 541, run 30, loss 9.67086\n",
      "epoch 542, run 0, loss 10.5919\n",
      "epoch 542, run 10, loss 8.28931\n",
      "epoch 542, run 20, loss 9.21034\n",
      "epoch 542, run 30, loss 10.1314\n",
      "epoch 543, run 0, loss 11.5129\n",
      "epoch 543, run 10, loss 5.98672\n",
      "epoch 543, run 20, loss 11.5129\n",
      "epoch 543, run 30, loss 11.9734\n",
      "epoch 544, run 0, loss 10.5919\n",
      "epoch 544, run 10, loss 4.14465\n",
      "epoch 544, run 20, loss 7.82879\n",
      "epoch 544, run 30, loss 11.5129\n",
      "epoch 545, run 0, loss 11.0524\n",
      "epoch 545, run 10, loss 2.7631\n",
      "epoch 545, run 20, loss 8.74982\n",
      "epoch 545, run 30, loss 10.5919\n",
      "epoch 546, run 0, loss 13.355\n",
      "epoch 546, run 10, loss 4.14465\n",
      "epoch 546, run 20, loss 7.36827\n",
      "epoch 546, run 30, loss 11.5129\n",
      "epoch 547, run 0, loss 10.1314\n",
      "epoch 547, run 10, loss 9.21034\n",
      "epoch 547, run 20, loss 9.67086\n",
      "epoch 547, run 30, loss 14.276\n",
      "epoch 548, run 0, loss 10.5919\n",
      "epoch 548, run 10, loss 10.1314\n",
      "epoch 548, run 20, loss 8.74982\n",
      "epoch 548, run 30, loss 12.434\n",
      "epoch 549, run 0, loss 11.5129\n",
      "epoch 549, run 10, loss 9.67086\n",
      "epoch 549, run 20, loss 8.74982\n",
      "epoch 549, run 30, loss 8.28931\n",
      "epoch 550, run 0, loss 14.276\n",
      "epoch 550, run 10, loss 11.0524\n",
      "epoch 550, run 20, loss 5.98672\n",
      "epoch 550, run 30, loss 11.9734\n",
      "epoch 551, run 0, loss 11.0524\n",
      "epoch 551, run 10, loss 12.8945\n",
      "epoch 551, run 20, loss 5.5262\n",
      "epoch 551, run 30, loss 11.0524\n",
      "epoch 552, run 0, loss 10.1314\n",
      "epoch 552, run 10, loss 10.1314\n",
      "epoch 552, run 20, loss 5.06569\n",
      "epoch 552, run 30, loss 9.21034\n",
      "epoch 553, run 0, loss 11.9734\n",
      "epoch 553, run 10, loss 12.8945\n",
      "epoch 553, run 20, loss 6.90775\n",
      "epoch 553, run 30, loss 11.0524\n",
      "epoch 554, run 0, loss 11.0524\n",
      "epoch 554, run 10, loss 10.1314\n",
      "epoch 554, run 20, loss 5.98672\n",
      "epoch 554, run 30, loss 11.5129\n",
      "epoch 555, run 0, loss 9.67086\n",
      "epoch 555, run 10, loss 8.74982\n",
      "epoch 555, run 20, loss 5.06569\n",
      "epoch 555, run 30, loss 8.28931\n",
      "epoch 556, run 0, loss 11.9734\n",
      "epoch 556, run 10, loss 10.5919\n",
      "epoch 556, run 20, loss 4.60517\n",
      "epoch 556, run 30, loss 8.74982\n",
      "epoch 557, run 0, loss 10.1314\n",
      "epoch 557, run 10, loss 11.9734\n",
      "epoch 557, run 20, loss 4.14465\n",
      "epoch 557, run 30, loss 6.44724\n",
      "epoch 558, run 0, loss 8.74982\n",
      "epoch 558, run 10, loss 11.5129\n",
      "epoch 558, run 20, loss 7.36827\n",
      "epoch 558, run 30, loss 5.98672\n",
      "epoch 559, run 0, loss 7.82879\n",
      "epoch 559, run 10, loss 10.5919\n",
      "epoch 559, run 20, loss 9.21034\n",
      "epoch 559, run 30, loss 9.21034\n",
      "epoch 560, run 0, loss 5.98672\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 560, run 10, loss 11.5129\n",
      "epoch 560, run 20, loss 5.98672\n",
      "epoch 560, run 30, loss 11.0524\n",
      "epoch 561, run 0, loss 6.44724\n",
      "epoch 561, run 10, loss 10.1314\n",
      "epoch 561, run 20, loss 4.14465\n",
      "epoch 561, run 30, loss 9.67086\n",
      "epoch 562, run 0, loss 9.21034\n",
      "epoch 562, run 10, loss 10.1314\n",
      "epoch 562, run 20, loss 2.30259\n",
      "epoch 562, run 30, loss 9.21034\n",
      "epoch 563, run 0, loss 11.0524\n",
      "epoch 563, run 10, loss 12.434\n",
      "epoch 563, run 20, loss 3.68414\n",
      "epoch 563, run 30, loss 7.82879\n",
      "epoch 564, run 0, loss 8.28931\n",
      "epoch 564, run 10, loss 11.0524\n",
      "epoch 564, run 20, loss 9.21034\n",
      "epoch 564, run 30, loss 8.28931\n",
      "epoch 565, run 0, loss 8.74982\n",
      "epoch 565, run 10, loss 10.5919\n",
      "epoch 565, run 20, loss 10.5919\n",
      "epoch 565, run 30, loss 9.67086\n",
      "epoch 566, run 0, loss 7.36827\n",
      "epoch 566, run 10, loss 11.5129\n",
      "epoch 566, run 20, loss 8.28931\n",
      "epoch 566, run 30, loss 8.74982\n",
      "epoch 567, run 0, loss 10.1314\n",
      "epoch 567, run 10, loss 14.7365\n",
      "epoch 567, run 20, loss 11.0524\n",
      "epoch 567, run 30, loss 6.90775\n",
      "epoch 568, run 0, loss 8.28931\n",
      "epoch 568, run 10, loss 11.9734\n",
      "epoch 568, run 20, loss 13.8155\n",
      "epoch 568, run 30, loss 5.06569\n",
      "epoch 569, run 0, loss 8.74982\n",
      "epoch 569, run 10, loss 8.74982\n",
      "epoch 569, run 20, loss 11.5129\n",
      "epoch 569, run 30, loss 5.06569\n",
      "epoch 570, run 0, loss 5.98672\n",
      "epoch 570, run 10, loss 11.9734\n",
      "epoch 570, run 20, loss 11.5129\n",
      "epoch 570, run 30, loss 5.5262\n",
      "epoch 571, run 0, loss 5.5262\n",
      "epoch 571, run 10, loss 11.0524\n",
      "epoch 571, run 20, loss 11.5129\n",
      "epoch 571, run 30, loss 5.5262\n",
      "epoch 572, run 0, loss 5.06569\n",
      "epoch 572, run 10, loss 9.21034\n",
      "epoch 572, run 20, loss 8.74982\n",
      "epoch 572, run 30, loss 3.22362\n",
      "epoch 573, run 0, loss 6.90775\n",
      "epoch 573, run 10, loss 11.0524\n",
      "epoch 573, run 20, loss 10.5919\n",
      "epoch 573, run 30, loss 4.14465\n",
      "epoch 574, run 0, loss 5.5262\n",
      "epoch 574, run 10, loss 11.5129\n",
      "epoch 574, run 20, loss 12.434\n",
      "epoch 574, run 30, loss 3.68414\n",
      "epoch 575, run 0, loss 5.06569\n",
      "epoch 575, run 10, loss 7.82879\n",
      "epoch 575, run 20, loss 11.0524\n",
      "epoch 575, run 30, loss 6.44724\n",
      "epoch 576, run 0, loss 4.60517\n",
      "epoch 576, run 10, loss 9.21034\n",
      "epoch 576, run 20, loss 10.1314\n",
      "epoch 576, run 30, loss 8.74982\n",
      "epoch 577, run 0, loss 4.14465\n",
      "epoch 577, run 10, loss 6.44724\n",
      "epoch 577, run 20, loss 11.5129\n",
      "epoch 577, run 30, loss 5.98672\n",
      "epoch 578, run 0, loss 7.82879\n",
      "epoch 578, run 10, loss 5.98672\n",
      "epoch 578, run 20, loss 10.1314\n",
      "epoch 578, run 30, loss 4.60517\n",
      "epoch 579, run 0, loss 9.21034\n",
      "epoch 579, run 10, loss 9.67086\n",
      "epoch 579, run 20, loss 9.21034\n",
      "epoch 579, run 30, loss 2.7631\n",
      "epoch 580, run 0, loss 5.98672\n",
      "epoch 580, run 10, loss 11.0524\n",
      "epoch 580, run 20, loss 12.8945\n",
      "epoch 580, run 30, loss 4.14465\n",
      "epoch 581, run 0, loss 4.14465\n",
      "epoch 581, run 10, loss 10.1314\n",
      "epoch 581, run 20, loss 11.0524\n",
      "epoch 581, run 30, loss 7.82879\n",
      "epoch 582, run 0, loss 2.30259\n",
      "epoch 582, run 10, loss 9.67086\n",
      "epoch 582, run 20, loss 10.1314\n",
      "epoch 582, run 30, loss 9.67086\n",
      "epoch 583, run 0, loss 3.68414\n",
      "epoch 583, run 10, loss 7.36827\n",
      "epoch 583, run 20, loss 11.9734\n",
      "epoch 583, run 30, loss 9.21034\n",
      "epoch 584, run 0, loss 9.21034\n",
      "epoch 584, run 10, loss 8.74982\n",
      "epoch 584, run 20, loss 13.355\n",
      "epoch 584, run 30, loss 10.1314\n",
      "epoch 585, run 0, loss 10.1314\n",
      "epoch 585, run 10, loss 9.67086\n",
      "epoch 585, run 20, loss 13.355\n",
      "epoch 585, run 30, loss 13.8155\n",
      "epoch 586, run 0, loss 8.74982\n",
      "epoch 586, run 10, loss 8.74982\n",
      "epoch 586, run 20, loss 8.28931\n",
      "epoch 586, run 30, loss 11.5129\n",
      "epoch 587, run 0, loss 11.0524\n",
      "epoch 587, run 10, loss 6.44724\n",
      "epoch 587, run 20, loss 11.5129\n",
      "epoch 587, run 30, loss 11.0524\n",
      "epoch 588, run 0, loss 13.8155\n",
      "epoch 588, run 10, loss 5.06569\n",
      "epoch 588, run 20, loss 11.9734\n",
      "epoch 588, run 30, loss 11.5129\n",
      "epoch 589, run 0, loss 11.0524\n",
      "epoch 589, run 10, loss 5.06569\n",
      "epoch 589, run 20, loss 9.67086\n",
      "epoch 589, run 30, loss 9.21034\n",
      "epoch 590, run 0, loss 11.5129\n",
      "epoch 590, run 10, loss 5.98672\n",
      "epoch 590, run 20, loss 10.5919\n",
      "epoch 590, run 30, loss 9.21034\n",
      "epoch 591, run 0, loss 11.0524\n",
      "epoch 591, run 10, loss 5.5262\n",
      "epoch 591, run 20, loss 11.0524\n",
      "epoch 591, run 30, loss 11.0524\n",
      "epoch 592, run 0, loss 9.21034\n",
      "epoch 592, run 10, loss 3.68414\n",
      "epoch 592, run 20, loss 8.28931\n",
      "epoch 592, run 30, loss 11.0524\n",
      "epoch 593, run 0, loss 10.5919\n",
      "epoch 593, run 10, loss 4.14465\n",
      "epoch 593, run 20, loss 8.28931\n",
      "epoch 593, run 30, loss 11.0524\n",
      "epoch 594, run 0, loss 11.9734\n",
      "epoch 594, run 10, loss 3.68414\n",
      "epoch 594, run 20, loss 5.98672\n",
      "epoch 594, run 30, loss 10.1314\n",
      "epoch 595, run 0, loss 11.0524\n",
      "epoch 595, run 10, loss 6.44724\n",
      "epoch 595, run 20, loss 5.98672\n",
      "epoch 595, run 30, loss 11.0524\n",
      "epoch 596, run 0, loss 10.1314\n",
      "epoch 596, run 10, loss 8.74982\n",
      "epoch 596, run 20, loss 8.28931\n",
      "epoch 596, run 30, loss 8.74982\n",
      "epoch 597, run 0, loss 11.5129\n",
      "epoch 597, run 10, loss 5.5262\n",
      "epoch 597, run 20, loss 11.9734\n",
      "epoch 597, run 30, loss 12.8945\n",
      "epoch 598, run 0, loss 10.1314\n",
      "epoch 598, run 10, loss 4.60517\n",
      "epoch 598, run 20, loss 9.21034\n",
      "epoch 598, run 30, loss 12.434\n",
      "epoch 599, run 0, loss 9.21034\n",
      "epoch 599, run 10, loss 2.30258\n",
      "epoch 599, run 20, loss 9.21034\n",
      "epoch 599, run 30, loss 10.1314\n",
      "epoch 600, run 0, loss 12.8945\n",
      "epoch 600, run 10, loss 4.14465\n",
      "epoch 600, run 20, loss 8.74982\n",
      "epoch 600, run 30, loss 11.5129\n",
      "epoch 601, run 0, loss 10.5919\n",
      "epoch 601, run 10, loss 8.28931\n",
      "epoch 601, run 20, loss 8.74982\n",
      "epoch 601, run 30, loss 12.8945\n",
      "epoch 602, run 0, loss 10.5919\n",
      "epoch 602, run 10, loss 10.1314\n",
      "epoch 602, run 20, loss 10.1314\n",
      "epoch 602, run 30, loss 11.9734\n",
      "epoch 603, run 0, loss 12.434\n",
      "epoch 603, run 10, loss 8.74982\n",
      "epoch 603, run 20, loss 8.74982\n",
      "epoch 603, run 30, loss 9.21034\n",
      "epoch 604, run 0, loss 13.8155\n",
      "epoch 604, run 10, loss 10.1314\n",
      "epoch 604, run 20, loss 7.36827\n",
      "epoch 604, run 30, loss 10.5919\n",
      "epoch 605, run 0, loss 12.8945\n",
      "epoch 605, run 10, loss 14.276\n",
      "epoch 605, run 20, loss 5.06569\n",
      "epoch 605, run 30, loss 11.5129\n",
      "epoch 606, run 0, loss 7.82879\n",
      "epoch 606, run 10, loss 11.0524\n",
      "epoch 606, run 20, loss 5.5262\n",
      "epoch 606, run 30, loss 10.1314\n",
      "epoch 607, run 0, loss 11.9734\n",
      "epoch 607, run 10, loss 10.5919\n",
      "epoch 607, run 20, loss 5.06569\n",
      "epoch 607, run 30, loss 9.67086\n",
      "epoch 608, run 0, loss 11.5129\n",
      "epoch 608, run 10, loss 11.5129\n",
      "epoch 608, run 20, loss 5.98672\n",
      "epoch 608, run 30, loss 11.5129\n",
      "epoch 609, run 0, loss 9.21034\n",
      "epoch 609, run 10, loss 9.21034\n",
      "epoch 609, run 20, loss 4.14465\n",
      "epoch 609, run 30, loss 9.21034\n",
      "epoch 610, run 0, loss 11.0524\n",
      "epoch 610, run 10, loss 9.67086\n",
      "epoch 610, run 20, loss 5.06569\n",
      "epoch 610, run 30, loss 9.21034\n",
      "epoch 611, run 0, loss 11.0524\n",
      "epoch 611, run 10, loss 11.5129\n",
      "epoch 611, run 20, loss 4.60517\n",
      "epoch 611, run 30, loss 7.82879\n",
      "epoch 612, run 0, loss 8.28931\n",
      "epoch 612, run 10, loss 11.0524\n",
      "epoch 612, run 20, loss 5.98672\n",
      "epoch 612, run 30, loss 6.90775\n",
      "epoch 613, run 0, loss 8.28931\n",
      "epoch 613, run 10, loss 11.5129\n",
      "epoch 613, run 20, loss 8.74982\n",
      "epoch 613, run 30, loss 6.90775\n",
      "epoch 614, run 0, loss 5.98672\n",
      "epoch 614, run 10, loss 10.5919\n",
      "epoch 614, run 20, loss 7.36827\n",
      "epoch 614, run 30, loss 11.5129\n",
      "epoch 615, run 0, loss 5.98672\n",
      "epoch 615, run 10, loss 11.0524\n",
      "epoch 615, run 20, loss 5.5262\n",
      "epoch 615, run 30, loss 10.5919\n",
      "epoch 616, run 0, loss 8.28931\n",
      "epoch 616, run 10, loss 9.21034\n",
      "epoch 616, run 20, loss 3.22362\n",
      "epoch 616, run 30, loss 8.74982\n",
      "epoch 617, run 0, loss 11.9734\n",
      "epoch 617, run 10, loss 12.434\n",
      "epoch 617, run 20, loss 3.68414\n",
      "epoch 617, run 30, loss 7.82879\n",
      "epoch 618, run 0, loss 9.67086\n",
      "epoch 618, run 10, loss 12.434\n",
      "epoch 618, run 20, loss 5.98672\n",
      "epoch 618, run 30, loss 9.21034\n",
      "epoch 619, run 0, loss 8.74982\n",
      "epoch 619, run 10, loss 10.1314\n",
      "epoch 619, run 20, loss 9.21034\n",
      "epoch 619, run 30, loss 9.21034\n",
      "epoch 620, run 0, loss 8.74982\n",
      "epoch 620, run 10, loss 11.5129\n",
      "epoch 620, run 20, loss 9.21034\n",
      "epoch 620, run 30, loss 9.21034\n",
      "epoch 621, run 0, loss 8.28931\n",
      "epoch 621, run 10, loss 13.355\n",
      "epoch 621, run 20, loss 9.21034\n",
      "epoch 621, run 30, loss 7.36827\n",
      "epoch 622, run 0, loss 10.1314\n",
      "epoch 622, run 10, loss 11.9734\n",
      "epoch 622, run 20, loss 12.8945\n",
      "epoch 622, run 30, loss 5.5262\n",
      "epoch 623, run 0, loss 8.28931\n",
      "epoch 623, run 10, loss 9.67086\n",
      "epoch 623, run 20, loss 11.5129\n",
      "epoch 623, run 30, loss 5.06569\n",
      "epoch 624, run 0, loss 7.36827\n",
      "epoch 624, run 10, loss 10.5919\n",
      "epoch 624, run 20, loss 10.1314\n",
      "epoch 624, run 30, loss 5.06569\n",
      "epoch 625, run 0, loss 5.06569\n",
      "epoch 625, run 10, loss 11.9734\n",
      "epoch 625, run 20, loss 11.5129\n",
      "epoch 625, run 30, loss 6.44724\n",
      "epoch 626, run 0, loss 5.5262\n",
      "epoch 626, run 10, loss 9.67086\n",
      "epoch 626, run 20, loss 9.21034\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 626, run 30, loss 5.06569\n",
      "epoch 627, run 0, loss 5.06569\n",
      "epoch 627, run 10, loss 10.1314\n",
      "epoch 627, run 20, loss 9.67086\n",
      "epoch 627, run 30, loss 5.06569\n",
      "epoch 628, run 0, loss 5.98672\n",
      "epoch 628, run 10, loss 11.5129\n",
      "epoch 628, run 20, loss 10.5919\n",
      "epoch 628, run 30, loss 4.60517\n",
      "epoch 629, run 0, loss 3.68414\n",
      "epoch 629, run 10, loss 9.67086\n",
      "epoch 629, run 20, loss 11.9734\n",
      "epoch 629, run 30, loss 4.14465\n",
      "epoch 630, run 0, loss 5.06569\n",
      "epoch 630, run 10, loss 8.74982\n",
      "epoch 630, run 20, loss 11.0524\n",
      "epoch 630, run 30, loss 8.28931\n",
      "epoch 631, run 0, loss 4.14465\n",
      "epoch 631, run 10, loss 7.36827\n",
      "epoch 631, run 20, loss 10.5919\n",
      "epoch 631, run 30, loss 8.28931\n",
      "epoch 632, run 0, loss 5.98672\n",
      "epoch 632, run 10, loss 6.90775\n",
      "epoch 632, run 20, loss 11.0524\n",
      "epoch 632, run 30, loss 5.98672\n",
      "epoch 633, run 0, loss 8.28931\n",
      "epoch 633, run 10, loss 6.90775\n",
      "epoch 633, run 20, loss 10.1314\n",
      "epoch 633, run 30, loss 3.68414\n",
      "epoch 634, run 0, loss 7.36827\n",
      "epoch 634, run 10, loss 11.9734\n",
      "epoch 634, run 20, loss 11.5129\n",
      "epoch 634, run 30, loss 2.30259\n",
      "epoch 635, run 0, loss 5.5262\n",
      "epoch 635, run 10, loss 10.5919\n",
      "epoch 635, run 20, loss 12.8945\n",
      "epoch 635, run 30, loss 4.60517\n",
      "epoch 636, run 0, loss 3.22362\n",
      "epoch 636, run 10, loss 8.74982\n",
      "epoch 636, run 20, loss 10.1314\n",
      "epoch 636, run 30, loss 9.21034\n",
      "epoch 637, run 0, loss 4.14465\n",
      "epoch 637, run 10, loss 8.28931\n",
      "epoch 637, run 20, loss 10.5919\n",
      "epoch 637, run 30, loss 10.1314\n",
      "epoch 638, run 0, loss 6.44724\n",
      "epoch 638, run 10, loss 9.21034\n",
      "epoch 638, run 20, loss 11.9734\n",
      "epoch 638, run 30, loss 8.74982\n",
      "epoch 639, run 0, loss 9.67086\n",
      "epoch 639, run 10, loss 9.21034\n",
      "epoch 639, run 20, loss 13.355\n",
      "epoch 639, run 30, loss 11.5129\n",
      "epoch 640, run 0, loss 9.21034\n",
      "epoch 640, run 10, loss 8.74982\n",
      "epoch 640, run 20, loss 10.5919\n",
      "epoch 640, run 30, loss 13.355\n",
      "epoch 641, run 0, loss 9.21034\n",
      "epoch 641, run 10, loss 7.36827\n",
      "epoch 641, run 20, loss 10.5919\n",
      "epoch 641, run 30, loss 10.1314\n",
      "epoch 642, run 0, loss 13.355\n",
      "epoch 642, run 10, loss 5.98672\n",
      "epoch 642, run 20, loss 11.5129\n",
      "epoch 642, run 30, loss 12.434\n",
      "epoch 643, run 0, loss 11.5129\n",
      "epoch 643, run 10, loss 5.06569\n",
      "epoch 643, run 20, loss 11.0524\n",
      "epoch 643, run 30, loss 9.67086\n",
      "epoch 644, run 0, loss 10.5919\n",
      "epoch 644, run 10, loss 5.06569\n",
      "epoch 644, run 20, loss 9.67086\n",
      "epoch 644, run 30, loss 8.74982\n",
      "epoch 645, run 0, loss 11.9734\n",
      "epoch 645, run 10, loss 5.98672\n",
      "epoch 645, run 20, loss 12.434\n",
      "epoch 645, run 30, loss 11.5129\n",
      "epoch 646, run 0, loss 8.74982\n",
      "epoch 646, run 10, loss 4.60517\n",
      "epoch 646, run 20, loss 9.67086\n",
      "epoch 646, run 30, loss 12.434\n",
      "epoch 647, run 0, loss 9.21034\n",
      "epoch 647, run 10, loss 5.06569\n",
      "epoch 647, run 20, loss 8.74982\n",
      "epoch 647, run 30, loss 11.9734\n",
      "epoch 648, run 0, loss 10.5919\n",
      "epoch 648, run 10, loss 4.60517\n",
      "epoch 648, run 20, loss 7.36827\n",
      "epoch 648, run 30, loss 10.1314\n",
      "epoch 649, run 0, loss 11.9734\n",
      "epoch 649, run 10, loss 4.60517\n",
      "epoch 649, run 20, loss 6.44724\n",
      "epoch 649, run 30, loss 11.5129\n",
      "epoch 650, run 0, loss 11.5129\n",
      "epoch 650, run 10, loss 8.28931\n",
      "epoch 650, run 20, loss 6.44724\n",
      "epoch 650, run 30, loss 10.1314\n",
      "epoch 651, run 0, loss 10.5919\n",
      "epoch 651, run 10, loss 7.82879\n",
      "epoch 651, run 20, loss 9.67086\n",
      "epoch 651, run 30, loss 10.5919\n",
      "epoch 652, run 0, loss 11.5129\n",
      "epoch 652, run 10, loss 5.98672\n",
      "epoch 652, run 20, loss 11.0524\n",
      "epoch 652, run 30, loss 12.434\n",
      "epoch 653, run 0, loss 10.1314\n",
      "epoch 653, run 10, loss 3.68414\n",
      "epoch 653, run 20, loss 8.74982\n",
      "epoch 653, run 30, loss 10.5919\n",
      "epoch 654, run 0, loss 11.9734\n",
      "epoch 654, run 10, loss 2.7631\n",
      "epoch 654, run 20, loss 8.74982\n",
      "epoch 654, run 30, loss 10.1314\n",
      "epoch 655, run 0, loss 13.355\n",
      "epoch 655, run 10, loss 5.06569\n",
      "epoch 655, run 20, loss 7.82879\n",
      "epoch 655, run 30, loss 11.5129\n",
      "epoch 656, run 0, loss 10.5919\n",
      "epoch 656, run 10, loss 9.67086\n",
      "epoch 656, run 20, loss 9.67086\n",
      "epoch 656, run 30, loss 15.1971\n",
      "epoch 657, run 0, loss 10.1314\n",
      "epoch 657, run 10, loss 9.67086\n",
      "epoch 657, run 20, loss 8.74982\n",
      "epoch 657, run 30, loss 11.5129\n",
      "epoch 658, run 0, loss 11.9734\n",
      "epoch 658, run 10, loss 8.74982\n",
      "epoch 658, run 20, loss 8.74982\n",
      "epoch 658, run 30, loss 9.67086\n",
      "epoch 659, run 0, loss 13.355\n",
      "epoch 659, run 10, loss 11.9734\n",
      "epoch 659, run 20, loss 5.98672\n",
      "epoch 659, run 30, loss 11.9734\n",
      "epoch 660, run 0, loss 10.1314\n",
      "epoch 660, run 10, loss 13.355\n",
      "epoch 660, run 20, loss 5.5262\n",
      "epoch 660, run 30, loss 11.5129\n",
      "epoch 661, run 0, loss 10.5919\n",
      "epoch 661, run 10, loss 10.1314\n",
      "epoch 661, run 20, loss 4.60517\n",
      "epoch 661, run 30, loss 9.67086\n",
      "epoch 662, run 0, loss 11.0524\n",
      "epoch 662, run 10, loss 12.8945\n",
      "epoch 662, run 20, loss 6.44724\n",
      "epoch 662, run 30, loss 11.5129\n",
      "epoch 663, run 0, loss 10.5919\n",
      "epoch 663, run 10, loss 9.21034\n",
      "epoch 663, run 20, loss 5.98672\n",
      "epoch 663, run 30, loss 10.5919\n",
      "epoch 664, run 0, loss 9.67086\n",
      "epoch 664, run 10, loss 8.74982\n",
      "epoch 664, run 20, loss 5.5262\n",
      "epoch 664, run 30, loss 8.74982\n",
      "epoch 665, run 0, loss 12.434\n",
      "epoch 665, run 10, loss 11.0524\n",
      "epoch 665, run 20, loss 4.14465\n",
      "epoch 665, run 30, loss 8.28931\n",
      "epoch 666, run 0, loss 10.1314\n",
      "epoch 666, run 10, loss 12.434\n",
      "epoch 666, run 20, loss 3.68414\n",
      "epoch 666, run 30, loss 5.98672\n",
      "epoch 667, run 0, loss 9.21034\n",
      "epoch 667, run 10, loss 12.434\n",
      "epoch 667, run 20, loss 8.74982\n",
      "epoch 667, run 30, loss 6.44724\n",
      "epoch 668, run 0, loss 7.36827\n",
      "epoch 668, run 10, loss 10.1314\n",
      "epoch 668, run 20, loss 8.74982\n",
      "epoch 668, run 30, loss 9.67086\n",
      "epoch 669, run 0, loss 6.44724\n",
      "epoch 669, run 10, loss 11.0524\n",
      "epoch 669, run 20, loss 5.98672\n",
      "epoch 669, run 30, loss 11.5129\n",
      "epoch 670, run 0, loss 6.44724\n",
      "epoch 670, run 10, loss 10.1314\n",
      "epoch 670, run 20, loss 4.60517\n",
      "epoch 670, run 30, loss 9.21034\n",
      "epoch 671, run 0, loss 10.1314\n",
      "epoch 671, run 10, loss 10.1314\n",
      "epoch 671, run 20, loss 2.30259\n",
      "epoch 671, run 30, loss 9.21034\n",
      "epoch 672, run 0, loss 11.5129\n",
      "epoch 672, run 10, loss 12.434\n",
      "epoch 672, run 20, loss 3.68414\n",
      "epoch 672, run 30, loss 7.36827\n",
      "epoch 673, run 0, loss 8.28931\n",
      "epoch 673, run 10, loss 10.1314\n",
      "epoch 673, run 20, loss 9.67086\n",
      "epoch 673, run 30, loss 9.67086\n",
      "epoch 674, run 0, loss 8.74982\n",
      "epoch 674, run 10, loss 10.1314\n",
      "epoch 674, run 20, loss 9.67086\n",
      "epoch 674, run 30, loss 9.67086\n",
      "epoch 675, run 0, loss 7.82879\n",
      "epoch 675, run 10, loss 11.5129\n",
      "epoch 675, run 20, loss 8.28931\n",
      "epoch 675, run 30, loss 8.28931\n",
      "epoch 676, run 0, loss 10.1314\n",
      "epoch 676, run 10, loss 15.1971\n",
      "epoch 676, run 20, loss 11.5129\n",
      "epoch 676, run 30, loss 5.98672\n",
      "epoch 677, run 0, loss 8.74982\n",
      "epoch 677, run 10, loss 11.5129\n",
      "epoch 677, run 20, loss 13.8155\n",
      "epoch 677, run 30, loss 5.06569\n",
      "epoch 678, run 0, loss 8.28931\n",
      "epoch 678, run 10, loss 9.21034\n",
      "epoch 678, run 20, loss 10.1314\n",
      "epoch 678, run 30, loss 5.06569\n",
      "epoch 679, run 0, loss 5.5262\n",
      "epoch 679, run 10, loss 12.434\n",
      "epoch 679, run 20, loss 12.434\n",
      "epoch 679, run 30, loss 6.90775\n",
      "epoch 680, run 0, loss 5.5262\n",
      "epoch 680, run 10, loss 11.5129\n",
      "epoch 680, run 20, loss 10.5919\n",
      "epoch 680, run 30, loss 5.98672\n",
      "epoch 681, run 0, loss 4.60517\n",
      "epoch 681, run 10, loss 9.21034\n",
      "epoch 681, run 20, loss 8.28931\n",
      "epoch 681, run 30, loss 4.14465\n",
      "epoch 682, run 0, loss 6.44724\n",
      "epoch 682, run 10, loss 11.9734\n",
      "epoch 682, run 20, loss 10.5919\n",
      "epoch 682, run 30, loss 4.14465\n",
      "epoch 683, run 0, loss 5.98672\n",
      "epoch 683, run 10, loss 10.5919\n",
      "epoch 683, run 20, loss 11.5129\n",
      "epoch 683, run 30, loss 3.68414\n",
      "epoch 684, run 0, loss 5.5262\n",
      "epoch 684, run 10, loss 8.74982\n",
      "epoch 684, run 20, loss 10.5919\n",
      "epoch 684, run 30, loss 6.90775\n",
      "epoch 685, run 0, loss 4.60517\n",
      "epoch 685, run 10, loss 7.82879\n",
      "epoch 685, run 20, loss 10.1314\n",
      "epoch 685, run 30, loss 8.74982\n",
      "epoch 686, run 0, loss 3.68414\n",
      "epoch 686, run 10, loss 5.98672\n",
      "epoch 686, run 20, loss 10.5919\n",
      "epoch 686, run 30, loss 5.5262\n",
      "epoch 687, run 0, loss 8.74982\n",
      "epoch 687, run 10, loss 5.98672\n",
      "epoch 687, run 20, loss 10.1314\n",
      "epoch 687, run 30, loss 3.68414\n",
      "epoch 688, run 0, loss 8.74982\n",
      "epoch 688, run 10, loss 9.67086\n",
      "epoch 688, run 20, loss 9.21034\n",
      "epoch 688, run 30, loss 2.30258\n",
      "epoch 689, run 0, loss 5.98672\n",
      "epoch 689, run 10, loss 11.5129\n",
      "epoch 689, run 20, loss 12.434\n",
      "epoch 689, run 30, loss 3.68414\n",
      "epoch 690, run 0, loss 4.60517\n",
      "epoch 690, run 10, loss 9.21034\n",
      "epoch 690, run 20, loss 11.5129\n",
      "epoch 690, run 30, loss 8.28931\n",
      "epoch 691, run 0, loss 2.7631\n",
      "epoch 691, run 10, loss 9.21034\n",
      "epoch 691, run 20, loss 10.5919\n",
      "epoch 691, run 30, loss 10.5919\n",
      "epoch 692, run 0, loss 3.68414\n",
      "epoch 692, run 10, loss 7.36827\n",
      "epoch 692, run 20, loss 11.9734\n",
      "epoch 692, run 30, loss 8.28931\n",
      "epoch 693, run 0, loss 9.67086\n",
      "epoch 693, run 10, loss 9.67086\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 693, run 20, loss 13.8155\n",
      "epoch 693, run 30, loss 10.5919\n",
      "epoch 694, run 0, loss 9.67086\n",
      "epoch 694, run 10, loss 9.21034\n",
      "epoch 694, run 20, loss 12.8945\n",
      "epoch 694, run 30, loss 13.8155\n",
      "epoch 695, run 0, loss 8.74982\n",
      "epoch 695, run 10, loss 8.28931\n",
      "epoch 695, run 20, loss 8.28931\n",
      "epoch 695, run 30, loss 11.5129\n",
      "epoch 696, run 0, loss 11.0524\n",
      "epoch 696, run 10, loss 5.98672\n",
      "epoch 696, run 20, loss 12.434\n",
      "epoch 696, run 30, loss 11.5129\n",
      "epoch 697, run 0, loss 13.8155\n",
      "epoch 697, run 10, loss 5.06569\n",
      "epoch 697, run 20, loss 11.9734\n",
      "epoch 697, run 30, loss 11.5129\n",
      "epoch 698, run 0, loss 10.5919\n",
      "epoch 698, run 10, loss 4.60517\n",
      "epoch 698, run 20, loss 9.21034\n",
      "epoch 698, run 30, loss 8.74982\n",
      "epoch 699, run 0, loss 12.434\n",
      "epoch 699, run 10, loss 6.90775\n",
      "epoch 699, run 20, loss 10.5919\n",
      "epoch 699, run 30, loss 9.67086\n",
      "epoch 700, run 0, loss 10.5919\n",
      "epoch 700, run 10, loss 5.98672\n",
      "epoch 700, run 20, loss 11.0524\n",
      "epoch 700, run 30, loss 11.9734\n",
      "epoch 701, run 0, loss 8.28931\n",
      "epoch 701, run 10, loss 4.14465\n",
      "epoch 701, run 20, loss 7.82879\n",
      "epoch 701, run 30, loss 11.5129\n",
      "epoch 702, run 0, loss 10.1314\n",
      "epoch 702, run 10, loss 4.14465\n",
      "epoch 702, run 20, loss 8.28931\n",
      "epoch 702, run 30, loss 10.5919\n",
      "epoch 703, run 0, loss 11.9734\n",
      "epoch 703, run 10, loss 3.68414\n",
      "epoch 703, run 20, loss 6.44724\n",
      "epoch 703, run 30, loss 10.5919\n",
      "epoch 704, run 0, loss 11.0524\n",
      "epoch 704, run 10, loss 7.36827\n",
      "epoch 704, run 20, loss 6.44724\n",
      "epoch 704, run 30, loss 10.5919\n",
      "epoch 705, run 0, loss 10.1314\n",
      "epoch 705, run 10, loss 8.28931\n",
      "epoch 705, run 20, loss 8.28931\n",
      "epoch 705, run 30, loss 9.21034\n",
      "epoch 706, run 0, loss 11.0524\n",
      "epoch 706, run 10, loss 5.5262\n",
      "epoch 706, run 20, loss 11.5129\n",
      "epoch 706, run 30, loss 12.434\n",
      "epoch 707, run 0, loss 10.1314\n",
      "epoch 707, run 10, loss 4.14465\n",
      "epoch 707, run 20, loss 8.74982\n",
      "epoch 707, run 30, loss 12.434\n",
      "epoch 708, run 0, loss 9.67086\n",
      "epoch 708, run 10, loss 2.30258\n",
      "epoch 708, run 20, loss 8.74982\n",
      "epoch 708, run 30, loss 10.1314\n",
      "epoch 709, run 0, loss 12.434\n",
      "epoch 709, run 10, loss 3.68414\n",
      "epoch 709, run 20, loss 8.28931\n",
      "epoch 709, run 30, loss 11.0524\n",
      "epoch 710, run 0, loss 11.5129\n",
      "epoch 710, run 10, loss 8.28931\n",
      "epoch 710, run 20, loss 8.28931\n",
      "epoch 710, run 30, loss 13.8155\n",
      "epoch 711, run 0, loss 10.1314\n",
      "epoch 711, run 10, loss 10.5919\n",
      "epoch 711, run 20, loss 9.67086\n",
      "epoch 711, run 30, loss 11.9734\n",
      "epoch 712, run 0, loss 11.5129\n",
      "epoch 712, run 10, loss 8.74982\n",
      "epoch 712, run 20, loss 8.28931\n",
      "epoch 712, run 30, loss 9.67086\n",
      "epoch 713, run 0, loss 14.276\n",
      "epoch 713, run 10, loss 10.5919\n",
      "epoch 713, run 20, loss 6.90775\n",
      "epoch 713, run 30, loss 10.5919\n",
      "epoch 714, run 0, loss 13.355\n",
      "epoch 714, run 10, loss 13.355\n",
      "epoch 714, run 20, loss 5.06569\n",
      "epoch 714, run 30, loss 11.9734\n",
      "epoch 715, run 0, loss 8.74982\n",
      "epoch 715, run 10, loss 11.5129\n",
      "epoch 715, run 20, loss 5.5262\n",
      "epoch 715, run 30, loss 8.74982\n",
      "epoch 716, run 0, loss 12.434\n",
      "epoch 716, run 10, loss 11.5129\n",
      "epoch 716, run 20, loss 5.5262\n",
      "epoch 716, run 30, loss 10.1314\n",
      "epoch 717, run 0, loss 11.5129\n",
      "epoch 717, run 10, loss 11.9734\n",
      "epoch 717, run 20, loss 5.5262\n",
      "epoch 717, run 30, loss 11.0524\n",
      "epoch 718, run 0, loss 9.21034\n",
      "epoch 718, run 10, loss 9.21034\n",
      "epoch 718, run 20, loss 3.22362\n",
      "epoch 718, run 30, loss 9.67086\n",
      "epoch 719, run 0, loss 10.5919\n",
      "epoch 719, run 10, loss 9.67086\n",
      "epoch 719, run 20, loss 4.60517\n",
      "epoch 719, run 30, loss 8.28931\n",
      "epoch 720, run 0, loss 11.0524\n",
      "epoch 720, run 10, loss 11.9734\n",
      "epoch 720, run 20, loss 4.14465\n",
      "epoch 720, run 30, loss 6.90775\n",
      "epoch 721, run 0, loss 7.82879\n",
      "epoch 721, run 10, loss 11.0524\n",
      "epoch 721, run 20, loss 6.44724\n",
      "epoch 721, run 30, loss 6.44724\n",
      "epoch 722, run 0, loss 8.28931\n",
      "epoch 722, run 10, loss 10.1314\n",
      "epoch 722, run 20, loss 8.74982\n",
      "epoch 722, run 30, loss 6.90775\n",
      "epoch 723, run 0, loss 6.44724\n",
      "epoch 723, run 10, loss 10.1314\n",
      "epoch 723, run 20, loss 6.44724\n",
      "epoch 723, run 30, loss 11.9734\n",
      "epoch 724, run 0, loss 6.44724\n",
      "epoch 724, run 10, loss 10.5919\n",
      "epoch 724, run 20, loss 5.06569\n",
      "epoch 724, run 30, loss 10.1314\n",
      "epoch 725, run 0, loss 8.28931\n",
      "epoch 725, run 10, loss 9.21034\n",
      "epoch 725, run 20, loss 3.22362\n",
      "epoch 725, run 30, loss 8.74982\n",
      "epoch 726, run 0, loss 11.5129\n",
      "epoch 726, run 10, loss 12.8945\n",
      "epoch 726, run 20, loss 3.68414\n",
      "epoch 726, run 30, loss 8.28931\n",
      "epoch 727, run 0, loss 9.21034\n",
      "epoch 727, run 10, loss 11.9734\n",
      "epoch 727, run 20, loss 6.90775\n",
      "epoch 727, run 30, loss 9.21034\n",
      "epoch 728, run 0, loss 8.28931\n",
      "epoch 728, run 10, loss 10.1314\n",
      "epoch 728, run 20, loss 9.67086\n",
      "epoch 728, run 30, loss 9.67086\n",
      "epoch 729, run 0, loss 8.28931\n",
      "epoch 729, run 10, loss 11.0524\n",
      "epoch 729, run 20, loss 9.21034\n",
      "epoch 729, run 30, loss 9.21034\n",
      "epoch 730, run 0, loss 8.28931\n",
      "epoch 730, run 10, loss 13.8155\n",
      "epoch 730, run 20, loss 9.67086\n",
      "epoch 730, run 30, loss 7.36827\n",
      "epoch 731, run 0, loss 9.21034\n",
      "epoch 731, run 10, loss 12.434\n",
      "epoch 731, run 20, loss 13.8155\n",
      "epoch 731, run 30, loss 5.06569\n",
      "epoch 732, run 0, loss 8.74982\n",
      "epoch 732, run 10, loss 9.21034\n",
      "epoch 732, run 20, loss 11.5129\n",
      "epoch 732, run 30, loss 5.5262\n",
      "epoch 733, run 0, loss 6.90775\n",
      "epoch 733, run 10, loss 11.0524\n",
      "epoch 733, run 20, loss 10.5919\n",
      "epoch 733, run 30, loss 4.14465\n",
      "epoch 734, run 0, loss 5.06569\n",
      "epoch 734, run 10, loss 11.9734\n",
      "epoch 734, run 20, loss 11.9734\n",
      "epoch 734, run 30, loss 5.98672\n",
      "epoch 735, run 0, loss 5.06569\n",
      "epoch 735, run 10, loss 9.21034\n",
      "epoch 735, run 20, loss 9.21034\n",
      "epoch 735, run 30, loss 4.60517\n",
      "epoch 736, run 0, loss 5.5262\n",
      "epoch 736, run 10, loss 10.5919\n",
      "epoch 736, run 20, loss 8.28931\n",
      "epoch 736, run 30, loss 5.5262\n",
      "epoch 737, run 0, loss 5.5262\n",
      "epoch 737, run 10, loss 11.0524\n",
      "epoch 737, run 20, loss 10.5919\n",
      "epoch 737, run 30, loss 4.60517\n",
      "epoch 738, run 0, loss 3.22362\n",
      "epoch 738, run 10, loss 9.67086\n",
      "epoch 738, run 20, loss 11.5129\n",
      "epoch 738, run 30, loss 5.5262\n",
      "epoch 739, run 0, loss 4.60517\n",
      "epoch 739, run 10, loss 8.28931\n",
      "epoch 739, run 20, loss 11.5129\n",
      "epoch 739, run 30, loss 8.74982\n",
      "epoch 740, run 0, loss 3.68414\n",
      "epoch 740, run 10, loss 6.44724\n",
      "epoch 740, run 20, loss 10.5919\n",
      "epoch 740, run 30, loss 7.36827\n",
      "epoch 741, run 0, loss 6.44724\n",
      "epoch 741, run 10, loss 6.44724\n",
      "epoch 741, run 20, loss 11.9734\n",
      "epoch 741, run 30, loss 5.5262\n",
      "epoch 742, run 0, loss 8.74982\n",
      "epoch 742, run 10, loss 7.36827\n",
      "epoch 742, run 20, loss 10.1314\n",
      "epoch 742, run 30, loss 3.68414\n",
      "epoch 743, run 0, loss 6.44724\n",
      "epoch 743, run 10, loss 11.9734\n",
      "epoch 743, run 20, loss 12.434\n",
      "epoch 743, run 30, loss 2.7631\n",
      "epoch 744, run 0, loss 4.60517\n",
      "epoch 744, run 10, loss 10.1314\n",
      "epoch 744, run 20, loss 12.8945\n",
      "epoch 744, run 30, loss 5.5262\n",
      "epoch 745, run 0, loss 3.22362\n",
      "epoch 745, run 10, loss 8.74982\n",
      "epoch 745, run 20, loss 9.67086\n",
      "epoch 745, run 30, loss 9.21034\n",
      "epoch 746, run 0, loss 3.68414\n",
      "epoch 746, run 10, loss 8.74982\n",
      "epoch 746, run 20, loss 10.5919\n",
      "epoch 746, run 30, loss 9.67086\n",
      "epoch 747, run 0, loss 7.36827\n",
      "epoch 747, run 10, loss 8.74982\n",
      "epoch 747, run 20, loss 12.434\n",
      "epoch 747, run 30, loss 9.21034\n",
      "epoch 748, run 0, loss 9.67086\n",
      "epoch 748, run 10, loss 10.1314\n",
      "epoch 748, run 20, loss 13.355\n",
      "epoch 748, run 30, loss 12.434\n",
      "epoch 749, run 0, loss 8.74982\n",
      "epoch 749, run 10, loss 9.67086\n",
      "epoch 749, run 20, loss 10.1314\n",
      "epoch 749, run 30, loss 12.434\n",
      "epoch 750, run 0, loss 10.1314\n",
      "epoch 750, run 10, loss 7.36827\n",
      "epoch 750, run 20, loss 10.5919\n",
      "epoch 750, run 30, loss 10.1314\n",
      "epoch 751, run 0, loss 13.355\n",
      "epoch 751, run 10, loss 5.06569\n",
      "epoch 751, run 20, loss 11.5129\n",
      "epoch 751, run 30, loss 12.434\n",
      "epoch 752, run 0, loss 11.5129\n",
      "epoch 752, run 10, loss 5.5262\n",
      "epoch 752, run 20, loss 10.1314\n",
      "epoch 752, run 30, loss 9.21034\n",
      "epoch 753, run 0, loss 10.5919\n",
      "epoch 753, run 10, loss 4.14465\n",
      "epoch 753, run 20, loss 9.67086\n",
      "epoch 753, run 30, loss 9.21034\n",
      "epoch 754, run 0, loss 11.5129\n",
      "epoch 754, run 10, loss 5.98672\n",
      "epoch 754, run 20, loss 11.5129\n",
      "epoch 754, run 30, loss 11.0524\n",
      "epoch 755, run 0, loss 9.21034\n",
      "epoch 755, run 10, loss 4.60517\n",
      "epoch 755, run 20, loss 9.67086\n",
      "epoch 755, run 30, loss 12.434\n",
      "epoch 756, run 0, loss 8.74982\n",
      "epoch 756, run 10, loss 5.5262\n",
      "epoch 756, run 20, loss 9.67086\n",
      "epoch 756, run 30, loss 11.9734\n",
      "epoch 757, run 0, loss 11.0524\n",
      "epoch 757, run 10, loss 4.60517\n",
      "epoch 757, run 20, loss 7.36827\n",
      "epoch 757, run 30, loss 9.67086\n",
      "epoch 758, run 0, loss 11.9734\n",
      "epoch 758, run 10, loss 5.98672\n",
      "epoch 758, run 20, loss 7.36827\n",
      "epoch 758, run 30, loss 11.5129\n",
      "epoch 759, run 0, loss 11.0524\n",
      "epoch 759, run 10, loss 8.74982\n",
      "epoch 759, run 20, loss 6.90775\n",
      "epoch 759, run 30, loss 10.5919\n",
      "epoch 760, run 0, loss 10.5919\n",
      "epoch 760, run 10, loss 7.36827\n",
      "epoch 760, run 20, loss 11.0524\n",
      "epoch 760, run 30, loss 10.5919\n",
      "epoch 761, run 0, loss 11.9734\n",
      "epoch 761, run 10, loss 5.5262\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 761, run 20, loss 11.0524\n",
      "epoch 761, run 30, loss 12.8945\n",
      "epoch 762, run 0, loss 9.67086\n",
      "epoch 762, run 10, loss 3.68414\n",
      "epoch 762, run 20, loss 9.21034\n",
      "epoch 762, run 30, loss 11.0524\n",
      "epoch 763, run 0, loss 12.434\n",
      "epoch 763, run 10, loss 3.22362\n",
      "epoch 763, run 20, loss 8.28931\n",
      "epoch 763, run 30, loss 9.67086\n",
      "epoch 764, run 0, loss 12.8945\n",
      "epoch 764, run 10, loss 5.5262\n",
      "epoch 764, run 20, loss 8.74982\n",
      "epoch 764, run 30, loss 11.5129\n",
      "epoch 765, run 0, loss 10.1314\n",
      "epoch 765, run 10, loss 9.21034\n",
      "epoch 765, run 20, loss 9.67086\n",
      "epoch 765, run 30, loss 14.276\n",
      "epoch 766, run 0, loss 11.0524\n",
      "epoch 766, run 10, loss 9.67086\n",
      "epoch 766, run 20, loss 9.21034\n",
      "epoch 766, run 30, loss 11.0524\n",
      "epoch 767, run 0, loss 12.434\n",
      "epoch 767, run 10, loss 9.67086\n",
      "epoch 767, run 20, loss 7.36827\n",
      "epoch 767, run 30, loss 9.67086\n",
      "epoch 768, run 0, loss 12.8945\n",
      "epoch 768, run 10, loss 11.9734\n",
      "epoch 768, run 20, loss 5.5262\n",
      "epoch 768, run 30, loss 11.9734\n",
      "epoch 769, run 0, loss 10.1314\n",
      "epoch 769, run 10, loss 11.9734\n",
      "epoch 769, run 20, loss 5.06569\n",
      "epoch 769, run 30, loss 11.0524\n",
      "epoch 770, run 0, loss 10.5919\n",
      "epoch 770, run 10, loss 10.1314\n",
      "epoch 770, run 20, loss 5.06569\n",
      "epoch 770, run 30, loss 9.67086\n",
      "epoch 771, run 0, loss 11.5129\n",
      "epoch 771, run 10, loss 11.9734\n",
      "epoch 771, run 20, loss 6.44724\n",
      "epoch 771, run 30, loss 12.434\n",
      "epoch 772, run 0, loss 10.1314\n",
      "epoch 772, run 10, loss 9.67086\n",
      "epoch 772, run 20, loss 5.5262\n",
      "epoch 772, run 30, loss 10.5919\n",
      "epoch 773, run 0, loss 9.21034\n",
      "epoch 773, run 10, loss 9.21034\n",
      "epoch 773, run 20, loss 5.06569\n",
      "epoch 773, run 30, loss 8.74982\n",
      "epoch 774, run 0, loss 11.5129\n",
      "epoch 774, run 10, loss 11.0524\n",
      "epoch 774, run 20, loss 5.06569\n",
      "epoch 774, run 30, loss 7.82879\n",
      "epoch 775, run 0, loss 9.67086\n",
      "epoch 775, run 10, loss 11.9734\n",
      "epoch 775, run 20, loss 4.14465\n",
      "epoch 775, run 30, loss 5.98672\n",
      "epoch 776, run 0, loss 9.67086\n",
      "epoch 776, run 10, loss 12.434\n",
      "epoch 776, run 20, loss 8.74982\n",
      "epoch 776, run 30, loss 6.44724\n",
      "epoch 777, run 0, loss 7.36827\n",
      "epoch 777, run 10, loss 10.1314\n",
      "epoch 777, run 20, loss 8.74982\n",
      "epoch 777, run 30, loss 9.67086\n",
      "epoch 778, run 0, loss 6.90775\n",
      "epoch 778, run 10, loss 11.5129\n",
      "epoch 778, run 20, loss 5.5262\n",
      "epoch 778, run 30, loss 11.9734\n",
      "epoch 779, run 0, loss 6.90775\n",
      "epoch 779, run 10, loss 10.5919\n",
      "epoch 779, run 20, loss 4.60517\n",
      "epoch 779, run 30, loss 8.28931\n",
      "epoch 780, run 0, loss 11.0524\n",
      "epoch 780, run 10, loss 11.0524\n",
      "epoch 780, run 20, loss 2.7631\n",
      "epoch 780, run 30, loss 9.21034\n",
      "epoch 781, run 0, loss 10.5919\n",
      "epoch 781, run 10, loss 13.355\n",
      "epoch 781, run 20, loss 4.14465\n",
      "epoch 781, run 30, loss 7.36827\n",
      "epoch 782, run 0, loss 9.21034\n",
      "epoch 782, run 10, loss 10.5919\n",
      "epoch 782, run 20, loss 9.21034\n",
      "epoch 782, run 30, loss 10.1314\n",
      "epoch 783, run 0, loss 7.82879\n",
      "epoch 783, run 10, loss 10.1314\n",
      "epoch 783, run 20, loss 9.67086\n",
      "epoch 783, run 30, loss 9.21034\n",
      "epoch 784, run 0, loss 8.28931\n",
      "epoch 784, run 10, loss 11.5129\n",
      "epoch 784, run 20, loss 9.67086\n",
      "epoch 784, run 30, loss 8.74982\n",
      "epoch 785, run 0, loss 9.67086\n",
      "epoch 785, run 10, loss 13.8155\n",
      "epoch 785, run 20, loss 11.0524\n",
      "epoch 785, run 30, loss 5.98672\n",
      "epoch 786, run 0, loss 9.21034\n",
      "epoch 786, run 10, loss 11.0524\n",
      "epoch 786, run 20, loss 12.8945\n",
      "epoch 786, run 30, loss 5.5262\n",
      "epoch 787, run 0, loss 7.36827\n",
      "epoch 787, run 10, loss 9.67086\n",
      "epoch 787, run 20, loss 10.1314\n",
      "epoch 787, run 30, loss 5.06569\n",
      "epoch 788, run 0, loss 5.5262\n",
      "epoch 788, run 10, loss 11.9734\n",
      "epoch 788, run 20, loss 12.434\n",
      "epoch 788, run 30, loss 6.90775\n",
      "epoch 789, run 0, loss 5.5262\n",
      "epoch 789, run 10, loss 11.5129\n",
      "epoch 789, run 20, loss 10.5919\n",
      "epoch 789, run 30, loss 5.5262\n",
      "epoch 790, run 0, loss 5.06569\n",
      "epoch 790, run 10, loss 9.67086\n",
      "epoch 790, run 20, loss 8.74982\n",
      "epoch 790, run 30, loss 4.60517\n",
      "epoch 791, run 0, loss 6.44724\n",
      "epoch 791, run 10, loss 12.434\n",
      "epoch 791, run 20, loss 10.5919\n",
      "epoch 791, run 30, loss 4.60517\n",
      "epoch 792, run 0, loss 5.06569\n",
      "epoch 792, run 10, loss 10.1314\n",
      "epoch 792, run 20, loss 11.9734\n",
      "epoch 792, run 30, loss 3.68414\n",
      "epoch 793, run 0, loss 5.06569\n",
      "epoch 793, run 10, loss 9.21034\n",
      "epoch 793, run 20, loss 11.5129\n",
      "epoch 793, run 30, loss 7.36827\n",
      "epoch 794, run 0, loss 5.06569\n",
      "epoch 794, run 10, loss 7.36827\n",
      "epoch 794, run 20, loss 10.1314\n",
      "epoch 794, run 30, loss 9.21034\n",
      "epoch 795, run 0, loss 4.14465\n",
      "epoch 795, run 10, loss 5.98672\n",
      "epoch 795, run 20, loss 11.0524\n",
      "epoch 795, run 30, loss 5.5262\n",
      "epoch 796, run 0, loss 8.28931\n",
      "epoch 796, run 10, loss 6.90775\n",
      "epoch 796, run 20, loss 9.67086\n",
      "epoch 796, run 30, loss 4.14465\n",
      "epoch 797, run 0, loss 8.28931\n",
      "epoch 797, run 10, loss 9.21034\n",
      "epoch 797, run 20, loss 10.1314\n",
      "epoch 797, run 30, loss 1.84207\n",
      "epoch 798, run 0, loss 5.98672\n",
      "epoch 798, run 10, loss 11.5129\n",
      "epoch 798, run 20, loss 11.9734\n",
      "epoch 798, run 30, loss 3.68414\n",
      "epoch 799, run 0, loss 4.14465\n",
      "epoch 799, run 10, loss 7.82879\n",
      "epoch 799, run 20, loss 11.5129\n",
      "epoch 799, run 30, loss 8.74982\n",
      "epoch 800, run 0, loss 2.7631\n",
      "epoch 800, run 10, loss 8.74982\n",
      "epoch 800, run 20, loss 10.5919\n",
      "epoch 800, run 30, loss 10.1314\n",
      "epoch 801, run 0, loss 4.14465\n",
      "epoch 801, run 10, loss 7.36827\n",
      "epoch 801, run 20, loss 11.5129\n",
      "epoch 801, run 30, loss 8.74982\n",
      "epoch 802, run 0, loss 9.21034\n",
      "epoch 802, run 10, loss 9.67086\n",
      "epoch 802, run 20, loss 14.276\n",
      "epoch 802, run 30, loss 10.5919\n",
      "epoch 803, run 0, loss 10.1314\n",
      "epoch 803, run 10, loss 8.74982\n",
      "epoch 803, run 20, loss 12.434\n",
      "epoch 803, run 30, loss 13.8155\n",
      "epoch 804, run 0, loss 9.67086\n",
      "epoch 804, run 10, loss 8.74982\n",
      "epoch 804, run 20, loss 8.28931\n",
      "epoch 804, run 30, loss 11.5129\n",
      "epoch 805, run 0, loss 11.0524\n",
      "epoch 805, run 10, loss 5.98672\n",
      "epoch 805, run 20, loss 11.9734\n",
      "epoch 805, run 30, loss 11.9734\n",
      "epoch 806, run 0, loss 12.8945\n",
      "epoch 806, run 10, loss 5.5262\n",
      "epoch 806, run 20, loss 11.0524\n",
      "epoch 806, run 30, loss 11.9734\n",
      "epoch 807, run 0, loss 10.1314\n",
      "epoch 807, run 10, loss 5.06569\n",
      "epoch 807, run 20, loss 9.21034\n",
      "epoch 807, run 30, loss 8.74982\n",
      "epoch 808, run 0, loss 12.8945\n",
      "epoch 808, run 10, loss 6.90775\n",
      "epoch 808, run 20, loss 11.0524\n",
      "epoch 808, run 30, loss 10.1314\n",
      "epoch 809, run 0, loss 10.1314\n",
      "epoch 809, run 10, loss 5.98672\n",
      "epoch 809, run 20, loss 11.5129\n",
      "epoch 809, run 30, loss 12.434\n",
      "epoch 810, run 0, loss 8.74982\n",
      "epoch 810, run 10, loss 5.06569\n",
      "epoch 810, run 20, loss 8.28931\n",
      "epoch 810, run 30, loss 11.0524\n",
      "epoch 811, run 0, loss 10.5919\n",
      "epoch 811, run 10, loss 4.60517\n",
      "epoch 811, run 20, loss 8.74982\n",
      "epoch 811, run 30, loss 9.67086\n",
      "epoch 812, run 0, loss 11.9734\n",
      "epoch 812, run 10, loss 4.14465\n",
      "epoch 812, run 20, loss 6.44724\n",
      "epoch 812, run 30, loss 11.0524\n",
      "epoch 813, run 0, loss 11.5129\n",
      "epoch 813, run 10, loss 7.36827\n",
      "epoch 813, run 20, loss 5.98672\n",
      "epoch 813, run 30, loss 10.1314\n",
      "epoch 814, run 0, loss 10.5919\n",
      "epoch 814, run 10, loss 9.21034\n",
      "epoch 814, run 20, loss 9.21034\n",
      "epoch 814, run 30, loss 9.21034\n",
      "epoch 815, run 0, loss 11.5129\n",
      "epoch 815, run 10, loss 5.98672\n",
      "epoch 815, run 20, loss 11.0524\n",
      "epoch 815, run 30, loss 12.434\n",
      "epoch 816, run 0, loss 10.1314\n",
      "epoch 816, run 10, loss 4.14465\n",
      "epoch 816, run 20, loss 9.67086\n",
      "epoch 816, run 30, loss 11.5129\n",
      "epoch 817, run 0, loss 10.1314\n",
      "epoch 817, run 10, loss 2.30259\n",
      "epoch 817, run 20, loss 9.21034\n",
      "epoch 817, run 30, loss 10.5919\n",
      "epoch 818, run 0, loss 12.434\n",
      "epoch 818, run 10, loss 3.68414\n",
      "epoch 818, run 20, loss 7.82879\n",
      "epoch 818, run 30, loss 11.5129\n",
      "epoch 819, run 0, loss 11.0524\n",
      "epoch 819, run 10, loss 9.21034\n",
      "epoch 819, run 20, loss 8.28931\n",
      "epoch 819, run 30, loss 13.355\n",
      "epoch 820, run 0, loss 10.5919\n",
      "epoch 820, run 10, loss 10.5919\n",
      "epoch 820, run 20, loss 9.67086\n",
      "epoch 820, run 30, loss 12.8945\n",
      "epoch 821, run 0, loss 11.5129\n",
      "epoch 821, run 10, loss 8.28931\n",
      "epoch 821, run 20, loss 8.74982\n",
      "epoch 821, run 30, loss 8.74982\n",
      "epoch 822, run 0, loss 14.7365\n",
      "epoch 822, run 10, loss 11.0524\n",
      "epoch 822, run 20, loss 6.90775\n",
      "epoch 822, run 30, loss 11.5129\n",
      "epoch 823, run 0, loss 11.9734\n",
      "epoch 823, run 10, loss 13.8155\n",
      "epoch 823, run 20, loss 5.06569\n",
      "epoch 823, run 30, loss 12.434\n",
      "epoch 824, run 0, loss 8.74982\n",
      "epoch 824, run 10, loss 11.5129\n",
      "epoch 824, run 20, loss 5.06569\n",
      "epoch 824, run 30, loss 9.21034\n",
      "epoch 825, run 0, loss 11.9734\n",
      "epoch 825, run 10, loss 11.5129\n",
      "epoch 825, run 20, loss 5.5262\n",
      "epoch 825, run 30, loss 10.5919\n",
      "epoch 826, run 0, loss 11.0524\n",
      "epoch 826, run 10, loss 11.5129\n",
      "epoch 826, run 20, loss 5.5262\n",
      "epoch 826, run 30, loss 11.0524\n",
      "epoch 827, run 0, loss 9.21034\n",
      "epoch 827, run 10, loss 8.74982\n",
      "epoch 827, run 20, loss 3.22362\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-155-f8200b7687f9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m#         print(x_.shape, y_.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m#         print(type(x_), type(y_))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0my_\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mj\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m10\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/harrygong/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    787\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 789\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    790\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/harrygong/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    995\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 997\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    998\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    999\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/harrygong/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1130\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1132\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1133\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/home/harrygong/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1137\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1139\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1140\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/harrygong/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1119\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1120\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1121\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(epoch):\n",
    "    xloss = 0\n",
    "    \n",
    "    for j in range(total_batch):\n",
    "        # need to incoporate y in the batches and expand to 8 classes \n",
    "        index, x_, y_ = next_batch(train_doc_embed_with_class, index, batch_size)\n",
    "#         print(x_.shape, y_.shape)\n",
    "#         print(type(x_), type(y_))\n",
    "        _, xloss = sess.run([optimizer, loss], feed_dict={x: x_, y: y_})\n",
    "        \n",
    "        if j % 10 == 0:\n",
    "            print(\"epoch %d, run %d, loss %g\" % (i, j, xloss))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(pred, tf.argmax(y, 1)), tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_doc_embed_with_class = embedded_with_class(model, valid_doc, len(label_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "(250, 100)\n",
      "(250, 8)\n",
      "(array([[ 0.45717028, -0.01775449,  0.89623034, ..., -0.31501675,\n",
      "         0.68082738, -0.41110277],\n",
      "       [ 0.47098407, -0.00393966,  0.71919209, ..., -0.52422023,\n",
      "         0.59656417, -0.30626851],\n",
      "       [ 0.60405642,  0.04082353,  0.88992083, ..., -0.23265001,\n",
      "         0.67125058, -0.46151358],\n",
      "       ..., \n",
      "       [ 0.57207495,  0.04660853,  0.87777597, ..., -0.30794084,\n",
      "         0.72478807, -0.45665005],\n",
      "       [ 0.38446307,  0.1561233 ,  0.80170846, ..., -0.1633113 ,\n",
      "         0.5337075 , -0.36341241],\n",
      "       [ 0.55622065,  0.03490572,  0.83159536, ..., -0.35373959,\n",
      "         0.63436121, -0.40071458]], dtype=float32), array([[0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 1, 0, 0],\n",
      "       ..., \n",
      "       [0, 1, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 1, ..., 0, 0, 0],\n",
      "       [0, 1, 0, ..., 0, 0, 0]]))\n"
     ]
    }
   ],
   "source": [
    "print(len(valid_doc_embed_with_class))\n",
    "print(valid_doc_embed_with_class[0].shape)\n",
    "print(valid_doc_embed_with_class[1].shape)\n",
    "print(valid_doc_embed_with_class[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_doc_embed_with_class = embedded_with_class(model, test_doc, len(label_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "(249, 100)\n",
      "(249, 8)\n",
      "[[1 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 0 1]\n",
      " [1 0 0 ..., 0 0 0]\n",
      " ..., \n",
      " [0 1 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 0 1]\n",
      " [1 0 0 ..., 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "print(len(test_doc_embed_with_class))\n",
    "print(test_doc_embed_with_class[0].shape)\n",
    "print(test_doc_embed_with_class[1].shape)\n",
    "print(test_doc_embed_with_class[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(250, 100)\n",
      "(250, 8)\n"
     ]
    }
   ],
   "source": [
    "x_valid, y_valid = (valid_doc_embed_with_class[0], valid_doc_embed_with_class[1])\n",
    "print(x_valid.shape)\n",
    "print(y_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 100)\n",
      "(?, 8)\n"
     ]
    }
   ],
   "source": [
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.344\n"
     ]
    }
   ],
   "source": [
    "acc = sess.run(accuracy, feed_dict={x:valid_doc_embed_with_class[0], y:valid_doc_embed_with_class[1]})\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epoch = 6000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, run 0, loss 21.3644\n",
      "epoch 0, run 30, loss 22.5653\n",
      "Validation acc: 13.2%\n",
      "epoch 1, run 0, loss 21.1838\n",
      "epoch 1, run 30, loss 22.5653\n",
      "epoch 2, run 0, loss 22.1048\n",
      "epoch 2, run 30, loss 21.1838\n",
      "epoch 3, run 0, loss 22.1048\n",
      "epoch 3, run 30, loss 20.7233\n",
      "epoch 4, run 0, loss 22.1048\n",
      "epoch 4, run 30, loss 21.6443\n",
      "epoch 5, run 0, loss 20.7233\n",
      "epoch 5, run 30, loss 21.6443\n",
      "epoch 6, run 0, loss 21.6443\n",
      "epoch 6, run 30, loss 21.1838\n",
      "epoch 7, run 0, loss 21.6443\n",
      "epoch 7, run 30, loss 21.6443\n",
      "epoch 8, run 0, loss 21.6443\n",
      "epoch 8, run 30, loss 22.5653\n",
      "epoch 9, run 0, loss 21.1838\n",
      "epoch 9, run 30, loss 23.0259\n",
      "epoch 10, run 0, loss 22.1048\n",
      "epoch 10, run 30, loss 22.1048\n",
      "epoch 11, run 0, loss 23.0259\n",
      "epoch 11, run 30, loss 21.6443\n",
      "epoch 12, run 0, loss 22.5653\n",
      "epoch 12, run 30, loss 22.1048\n",
      "epoch 13, run 0, loss 22.1048\n",
      "epoch 13, run 30, loss 23.0259\n",
      "epoch 14, run 0, loss 21.6443\n",
      "epoch 14, run 30, loss 22.5653\n",
      "epoch 15, run 0, loss 22.1048\n",
      "epoch 15, run 30, loss 22.5653\n",
      "epoch 16, run 0, loss 23.0259\n",
      "epoch 16, run 30, loss 22.5653\n",
      "epoch 17, run 0, loss 22.5653\n",
      "epoch 17, run 30, loss 22.1048\n",
      "epoch 18, run 0, loss 22.5653\n",
      "epoch 18, run 30, loss 22.5653\n",
      "epoch 19, run 0, loss 22.5653\n",
      "epoch 19, run 30, loss 23.0259\n",
      "epoch 20, run 0, loss 22.5653\n",
      "epoch 20, run 30, loss 23.0259\n",
      "epoch 21, run 0, loss 22.5653\n",
      "epoch 21, run 30, loss 23.0259\n",
      "epoch 22, run 0, loss 23.0259\n",
      "epoch 22, run 30, loss 22.5653\n",
      "epoch 23, run 0, loss 23.0259\n",
      "epoch 23, run 30, loss 22.5653\n",
      "epoch 24, run 0, loss 23.0259\n",
      "epoch 24, run 30, loss 22.1048\n",
      "epoch 25, run 0, loss 22.5653\n",
      "epoch 25, run 30, loss 21.6443\n",
      "epoch 26, run 0, loss 22.5653\n",
      "epoch 26, run 30, loss 20.7233\n",
      "epoch 27, run 0, loss 21.6443\n",
      "epoch 27, run 30, loss 20.7233\n",
      "epoch 28, run 0, loss 22.1048\n",
      "epoch 28, run 30, loss 21.1838\n",
      "epoch 29, run 0, loss 20.2627\n",
      "epoch 29, run 30, loss 19.3417\n",
      "epoch 30, run 0, loss 21.1838\n",
      "epoch 30, run 30, loss 21.1838\n",
      "epoch 31, run 0, loss 20.2627\n",
      "epoch 31, run 30, loss 22.5653\n",
      "epoch 32, run 0, loss 19.3417\n",
      "epoch 32, run 30, loss 20.7233\n",
      "epoch 33, run 0, loss 21.1838\n",
      "epoch 33, run 30, loss 21.6443\n",
      "epoch 34, run 0, loss 21.6443\n",
      "epoch 34, run 30, loss 22.1048\n",
      "epoch 35, run 0, loss 20.7233\n",
      "epoch 35, run 30, loss 21.6443\n",
      "epoch 36, run 0, loss 22.1048\n",
      "epoch 36, run 30, loss 21.1838\n",
      "epoch 37, run 0, loss 21.1838\n",
      "epoch 37, run 30, loss 20.7233\n",
      "epoch 38, run 0, loss 20.2627\n",
      "epoch 38, run 30, loss 21.6443\n",
      "epoch 39, run 0, loss 20.2627\n",
      "epoch 39, run 30, loss 22.1048\n",
      "epoch 40, run 0, loss 20.7233\n",
      "epoch 40, run 30, loss 21.1838\n",
      "epoch 41, run 0, loss 22.1048\n",
      "epoch 41, run 30, loss 20.2627\n",
      "epoch 42, run 0, loss 21.6443\n",
      "epoch 42, run 30, loss 20.2627\n",
      "epoch 43, run 0, loss 20.7233\n",
      "epoch 43, run 30, loss 20.7233\n",
      "epoch 44, run 0, loss 20.2627\n",
      "epoch 44, run 30, loss 21.6443\n",
      "epoch 45, run 0, loss 20.2627\n",
      "epoch 45, run 30, loss 19.8022\n",
      "epoch 46, run 0, loss 20.7233\n",
      "epoch 46, run 30, loss 19.3417\n",
      "epoch 47, run 0, loss 21.1838\n",
      "epoch 47, run 30, loss 20.2627\n",
      "epoch 48, run 0, loss 20.2627\n",
      "epoch 48, run 30, loss 20.2627\n",
      "epoch 49, run 0, loss 20.2627\n",
      "epoch 49, run 30, loss 20.7233\n",
      "epoch 50, run 0, loss 20.7233\n",
      "epoch 50, run 30, loss 22.1048\n",
      "epoch 51, run 0, loss 21.1838\n",
      "epoch 51, run 30, loss 22.5653\n",
      "epoch 52, run 0, loss 21.1838\n",
      "epoch 52, run 30, loss 21.6443\n",
      "epoch 53, run 0, loss 22.1048\n",
      "epoch 53, run 30, loss 22.1048\n",
      "epoch 54, run 0, loss 21.6443\n",
      "epoch 54, run 30, loss 22.5653\n",
      "epoch 55, run 0, loss 21.1838\n",
      "epoch 55, run 30, loss 22.1048\n",
      "epoch 56, run 0, loss 22.1048\n",
      "epoch 56, run 30, loss 21.1838\n",
      "epoch 57, run 0, loss 22.5653\n",
      "epoch 57, run 30, loss 20.7233\n",
      "epoch 58, run 0, loss 22.5653\n",
      "epoch 58, run 30, loss 21.6443\n",
      "epoch 59, run 0, loss 20.7233\n",
      "epoch 59, run 30, loss 22.1048\n",
      "epoch 60, run 0, loss 20.2627\n",
      "epoch 60, run 30, loss 21.1838\n",
      "epoch 61, run 0, loss 21.6443\n",
      "epoch 61, run 30, loss 20.7233\n",
      "epoch 62, run 0, loss 22.1048\n",
      "epoch 62, run 30, loss 22.1048\n",
      "epoch 63, run 0, loss 21.6443\n",
      "epoch 63, run 30, loss 23.0259\n",
      "epoch 64, run 0, loss 21.6443\n",
      "epoch 64, run 30, loss 22.5653\n",
      "epoch 65, run 0, loss 22.5653\n",
      "epoch 65, run 30, loss 22.1048\n",
      "epoch 66, run 0, loss 23.0259\n",
      "epoch 66, run 30, loss 21.6443\n",
      "epoch 67, run 0, loss 22.5653\n",
      "epoch 67, run 30, loss 23.0259\n",
      "epoch 68, run 0, loss 21.1838\n",
      "epoch 68, run 30, loss 23.0259\n",
      "epoch 69, run 0, loss 22.1048\n",
      "epoch 69, run 30, loss 22.5653\n",
      "epoch 70, run 0, loss 23.0259\n",
      "epoch 70, run 30, loss 22.1048\n",
      "epoch 71, run 0, loss 23.0259\n",
      "epoch 71, run 30, loss 22.5653\n",
      "epoch 72, run 0, loss 22.5653\n",
      "epoch 72, run 30, loss 22.5653\n",
      "epoch 73, run 0, loss 22.5653\n",
      "epoch 73, run 30, loss 22.5653\n",
      "epoch 74, run 0, loss 22.5653\n",
      "epoch 74, run 30, loss 23.0259\n",
      "epoch 75, run 0, loss 22.5653\n",
      "epoch 75, run 30, loss 23.0259\n",
      "epoch 76, run 0, loss 23.0259\n",
      "epoch 76, run 30, loss 22.5653\n",
      "epoch 77, run 0, loss 23.0259\n",
      "epoch 77, run 30, loss 22.5653\n",
      "epoch 78, run 0, loss 23.0259\n",
      "epoch 78, run 30, loss 22.1048\n",
      "epoch 79, run 0, loss 22.5653\n",
      "epoch 79, run 30, loss 21.6443\n",
      "epoch 80, run 0, loss 22.5653\n",
      "epoch 80, run 30, loss 21.6443\n",
      "epoch 81, run 0, loss 22.1048\n",
      "epoch 81, run 30, loss 20.2627\n",
      "epoch 82, run 0, loss 22.1048\n",
      "epoch 82, run 30, loss 21.6443\n",
      "epoch 83, run 0, loss 20.7233\n",
      "epoch 83, run 30, loss 20.2627\n",
      "epoch 84, run 0, loss 20.7233\n",
      "epoch 84, run 30, loss 20.2627\n",
      "epoch 85, run 0, loss 21.6443\n",
      "epoch 85, run 30, loss 21.1838\n",
      "epoch 86, run 0, loss 20.2627\n",
      "epoch 86, run 30, loss 21.1838\n",
      "epoch 87, run 0, loss 20.2627\n",
      "epoch 87, run 30, loss 20.7233\n",
      "epoch 88, run 0, loss 22.1048\n",
      "epoch 88, run 30, loss 22.5653\n",
      "epoch 89, run 0, loss 20.7233\n",
      "epoch 89, run 30, loss 21.1838\n",
      "epoch 90, run 0, loss 20.7233\n",
      "epoch 90, run 30, loss 20.7233\n",
      "epoch 91, run 0, loss 22.1048\n",
      "epoch 91, run 30, loss 19.8022\n",
      "epoch 92, run 0, loss 21.1838\n",
      "epoch 92, run 30, loss 21.1838\n",
      "epoch 93, run 0, loss 20.7233\n",
      "epoch 93, run 30, loss 22.5653\n",
      "epoch 94, run 0, loss 20.2627\n",
      "epoch 94, run 30, loss 22.1048\n",
      "epoch 95, run 0, loss 21.1838\n",
      "epoch 95, run 30, loss 20.7233\n",
      "epoch 96, run 0, loss 22.1048\n",
      "epoch 96, run 30, loss 20.2627\n",
      "epoch 97, run 0, loss 22.1048\n",
      "epoch 97, run 30, loss 21.1838\n",
      "epoch 98, run 0, loss 19.8022\n",
      "epoch 98, run 30, loss 21.1838\n",
      "epoch 99, run 0, loss 20.2627\n",
      "epoch 99, run 30, loss 20.7233\n",
      "epoch 100, run 0, loss 20.7233\n",
      "epoch 100, run 30, loss 19.8022\n",
      "Validation acc: 13.2%\n",
      "epoch 101, run 0, loss 21.6443\n",
      "epoch 101, run 30, loss 20.2627\n",
      "epoch 102, run 0, loss 19.8022\n",
      "epoch 102, run 30, loss 20.2627\n",
      "epoch 103, run 0, loss 19.8022\n",
      "epoch 103, run 30, loss 20.7233\n",
      "epoch 104, run 0, loss 20.2627\n",
      "epoch 104, run 30, loss 21.6443\n",
      "epoch 105, run 0, loss 20.7233\n",
      "epoch 105, run 30, loss 22.1048\n",
      "epoch 106, run 0, loss 20.7233\n",
      "epoch 106, run 30, loss 21.6443\n",
      "epoch 107, run 0, loss 22.1048\n",
      "epoch 107, run 30, loss 21.1838\n",
      "epoch 108, run 0, loss 22.5653\n",
      "epoch 108, run 30, loss 22.1048\n",
      "epoch 109, run 0, loss 21.1838\n",
      "epoch 109, run 30, loss 22.5653\n",
      "epoch 110, run 0, loss 21.6443\n",
      "epoch 110, run 30, loss 22.5653\n",
      "epoch 111, run 0, loss 22.5653\n",
      "epoch 111, run 30, loss 21.1838\n",
      "epoch 112, run 0, loss 22.1048\n",
      "epoch 112, run 30, loss 21.1838\n",
      "epoch 113, run 0, loss 21.6443\n",
      "epoch 113, run 30, loss 21.6443\n",
      "epoch 114, run 0, loss 20.7233\n",
      "epoch 114, run 30, loss 21.1838\n",
      "epoch 115, run 0, loss 21.6443\n",
      "epoch 115, run 30, loss 21.1838\n",
      "epoch 116, run 0, loss 21.6443\n",
      "epoch 116, run 30, loss 21.6443\n",
      "epoch 117, run 0, loss 21.6443\n",
      "epoch 117, run 30, loss 22.5653\n",
      "epoch 118, run 0, loss 21.1838\n",
      "epoch 118, run 30, loss 23.0259\n",
      "epoch 119, run 0, loss 22.1048\n",
      "epoch 119, run 30, loss 22.1048\n",
      "epoch 120, run 0, loss 23.0259\n",
      "epoch 120, run 30, loss 21.6443\n",
      "epoch 121, run 0, loss 22.5653\n",
      "epoch 121, run 30, loss 22.1048\n",
      "epoch 122, run 0, loss 22.1048\n",
      "epoch 122, run 30, loss 23.0259\n",
      "epoch 123, run 0, loss 21.6443\n",
      "epoch 123, run 30, loss 22.5653\n",
      "epoch 124, run 0, loss 22.5653\n",
      "epoch 124, run 30, loss 22.5653\n",
      "epoch 125, run 0, loss 23.0259\n",
      "epoch 125, run 30, loss 22.5653\n",
      "epoch 126, run 0, loss 22.5653\n",
      "epoch 126, run 30, loss 22.1048\n",
      "epoch 127, run 0, loss 22.5653\n",
      "epoch 127, run 30, loss 22.5653\n",
      "epoch 128, run 0, loss 22.5653\n",
      "epoch 128, run 30, loss 23.0259\n",
      "epoch 129, run 0, loss 22.5653\n",
      "epoch 129, run 30, loss 23.0259\n",
      "epoch 130, run 0, loss 22.5653\n",
      "epoch 130, run 30, loss 23.0259\n",
      "epoch 131, run 0, loss 23.0259\n",
      "epoch 131, run 30, loss 22.5653\n",
      "epoch 132, run 0, loss 23.0259\n",
      "epoch 132, run 30, loss 22.1048\n",
      "epoch 133, run 0, loss 23.0259\n",
      "epoch 133, run 30, loss 22.1048\n",
      "epoch 134, run 0, loss 22.5653\n",
      "epoch 134, run 30, loss 21.6443\n",
      "epoch 135, run 0, loss 22.5653\n",
      "epoch 135, run 30, loss 20.2627\n",
      "epoch 136, run 0, loss 21.6443\n",
      "epoch 136, run 30, loss 21.1838\n",
      "epoch 137, run 0, loss 21.6443\n",
      "epoch 137, run 30, loss 21.1838\n",
      "epoch 138, run 0, loss 20.2627\n",
      "epoch 138, run 30, loss 19.3417\n",
      "epoch 139, run 0, loss 21.6443\n",
      "epoch 139, run 30, loss 21.1838\n",
      "epoch 140, run 0, loss 20.2627\n",
      "epoch 140, run 30, loss 22.5653\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 141, run 0, loss 19.8022\n",
      "epoch 141, run 30, loss 20.7233\n",
      "epoch 142, run 0, loss 21.1838\n",
      "epoch 142, run 30, loss 22.1048\n",
      "epoch 143, run 0, loss 21.1838\n",
      "epoch 143, run 30, loss 21.6443\n",
      "epoch 144, run 0, loss 20.7233\n",
      "epoch 144, run 30, loss 20.7233\n",
      "epoch 145, run 0, loss 22.1048\n",
      "epoch 145, run 30, loss 20.7233\n",
      "epoch 146, run 0, loss 21.1838\n",
      "epoch 146, run 30, loss 20.7233\n",
      "epoch 147, run 0, loss 20.2627\n",
      "epoch 147, run 30, loss 21.6443\n",
      "epoch 148, run 0, loss 20.2627\n",
      "epoch 148, run 30, loss 22.1048\n",
      "epoch 149, run 0, loss 21.1838\n",
      "epoch 149, run 30, loss 21.1838\n",
      "epoch 150, run 0, loss 22.1048\n",
      "epoch 150, run 30, loss 20.2627\n",
      "epoch 151, run 0, loss 21.6443\n",
      "epoch 151, run 30, loss 20.2627\n",
      "epoch 152, run 0, loss 21.1838\n",
      "epoch 152, run 30, loss 20.7233\n",
      "epoch 153, run 0, loss 20.2627\n",
      "epoch 153, run 30, loss 21.6443\n",
      "epoch 154, run 0, loss 20.7233\n",
      "epoch 154, run 30, loss 19.8022\n",
      "epoch 155, run 0, loss 21.1838\n",
      "epoch 155, run 30, loss 19.3417\n",
      "epoch 156, run 0, loss 21.6443\n",
      "epoch 156, run 30, loss 20.7233\n",
      "epoch 157, run 0, loss 19.8022\n",
      "epoch 157, run 30, loss 20.2627\n",
      "epoch 158, run 0, loss 20.7233\n",
      "epoch 158, run 30, loss 20.2627\n",
      "epoch 159, run 0, loss 20.7233\n",
      "epoch 159, run 30, loss 22.1048\n",
      "epoch 160, run 0, loss 21.1838\n",
      "epoch 160, run 30, loss 22.1048\n",
      "epoch 161, run 0, loss 21.1838\n",
      "epoch 161, run 30, loss 21.1838\n",
      "epoch 162, run 0, loss 22.1048\n",
      "epoch 162, run 30, loss 22.1048\n",
      "epoch 163, run 0, loss 21.6443\n",
      "epoch 163, run 30, loss 22.5653\n",
      "epoch 164, run 0, loss 21.1838\n",
      "epoch 164, run 30, loss 22.1048\n",
      "epoch 165, run 0, loss 22.1048\n",
      "epoch 165, run 30, loss 21.1838\n",
      "epoch 166, run 0, loss 22.5653\n",
      "epoch 166, run 30, loss 20.7233\n",
      "epoch 167, run 0, loss 22.5653\n",
      "epoch 167, run 30, loss 21.6443\n",
      "epoch 168, run 0, loss 21.1838\n",
      "epoch 168, run 30, loss 22.1048\n",
      "epoch 169, run 0, loss 20.7233\n",
      "epoch 169, run 30, loss 21.6443\n",
      "epoch 170, run 0, loss 21.6443\n",
      "epoch 170, run 30, loss 21.1838\n",
      "epoch 171, run 0, loss 21.6443\n",
      "epoch 171, run 30, loss 22.1048\n",
      "epoch 172, run 0, loss 21.6443\n",
      "epoch 172, run 30, loss 23.0259\n",
      "epoch 173, run 0, loss 21.6443\n",
      "epoch 173, run 30, loss 22.5653\n",
      "epoch 174, run 0, loss 22.5653\n",
      "epoch 174, run 30, loss 21.6443\n",
      "epoch 175, run 0, loss 23.0259\n",
      "epoch 175, run 30, loss 21.6443\n",
      "epoch 176, run 0, loss 22.5653\n",
      "epoch 176, run 30, loss 23.0259\n",
      "epoch 177, run 0, loss 21.1838\n",
      "epoch 177, run 30, loss 23.0259\n",
      "epoch 178, run 0, loss 22.1048\n",
      "epoch 178, run 30, loss 22.5653\n",
      "epoch 179, run 0, loss 23.0259\n",
      "epoch 179, run 30, loss 22.5653\n",
      "epoch 180, run 0, loss 22.5653\n",
      "epoch 180, run 30, loss 22.5653\n",
      "epoch 181, run 0, loss 22.5653\n",
      "epoch 181, run 30, loss 22.5653\n",
      "epoch 182, run 0, loss 22.5653\n",
      "epoch 182, run 30, loss 22.5653\n",
      "epoch 183, run 0, loss 22.5653\n",
      "epoch 183, run 30, loss 23.0259\n",
      "epoch 184, run 0, loss 22.5653\n",
      "epoch 184, run 30, loss 23.0259\n",
      "epoch 185, run 0, loss 23.0259\n",
      "epoch 185, run 30, loss 22.5653\n",
      "epoch 186, run 0, loss 23.0259\n",
      "epoch 186, run 30, loss 22.5653\n",
      "epoch 187, run 0, loss 23.0259\n",
      "epoch 187, run 30, loss 22.1048\n",
      "epoch 188, run 0, loss 22.5653\n",
      "epoch 188, run 30, loss 21.6443\n",
      "epoch 189, run 0, loss 22.5653\n",
      "epoch 189, run 30, loss 21.1838\n",
      "epoch 190, run 0, loss 22.1048\n",
      "epoch 190, run 30, loss 20.7233\n",
      "epoch 191, run 0, loss 21.6443\n",
      "epoch 191, run 30, loss 21.1838\n",
      "epoch 192, run 0, loss 21.1838\n",
      "epoch 192, run 30, loss 20.2627\n",
      "epoch 193, run 0, loss 20.7233\n",
      "epoch 193, run 30, loss 20.2627\n",
      "epoch 194, run 0, loss 21.6443\n",
      "epoch 194, run 30, loss 21.6443\n",
      "epoch 195, run 0, loss 19.8022\n",
      "epoch 195, run 30, loss 21.1838\n",
      "epoch 196, run 0, loss 20.7233\n",
      "epoch 196, run 30, loss 20.7233\n",
      "epoch 197, run 0, loss 22.5653\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-166-5c3cbb785110>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;31m# need to incoporate y in the batches and expand to 8 classes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_doc_embed_with_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0my_\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mj\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m30\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/harrygong/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    787\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 789\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    790\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/harrygong/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    995\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 997\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    998\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    999\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/harrygong/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1130\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1132\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1133\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/home/harrygong/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1137\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1139\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1140\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/harrygong/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1119\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1120\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1121\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(epoch):\n",
    "    xloss = 0\n",
    "    acc = 0.0\n",
    "    \n",
    "    for j in range(total_batch):\n",
    "        # need to incoporate y in the batches and expand to 8 classes \n",
    "        index, x_, y_ = next_batch(train_doc_embed_with_class, index, batch_size)\n",
    "        _, xloss = sess.run([optimizer, loss], feed_dict={x: x_, y: y_})\n",
    "        \n",
    "        if j % 30 == 0:\n",
    "            print(\"epoch %d, run %d, loss %g\" % (i, j, xloss))\n",
    "            \n",
    "    if i % 100 == 0:\n",
    "        acc = sess.run(accuracy, feed_dict={x:valid_doc_embed_with_class[0], y:valid_doc_embed_with_class[1]})\n",
    "        print(\"Validation acc: %g\" % (acc * 100), end=\"\")\n",
    "        print(\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions to answer "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Compare the learning curves of the model starting from random embeddings, starting from GloVe embeddings (http://nlp.stanford.edu/data/glove.6B.zip; 50 dimensions) or fixed to be the GloVe values. Training in batches is more stable (e.g. 50), which model works best on training vs. test? Which model works best on held-out accuracy?\n",
    "- What happens if you try alternative non-linearities (logistic sigmoid or ReLU instead of tanh)?\n",
    "- What happens if you add dropout to the network?\n",
    "- What happens if you vary the size of the hidden layer?\n",
    "- How would the code change if you wanted to add a second hidden layer?\n",
    "- How does the training algorithm affect the quality of the model?\n",
    "- Project the embeddings of the labels onto 2 dimensions and visualise (each row of the projection matrix V corresponds a label embedding). Do you see anything interesting?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 10000\n",
    "\n",
    "W = tf.Variable(tf.truncated_normal(shape=[100, 256]))\n",
    "b = tf.Variable(tf.constant(0.0, shape=[256]))\n",
    "\n",
    "W2 = tf.Variable(tf.truncated_normal(shape=[256, 128]))\n",
    "b2 = tf.Variable(tf.constant(0.0, shape=[128]))\n",
    "\n",
    "V = tf.Variable(tf.truncated_normal(shape=[128, 8]))\n",
    "c = tf.Variable(tf.constant(0.0, shape=[8]))\n",
    "\n",
    "dropout_rate = tf.placeholder(tf.float32)\n",
    "\n",
    "h = tf.nn.relu(tf.matmul(x, W) + b)\n",
    "h2 = tf.nn.relu(tf.matmul(h, W2) + b2)\n",
    "h2_drop = tf.nn.dropout(h2, keep_prob=dropout_rate)\n",
    "u = tf.matmul(h2_drop, V) + c\n",
    "p = tf.nn.softmax(u)\n",
    "pred = tf.argmax(p, 1)\n",
    "loss = tf.reduce_mean(tf.reduce_sum(-tf.cast(y, tf.float32)*tf.log(tf.clip_by_value(p, 1e-10, 1.0)), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, run 0, loss 22.1048\n",
      "epoch 0, run 30, loss 20.7243\n",
      "epoch 0, Validation acc: 34.4%\n",
      "epoch 1, run 0, loss 21.1838\n",
      "epoch 1, run 30, loss 22.1048\n",
      "epoch 2, run 0, loss 22.414\n",
      "epoch 2, run 30, loss 22.1119\n",
      "epoch 3, run 0, loss 21.1843\n",
      "epoch 3, run 30, loss 21.6443\n",
      "epoch 4, run 0, loss 21.6443\n",
      "epoch 4, run 30, loss 21.1838\n",
      "epoch 5, run 0, loss 21.6443\n",
      "epoch 5, run 30, loss 21.3803\n",
      "epoch 6, run 0, loss 21.9246\n",
      "epoch 6, run 30, loss 21.4713\n",
      "epoch 7, run 0, loss 21.6443\n",
      "epoch 7, run 30, loss 21.6443\n",
      "epoch 8, run 0, loss 21.6443\n",
      "epoch 8, run 30, loss 21.6987\n",
      "epoch 9, run 0, loss 21.1838\n",
      "epoch 9, run 30, loss 20.7233\n",
      "epoch 10, run 0, loss 22.5653\n",
      "epoch 10, run 30, loss 21.0082\n",
      "epoch 11, run 0, loss 22.1048\n",
      "epoch 11, run 30, loss 20.7233\n",
      "epoch 12, run 0, loss 21.1838\n",
      "epoch 12, run 30, loss 20.6662\n",
      "epoch 13, run 0, loss 20.7233\n",
      "epoch 13, run 30, loss 21.5665\n",
      "epoch 14, run 0, loss 22.5653\n",
      "epoch 14, run 30, loss 21.1838\n",
      "epoch 15, run 0, loss 21.9418\n",
      "epoch 15, run 30, loss 21.3755\n",
      "epoch 16, run 0, loss 21.9373\n",
      "epoch 16, run 30, loss 21.1873\n",
      "epoch 17, run 0, loss 22.0823\n",
      "epoch 17, run 30, loss 22.1049\n",
      "epoch 18, run 0, loss 21.776\n",
      "epoch 18, run 30, loss 20.749\n",
      "epoch 19, run 0, loss 20.1864\n",
      "epoch 19, run 30, loss 20.7233\n",
      "epoch 20, run 0, loss 21.1838\n",
      "epoch 20, run 30, loss 21.0604\n",
      "epoch 21, run 0, loss 21.6443\n",
      "epoch 21, run 30, loss 22.5653\n",
      "epoch 22, run 0, loss 20.689\n",
      "epoch 22, run 30, loss 20.7233\n",
      "epoch 23, run 0, loss 21.6443\n",
      "epoch 23, run 30, loss 22.1048\n",
      "epoch 24, run 0, loss 23.0259\n",
      "epoch 24, run 30, loss 21.2632\n",
      "epoch 25, run 0, loss 22.5653\n",
      "epoch 25, run 30, loss 22.5653\n",
      "epoch 26, run 0, loss 22.5653\n",
      "epoch 26, run 30, loss 21.6443\n",
      "epoch 27, run 0, loss 21.1838\n",
      "epoch 27, run 30, loss 21.6443\n",
      "epoch 28, run 0, loss 21.6443\n",
      "epoch 28, run 30, loss 21.1549\n",
      "epoch 29, run 0, loss 22.5653\n",
      "epoch 29, run 30, loss 22.1124\n",
      "epoch 30, run 0, loss 21.6443\n",
      "epoch 30, run 30, loss 22.5653\n",
      "epoch 31, run 0, loss 21.6443\n",
      "epoch 31, run 30, loss 21.6443\n",
      "epoch 32, run 0, loss 22.5653\n",
      "epoch 32, run 30, loss 21.7127\n",
      "epoch 33, run 0, loss 21.1838\n",
      "epoch 33, run 30, loss 18.8812\n",
      "epoch 34, run 0, loss 22.1048\n",
      "epoch 34, run 30, loss 22.1048\n",
      "epoch 35, run 0, loss 22.2969\n",
      "epoch 35, run 30, loss 22.5653\n",
      "epoch 36, run 0, loss 21.329\n",
      "epoch 36, run 30, loss 21.357\n",
      "epoch 37, run 0, loss 20.7564\n",
      "epoch 37, run 30, loss 22.4945\n",
      "epoch 38, run 0, loss 20.7293\n",
      "epoch 38, run 30, loss 22.378\n",
      "epoch 39, run 0, loss 22.336\n",
      "epoch 39, run 30, loss 21.6443\n",
      "epoch 40, run 0, loss 22.5653\n",
      "epoch 40, run 30, loss 22.1898\n",
      "epoch 41, run 0, loss 21.6443\n",
      "epoch 41, run 30, loss 21.6443\n",
      "epoch 42, run 0, loss 22.5653\n",
      "epoch 42, run 30, loss 21.6445\n",
      "epoch 43, run 0, loss 22.1058\n",
      "epoch 43, run 30, loss 23.0259\n",
      "epoch 44, run 0, loss 22.1048\n",
      "epoch 44, run 30, loss 22.5653\n",
      "epoch 45, run 0, loss 22.5653\n",
      "epoch 45, run 30, loss 21.1758\n",
      "epoch 46, run 0, loss 22.2934\n",
      "epoch 46, run 30, loss 20.7458\n",
      "epoch 47, run 0, loss 23.0259\n",
      "epoch 47, run 30, loss 21.1996\n",
      "epoch 48, run 0, loss 23.0259\n",
      "epoch 48, run 30, loss 22.4879\n",
      "epoch 49, run 0, loss 21.1838\n",
      "epoch 49, run 30, loss 21.6443\n",
      "epoch 50, run 0, loss 21.9986\n",
      "epoch 50, run 30, loss 21.6443\n",
      "epoch 51, run 0, loss 20.7233\n",
      "epoch 51, run 30, loss 20.7233\n",
      "epoch 52, run 0, loss 22.1048\n",
      "epoch 52, run 30, loss 20.2637\n",
      "epoch 53, run 0, loss 22.5653\n",
      "epoch 53, run 30, loss 22.0769\n",
      "epoch 54, run 0, loss 21.7949\n",
      "epoch 54, run 30, loss 21.0084\n",
      "epoch 55, run 0, loss 22.1048\n",
      "epoch 55, run 30, loss 22.7639\n",
      "epoch 56, run 0, loss 22.1048\n",
      "epoch 56, run 30, loss 21.1838\n",
      "epoch 57, run 0, loss 21.1838\n",
      "epoch 57, run 30, loss 20.7233\n",
      "epoch 58, run 0, loss 22.1048\n",
      "epoch 58, run 30, loss 23.0259\n",
      "epoch 59, run 0, loss 21.6595\n",
      "epoch 59, run 30, loss 21.1838\n",
      "epoch 60, run 0, loss 23.0259\n",
      "epoch 60, run 30, loss 21.1838\n",
      "epoch 61, run 0, loss 22.1048\n",
      "epoch 61, run 30, loss 22.1049\n",
      "epoch 62, run 0, loss 22.1048\n",
      "epoch 62, run 30, loss 22.0712\n",
      "epoch 63, run 0, loss 22.5653\n",
      "epoch 63, run 30, loss 21.6443\n",
      "epoch 64, run 0, loss 21.6443\n",
      "epoch 64, run 30, loss 21.9429\n",
      "epoch 65, run 0, loss 22.1048\n",
      "epoch 65, run 30, loss 21.4511\n",
      "epoch 66, run 0, loss 20.7233\n",
      "epoch 66, run 30, loss 21.1838\n",
      "epoch 67, run 0, loss 22.1048\n",
      "epoch 67, run 30, loss 22.1048\n",
      "epoch 68, run 0, loss 19.9417\n",
      "epoch 68, run 30, loss 22.0791\n",
      "epoch 69, run 0, loss 21.6443\n",
      "epoch 69, run 30, loss 21.4877\n",
      "epoch 70, run 0, loss 21.2466\n",
      "epoch 70, run 30, loss 20.7233\n",
      "epoch 71, run 0, loss 22.1048\n",
      "epoch 71, run 30, loss 21.6444\n",
      "epoch 72, run 0, loss 19.3417\n",
      "epoch 72, run 30, loss 21.6443\n",
      "epoch 73, run 0, loss 21.6443\n",
      "epoch 73, run 30, loss 22.5653\n",
      "epoch 74, run 0, loss 21.3689\n",
      "epoch 74, run 30, loss 21.1838\n",
      "epoch 75, run 0, loss 22.0952\n",
      "epoch 75, run 30, loss 22.5653\n",
      "epoch 76, run 0, loss 22.4017\n",
      "epoch 76, run 30, loss 21.1838\n",
      "epoch 77, run 0, loss 21.1838\n",
      "epoch 77, run 30, loss 22.1048\n",
      "epoch 78, run 0, loss 20.7977\n",
      "epoch 78, run 30, loss 22.1211\n",
      "epoch 79, run 0, loss 22.1048\n",
      "epoch 79, run 30, loss 21.6443\n",
      "epoch 80, run 0, loss 22.1048\n",
      "epoch 80, run 30, loss 21.6744\n",
      "epoch 81, run 0, loss 22.1054\n",
      "epoch 81, run 30, loss 22.1048\n",
      "epoch 82, run 0, loss 23.0259\n",
      "epoch 82, run 30, loss 21.6443\n",
      "epoch 83, run 0, loss 21.2162\n",
      "epoch 83, run 30, loss 21.284\n",
      "epoch 84, run 0, loss 23.0259\n",
      "epoch 84, run 30, loss 22.1396\n",
      "epoch 85, run 0, loss 21.1838\n",
      "epoch 85, run 30, loss 21.241\n",
      "epoch 86, run 0, loss 22.5653\n",
      "epoch 86, run 30, loss 19.8022\n",
      "epoch 87, run 0, loss 22.1109\n",
      "epoch 87, run 30, loss 22.7257\n",
      "epoch 88, run 0, loss 21.1838\n",
      "epoch 88, run 30, loss 21.1972\n",
      "epoch 89, run 0, loss 21.6443\n",
      "epoch 89, run 30, loss 21.7272\n",
      "epoch 90, run 0, loss 20.8694\n",
      "epoch 90, run 30, loss 21.6443\n",
      "epoch 91, run 0, loss 22.1048\n",
      "epoch 91, run 30, loss 22.1562\n",
      "epoch 92, run 0, loss 22.5653\n",
      "epoch 92, run 30, loss 21.6443\n",
      "epoch 93, run 0, loss 21.7547\n",
      "epoch 93, run 30, loss 22.1048\n",
      "epoch 94, run 0, loss 22.5653\n",
      "epoch 94, run 30, loss 22.1048\n",
      "epoch 95, run 0, loss 20.3418\n",
      "epoch 95, run 30, loss 22.1048\n",
      "epoch 96, run 0, loss 22.5653\n",
      "epoch 96, run 30, loss 23.0259\n",
      "epoch 97, run 0, loss 22.5653\n",
      "epoch 97, run 30, loss 22.5653\n",
      "epoch 98, run 0, loss 21.1838\n",
      "epoch 98, run 30, loss 22.2843\n",
      "epoch 99, run 0, loss 21.1838\n",
      "epoch 99, run 30, loss 22.5653\n",
      "epoch 100, run 0, loss 22.2704\n",
      "epoch 100, run 30, loss 22.0739\n",
      "epoch 100, Validation acc: 34.4%\n",
      "epoch 101, run 0, loss 22.5653\n",
      "epoch 101, run 30, loss 21.1838\n",
      "epoch 102, run 0, loss 21.1838\n",
      "epoch 102, run 30, loss 21.6443\n",
      "epoch 103, run 0, loss 22.1099\n",
      "epoch 103, run 30, loss 21.6443\n",
      "epoch 104, run 0, loss 21.1838\n",
      "epoch 104, run 30, loss 22.5658\n",
      "epoch 105, run 0, loss 22.1048\n",
      "epoch 105, run 30, loss 21.6443\n",
      "epoch 106, run 0, loss 21.9379\n",
      "epoch 106, run 30, loss 22.5653\n",
      "epoch 107, run 0, loss 21.1838\n",
      "epoch 107, run 30, loss 22.7813\n",
      "epoch 108, run 0, loss 22.1048\n",
      "epoch 108, run 30, loss 22.5653\n",
      "epoch 109, run 0, loss 22.5653\n",
      "epoch 109, run 30, loss 22.1102\n",
      "epoch 110, run 0, loss 22.5653\n",
      "epoch 110, run 30, loss 22.1048\n",
      "epoch 111, run 0, loss 22.5653\n",
      "epoch 111, run 30, loss 20.5357\n",
      "epoch 112, run 0, loss 22.1048\n",
      "epoch 112, run 30, loss 21.2109\n",
      "epoch 113, run 0, loss 23.0259\n",
      "epoch 113, run 30, loss 21.1983\n",
      "epoch 114, run 0, loss 21.2917\n",
      "epoch 114, run 30, loss 21.6443\n",
      "epoch 115, run 0, loss 22.8656\n",
      "epoch 115, run 30, loss 22.2627\n",
      "epoch 116, run 0, loss 21.1838\n",
      "epoch 116, run 30, loss 21.1838\n",
      "epoch 117, run 0, loss 20.7233\n",
      "epoch 117, run 30, loss 22.1048\n",
      "epoch 118, run 0, loss 21.6443\n",
      "epoch 118, run 30, loss 21.1406\n",
      "epoch 119, run 0, loss 21.3136\n",
      "epoch 119, run 30, loss 20.5038\n",
      "epoch 120, run 0, loss 21.6443\n",
      "epoch 120, run 30, loss 20.7233\n",
      "epoch 121, run 0, loss 21.1838\n",
      "epoch 121, run 30, loss 20.7233\n",
      "epoch 122, run 0, loss 21.5418\n",
      "epoch 122, run 30, loss 22.5653\n",
      "epoch 123, run 0, loss 21.6443\n",
      "epoch 123, run 30, loss 22.7895\n",
      "epoch 124, run 0, loss 21.1838\n",
      "epoch 124, run 30, loss 22.1048\n",
      "epoch 125, run 0, loss 21.4461\n",
      "epoch 125, run 30, loss 22.1048\n",
      "epoch 126, run 0, loss 22.5645\n",
      "epoch 126, run 30, loss 22.5653\n",
      "epoch 127, run 0, loss 22.1048\n",
      "epoch 127, run 30, loss 21.0075\n",
      "epoch 128, run 0, loss 21.6443\n",
      "epoch 128, run 30, loss 22.1048\n",
      "epoch 129, run 0, loss 20.4592\n",
      "epoch 129, run 30, loss 22.5856\n",
      "epoch 130, run 0, loss 22.0284\n",
      "epoch 130, run 30, loss 22.1975\n",
      "epoch 131, run 0, loss 22.5655\n",
      "epoch 131, run 30, loss 21.1838\n",
      "epoch 132, run 0, loss 21.3873\n",
      "epoch 132, run 30, loss 22.1048\n",
      "epoch 133, run 0, loss 21.8325\n",
      "epoch 133, run 30, loss 21.5552\n",
      "epoch 134, run 0, loss 22.1048\n",
      "epoch 134, run 30, loss 22.1048\n",
      "epoch 135, run 0, loss 21.9218\n",
      "epoch 135, run 30, loss 20.7233\n",
      "epoch 136, run 0, loss 21.6443\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 136, run 30, loss 22.4468\n",
      "epoch 137, run 0, loss 20.7233\n",
      "epoch 137, run 30, loss 22.1048\n",
      "epoch 138, run 0, loss 22.5653\n",
      "epoch 138, run 30, loss 22.5653\n",
      "epoch 139, run 0, loss 20.7233\n",
      "epoch 139, run 30, loss 23.0259\n",
      "epoch 140, run 0, loss 21.6443\n",
      "epoch 140, run 30, loss 21.6443\n",
      "epoch 141, run 0, loss 23.0259\n",
      "epoch 141, run 30, loss 20.7233\n",
      "epoch 142, run 0, loss 19.5667\n",
      "epoch 142, run 30, loss 22.1048\n",
      "epoch 143, run 0, loss 23.0259\n",
      "epoch 143, run 30, loss 21.1838\n",
      "epoch 144, run 0, loss 21.6443\n",
      "epoch 144, run 30, loss 20.7233\n",
      "epoch 145, run 0, loss 20.7263\n",
      "epoch 145, run 30, loss 20.9639\n",
      "epoch 146, run 0, loss 21.1838\n",
      "epoch 146, run 30, loss 21.3572\n",
      "epoch 147, run 0, loss 21.352\n",
      "epoch 147, run 30, loss 22.5653\n",
      "epoch 148, run 0, loss 21.9001\n",
      "epoch 148, run 30, loss 22.5653\n",
      "epoch 149, run 0, loss 21.1908\n",
      "epoch 149, run 30, loss 20.7233\n",
      "epoch 150, run 0, loss 22.1048\n",
      "epoch 150, run 30, loss 21.1838\n",
      "epoch 151, run 0, loss 22.5653\n",
      "epoch 151, run 30, loss 22.1048\n",
      "epoch 152, run 0, loss 21.1838\n",
      "epoch 152, run 30, loss 21.6443\n",
      "epoch 153, run 0, loss 22.5653\n",
      "epoch 153, run 30, loss 22.1048\n",
      "epoch 154, run 0, loss 22.5653\n",
      "epoch 154, run 30, loss 21.6443\n",
      "epoch 155, run 0, loss 21.6443\n",
      "epoch 155, run 30, loss 22.1048\n",
      "epoch 156, run 0, loss 23.0259\n",
      "epoch 156, run 30, loss 22.1394\n",
      "epoch 157, run 0, loss 21.3889\n",
      "epoch 157, run 30, loss 22.5653\n",
      "epoch 158, run 0, loss 21.6443\n",
      "epoch 158, run 30, loss 20.9911\n",
      "epoch 159, run 0, loss 21.4904\n",
      "epoch 159, run 30, loss 22.1048\n",
      "epoch 160, run 0, loss 22.1048\n",
      "epoch 160, run 30, loss 21.6443\n",
      "epoch 161, run 0, loss 21.651\n",
      "epoch 161, run 30, loss 21.396\n",
      "epoch 162, run 0, loss 21.5723\n",
      "epoch 162, run 30, loss 22.5653\n",
      "epoch 163, run 0, loss 22.1203\n",
      "epoch 163, run 30, loss 21.6159\n",
      "epoch 164, run 0, loss 21.6443\n",
      "epoch 164, run 30, loss 22.1048\n",
      "epoch 165, run 0, loss 20.5829\n",
      "epoch 165, run 30, loss 22.1048\n",
      "epoch 166, run 0, loss 22.1129\n",
      "epoch 166, run 30, loss 22.5653\n",
      "epoch 167, run 0, loss 22.1048\n",
      "epoch 167, run 30, loss 22.1048\n",
      "epoch 168, run 0, loss 22.1049\n",
      "epoch 168, run 30, loss 21.1838\n",
      "epoch 169, run 0, loss 21.8524\n",
      "epoch 169, run 30, loss 22.9697\n",
      "epoch 170, run 0, loss 21.6443\n",
      "epoch 170, run 30, loss 21.2782\n",
      "epoch 171, run 0, loss 21.6443\n",
      "epoch 171, run 30, loss 21.3577\n",
      "epoch 172, run 0, loss 21.1838\n",
      "epoch 172, run 30, loss 22.5653\n",
      "epoch 173, run 0, loss 21.6443\n",
      "epoch 173, run 30, loss 22.1048\n",
      "epoch 174, run 0, loss 21.6443\n",
      "epoch 174, run 30, loss 20.932\n",
      "epoch 175, run 0, loss 21.6997\n",
      "epoch 175, run 30, loss 22.1048\n",
      "epoch 176, run 0, loss 21.1838\n",
      "epoch 176, run 30, loss 22.1048\n",
      "epoch 177, run 0, loss 21.2248\n",
      "epoch 177, run 30, loss 21.407\n",
      "epoch 178, run 0, loss 21.1838\n",
      "epoch 178, run 30, loss 22.1583\n",
      "epoch 179, run 0, loss 20.7387\n",
      "epoch 179, run 30, loss 22.5658\n",
      "epoch 180, run 0, loss 21.1838\n",
      "epoch 180, run 30, loss 22.1048\n",
      "epoch 181, run 0, loss 21.6443\n",
      "epoch 181, run 30, loss 21.4114\n",
      "epoch 182, run 0, loss 21.2274\n",
      "epoch 182, run 30, loss 21.1838\n",
      "epoch 183, run 0, loss 22.1048\n",
      "epoch 183, run 30, loss 21.6443\n",
      "epoch 184, run 0, loss 22.1048\n",
      "epoch 184, run 30, loss 21.2763\n",
      "epoch 185, run 0, loss 20.2627\n",
      "epoch 185, run 30, loss 22.1048\n",
      "epoch 186, run 0, loss 21.6443\n",
      "epoch 186, run 30, loss 21.9821\n",
      "epoch 187, run 0, loss 23.0259\n",
      "epoch 187, run 30, loss 21.6443\n",
      "epoch 188, run 0, loss 20.5751\n",
      "epoch 188, run 30, loss 21.6443\n",
      "epoch 189, run 0, loss 21.6443\n",
      "epoch 189, run 30, loss 22.5653\n",
      "epoch 190, run 0, loss 21.1838\n",
      "epoch 190, run 30, loss 22.7532\n",
      "epoch 191, run 0, loss 21.7164\n",
      "epoch 191, run 30, loss 20.7233\n",
      "epoch 192, run 0, loss 21.6443\n",
      "epoch 192, run 30, loss 21.6455\n",
      "epoch 193, run 0, loss 22.5653\n",
      "epoch 193, run 30, loss 21.6443\n",
      "epoch 194, run 0, loss 22.1048\n",
      "epoch 194, run 30, loss 21.6443\n",
      "epoch 195, run 0, loss 21.014\n",
      "epoch 195, run 30, loss 22.0596\n",
      "epoch 196, run 0, loss 22.5653\n",
      "epoch 196, run 30, loss 20.7233\n",
      "epoch 197, run 0, loss 20.7233\n",
      "epoch 197, run 30, loss 21.0108\n",
      "epoch 198, run 0, loss 20.7233\n",
      "epoch 198, run 30, loss 21.6443\n",
      "epoch 199, run 0, loss 21.6443\n",
      "epoch 199, run 30, loss 22.1048\n",
      "epoch 200, run 0, loss 19.8022\n",
      "epoch 200, run 30, loss 22.3015\n",
      "epoch 200, Validation acc: 34.4%\n",
      "epoch 201, run 0, loss 21.6443\n",
      "epoch 201, run 30, loss 22.8069\n",
      "epoch 202, run 0, loss 21.6443\n",
      "epoch 202, run 30, loss 21.4188\n",
      "epoch 203, run 0, loss 22.1048\n",
      "epoch 203, run 30, loss 22.5653\n",
      "epoch 204, run 0, loss 21.6443\n",
      "epoch 204, run 30, loss 20.7233\n",
      "epoch 205, run 0, loss 23.0259\n",
      "epoch 205, run 30, loss 21.1263\n",
      "epoch 206, run 0, loss 21.2486\n",
      "epoch 206, run 30, loss 20.7233\n",
      "epoch 207, run 0, loss 20.7233\n",
      "epoch 207, run 30, loss 22.7011\n",
      "epoch 208, run 0, loss 21.9239\n",
      "epoch 208, run 30, loss 20.1155\n",
      "epoch 209, run 0, loss 22.2407\n",
      "epoch 209, run 30, loss 22.4213\n",
      "epoch 210, run 0, loss 22.1048\n",
      "epoch 210, run 30, loss 22.1048\n",
      "epoch 211, run 0, loss 22.9151\n",
      "epoch 211, run 30, loss 21.0549\n",
      "epoch 212, run 0, loss 20.7233\n",
      "epoch 212, run 30, loss 21.9631\n",
      "epoch 213, run 0, loss 22.1055\n",
      "epoch 213, run 30, loss 22.1048\n",
      "epoch 214, run 0, loss 18.8812\n",
      "epoch 214, run 30, loss 21.1838\n",
      "epoch 215, run 0, loss 21.2034\n",
      "epoch 215, run 30, loss 22.1048\n",
      "epoch 216, run 0, loss 22.5653\n",
      "epoch 216, run 30, loss 22.1048\n",
      "epoch 217, run 0, loss 22.1048\n",
      "epoch 217, run 30, loss 21.7372\n",
      "epoch 218, run 0, loss 22.2517\n",
      "epoch 218, run 30, loss 21.4056\n",
      "epoch 219, run 0, loss 21.1838\n",
      "epoch 219, run 30, loss 22.1048\n",
      "epoch 220, run 0, loss 22.5653\n",
      "epoch 220, run 30, loss 21.7189\n",
      "epoch 221, run 0, loss 21.6443\n",
      "epoch 221, run 30, loss 22.5653\n",
      "epoch 222, run 0, loss 22.1048\n",
      "epoch 222, run 30, loss 21.6443\n",
      "epoch 223, run 0, loss 22.2669\n",
      "epoch 223, run 30, loss 22.1048\n",
      "epoch 224, run 0, loss 20.2702\n",
      "epoch 224, run 30, loss 22.5653\n",
      "epoch 225, run 0, loss 21.6443\n",
      "epoch 225, run 30, loss 21.6443\n",
      "epoch 226, run 0, loss 21.5668\n",
      "epoch 226, run 30, loss 21.6443\n",
      "epoch 227, run 0, loss 21.6443\n",
      "epoch 227, run 30, loss 20.2627\n",
      "epoch 228, run 0, loss 21.3017\n",
      "epoch 228, run 30, loss 20.3525\n",
      "epoch 229, run 0, loss 21.6443\n",
      "epoch 229, run 30, loss 20.9055\n",
      "epoch 230, run 0, loss 21.6443\n",
      "epoch 230, run 30, loss 21.4346\n",
      "epoch 231, run 0, loss 21.1838\n",
      "epoch 231, run 30, loss 22.8205\n",
      "epoch 232, run 0, loss 22.1048\n",
      "epoch 232, run 30, loss 21.8841\n",
      "epoch 233, run 0, loss 22.5653\n",
      "epoch 233, run 30, loss 21.9602\n",
      "epoch 234, run 0, loss 22.1048\n",
      "epoch 234, run 30, loss 21.6443\n",
      "epoch 235, run 0, loss 21.1838\n",
      "epoch 235, run 30, loss 20.2627\n",
      "epoch 236, run 0, loss 21.6443\n",
      "epoch 236, run 30, loss 19.8022\n",
      "epoch 237, run 0, loss 22.6925\n",
      "epoch 237, run 30, loss 20.1527\n",
      "epoch 238, run 0, loss 21.2874\n",
      "epoch 238, run 30, loss 20.7233\n",
      "epoch 239, run 0, loss 20.7233\n",
      "epoch 239, run 30, loss 21.2485\n",
      "epoch 240, run 0, loss 21.7093\n",
      "epoch 240, run 30, loss 22.5653\n",
      "epoch 241, run 0, loss 20.7235\n",
      "epoch 241, run 30, loss 22.1143\n",
      "epoch 242, run 0, loss 20.7309\n",
      "epoch 242, run 30, loss 21.1838\n",
      "epoch 243, run 0, loss 22.1048\n",
      "epoch 243, run 30, loss 21.9726\n",
      "epoch 244, run 0, loss 21.6443\n",
      "epoch 244, run 30, loss 22.5653\n",
      "epoch 245, run 0, loss 22.8166\n",
      "epoch 245, run 30, loss 22.5653\n",
      "epoch 246, run 0, loss 20.6618\n",
      "epoch 246, run 30, loss 21.3661\n",
      "epoch 247, run 0, loss 21.6443\n",
      "epoch 247, run 30, loss 21.5642\n",
      "epoch 248, run 0, loss 22.1048\n",
      "epoch 248, run 30, loss 22.5653\n",
      "epoch 249, run 0, loss 22.1048\n",
      "epoch 249, run 30, loss 21.1838\n",
      "epoch 250, run 0, loss 22.5653\n",
      "epoch 250, run 30, loss 21.1887\n",
      "epoch 251, run 0, loss 21.6455\n",
      "epoch 251, run 30, loss 22.1048\n",
      "epoch 252, run 0, loss 21.6443\n",
      "epoch 252, run 30, loss 22.5653\n",
      "epoch 253, run 0, loss 21.6997\n",
      "epoch 253, run 30, loss 21.6443\n",
      "epoch 254, run 0, loss 21.6443\n",
      "epoch 254, run 30, loss 22.5653\n",
      "epoch 255, run 0, loss 21.1838\n",
      "epoch 255, run 30, loss 21.1838\n",
      "epoch 256, run 0, loss 22.1048\n",
      "epoch 256, run 30, loss 22.1048\n",
      "epoch 257, run 0, loss 22.4339\n",
      "epoch 257, run 30, loss 22.5653\n",
      "epoch 258, run 0, loss 21.6453\n",
      "epoch 258, run 30, loss 23.0259\n",
      "epoch 259, run 0, loss 23.0259\n",
      "epoch 259, run 30, loss 21.1838\n",
      "epoch 260, run 0, loss 21.1838\n",
      "epoch 260, run 30, loss 21.6445\n",
      "epoch 261, run 0, loss 21.6443\n",
      "epoch 261, run 30, loss 22.4722\n",
      "epoch 262, run 0, loss 22.1048\n",
      "epoch 262, run 30, loss 23.0259\n",
      "epoch 263, run 0, loss 22.4201\n",
      "epoch 263, run 30, loss 21.5197\n",
      "epoch 264, run 0, loss 22.5653\n",
      "epoch 264, run 30, loss 21.7883\n",
      "epoch 265, run 0, loss 20.835\n",
      "epoch 265, run 30, loss 21.6443\n",
      "epoch 266, run 0, loss 19.8022\n",
      "epoch 266, run 30, loss 22.5653\n",
      "epoch 267, run 0, loss 21.6443\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 267, run 30, loss 22.4855\n",
      "epoch 268, run 0, loss 22.1048\n",
      "epoch 268, run 30, loss 22.5653\n",
      "epoch 269, run 0, loss 21.067\n",
      "epoch 269, run 30, loss 22.1017\n",
      "epoch 270, run 0, loss 23.0259\n",
      "epoch 270, run 30, loss 22.0562\n",
      "epoch 271, run 0, loss 21.6443\n",
      "epoch 271, run 30, loss 20.6421\n",
      "epoch 272, run 0, loss 20.8923\n",
      "epoch 272, run 30, loss 22.5653\n",
      "epoch 273, run 0, loss 22.1048\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-171-02f30765f7c8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;31m# need to incoporate y in the batches and expand to 8 classes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_doc_embed_with_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0my_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout_rate\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mj\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m30\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/harrygong/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    787\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 789\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    790\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/harrygong/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    969\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    970\u001b[0m           if (not is_tensor_handle_feed and\n\u001b[0;32m--> 971\u001b[0;31m               not subfeed_t.get_shape().is_compatible_with(np_val.shape)):\n\u001b[0m\u001b[1;32m    972\u001b[0m             raise ValueError(\n\u001b[1;32m    973\u001b[0m                 \u001b[0;34m'Cannot feed value of shape %r for Tensor %r, '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/harrygong/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/tensor_shape.py\u001b[0m in \u001b[0;36mis_compatible_with\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    713\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    714\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mx_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_dim\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 715\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mx_dim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_compatible_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    716\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    717\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/harrygong/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/tensor_shape.py\u001b[0m in \u001b[0;36mis_compatible_with\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0mother\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mas_dimension\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     return (self._value is None or other.value is None or\n\u001b[0;32m---> 92\u001b[0;31m             self._value == other.value)\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0massert_is_compatible_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "\n",
    "for i in range(epoch):\n",
    "    xloss = 0\n",
    "    acc = 0.0\n",
    "    \n",
    "    for j in range(total_batch):\n",
    "        # need to incoporate y in the batches and expand to 8 classes \n",
    "        index, x_, y_ = next_batch(train_doc_embed_with_class, index, batch_size)\n",
    "        _, xloss = sess.run([optimizer, loss], feed_dict={x: x_, y: y_, dropout_rate: 0.5})\n",
    "        \n",
    "        if j % 30 == 0:\n",
    "            print(\"epoch %d, run %d, loss %g\" % (i, j, xloss))\n",
    "            \n",
    "    if i % 100 == 0:\n",
    "        acc = sess.run(accuracy, feed_dict={x:valid_doc_embed_with_class[0], y:valid_doc_embed_with_class[1], dropout_rate: 1.0})\n",
    "        print(\"epoch %d, Validation acc: %g\" % (i, acc * 100), end=\"\")\n",
    "        print(\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save data sets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.savez('corpus_all_temp', train_doc_temp=train_doc_temp, valid_doc_temp=valid_doc_temp, test_doc_temp=test_doc_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez('corpus_all_47001', train_doc=train_doc, valid_doc=valid_doc, test_doc=test_doc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
