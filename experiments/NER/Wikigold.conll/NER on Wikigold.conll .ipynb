{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference: https://gist.github.com/dirko/1d596ca757a541da96ac3caa6f291229"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle \n",
    "import numpy as np \n",
    "\n",
    "# from sklearn.cross_validation import train_test_split\n",
    "# from lambdawithmask import Lambda as MaskLambda\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import load_model\n",
    "\n",
    "# from keras.layers.recurrent import LSTM\n",
    "# from keras.layers.core import Activation, Dense, Input\n",
    "# from keras.layers.embeddings import Embedding\n",
    "# from keras.layers.wrappers import TimeDistributed, Bidirectional\n",
    "\n",
    "from keras.layers import Input, Dense, TimeDistributed\n",
    "from keras.layers import Embedding, Activation\n",
    "from keras.layers import GRU, LSTM, Bidirectional\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "\n",
    "from keras.backend import tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('conll.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = data['X']\n",
    "y = data['y']\n",
    "word2ind = data['word2ind']\n",
    "ind2word = data['ind2word']\n",
    "label2ind = data['label2ind']\n",
    "ind2label = data['ind2label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3640\n",
      "15\n",
      "['010', 'is', 'the', 'tenth', 'album', 'from', 'Japanese', 'Punk', 'Techno', 'band', 'The', 'Mad', 'Capsule', 'Markets', '.']\n",
      "3640\n",
      "15\n",
      "['I-MISC', 'O', 'O', 'O', 'O', 'O', 'I-MISC', 'O', 'O', 'O', 'I-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'O']\n",
      "{'I-PER': 1, 'I-LOC': 2, 'I-ORG': 4, 'I-MISC': 5, 'O': 3}\n",
      "{1: 'I-PER', 2: 'I-LOC', 3: 'O', 4: 'I-ORG', 5: 'I-MISC'}\n"
     ]
    }
   ],
   "source": [
    "print(len(X))\n",
    "print(len(X[0]))\n",
    "print(X[0])\n",
    "\n",
    "print(len(y))\n",
    "print(len(y[0]))\n",
    "print(y[0])\n",
    "\n",
    "print(label2ind)\n",
    "print(ind2label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def encode(x, n):\n",
    "    result = np.zeros(n)\n",
    "    result[x] = 1\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum sequence length: 63\n"
     ]
    }
   ],
   "source": [
    "maxlen = max([len(x) for x in X])\n",
    "print('Maximum sequence length:', maxlen)\n",
    "\n",
    "X_enc = [[word2ind[c] for c in x] for x in X]\n",
    "# X_enc_reverse = [[c for c in reversed(x)] for x in X_enc]\n",
    "X_enc = pad_sequences(X_enc, maxlen=maxlen)\n",
    "# X_enc_b = pad_sequences(X_enc_reverse, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(3640, 63)\n"
     ]
    }
   ],
   "source": [
    "print(type(X_enc))\n",
    "print(X_enc.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 3, 3, 3, 3, 3, 5, 3, 3, 3, 4, 4, 4, 4, 3]\n",
      "63\n",
      "<class 'numpy.ndarray'>\n",
      "(3640, 63, 6)\n"
     ]
    }
   ],
   "source": [
    "max_label = max(label2ind.values()) + 1\n",
    "print(max_label)\n",
    "\n",
    "y_enc = [[0] * (maxlen - len(ey)) + [label2ind[c] for c in ey] for ey in y]\n",
    "print(y_enc[0])\n",
    "y_enc = [[encode(c, max_label) for c in ey] for ey in y_enc]\n",
    "print(len(y_enc[0]))\n",
    "y_enc = pad_sequences(y_enc, maxlen=maxlen)\n",
    "print(type(y_enc))\n",
    "print(y_enc.shape)\n",
    "\n",
    "# (X_train_f, X_test_f, X_train_b,\n",
    "#  X_test_b, y_train, y_test) = train_test_split(X_enc_f, X_enc_b, y_enc,\n",
    "#                                                test_size=11*32, train_size=45*32, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "validation_split = 0.1\n",
    "test_split = 0.1 \n",
    "\n",
    "indices = np.arange(X_enc.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "X_enc = X_enc[indices]\n",
    "y_enc = y_enc[indices]\n",
    "num_validation_samples = int(validation_split * X_enc.shape[0])\n",
    "num_test_samples = int(test_split * X_enc.shape[0])\n",
    "\n",
    "X_train = X_enc[:-num_validation_samples-num_test_samples]\n",
    "y_train = y_enc[:-num_validation_samples-num_test_samples]\n",
    "X_val = X_enc[-num_validation_samples-num_test_samples:]\n",
    "y_val = y_enc[-num_validation_samples-num_test_samples:]\n",
    "X_test = X_enc[-num_test_samples:]\n",
    "y_test = y_enc[-num_test_samples:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and testing tensor shapes:\n",
      "(2912, 63) (728, 63) (364, 63) (2912, 63, 6) (728, 63, 6) (364, 63, 6)\n"
     ]
    }
   ],
   "source": [
    "print('Training and testing tensor shapes:')\n",
    "print(X_train.shape, X_val.shape, X_test.shape, y_train.shape, y_val.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "max_features = len(word2ind)\n",
    "embedding_size = 128\n",
    "hidden_size = 32\n",
    "out_size = len(label2ind) + 1\n",
    "batch_size = 32\n",
    "epochs = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 63, 128)           1060480   \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 63, 64)            41216     \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 63, 6)             390       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 63, 6)             0         \n",
      "=================================================================\n",
      "Total params: 1,102,086\n",
      "Trainable params: 1,102,086\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=max_features, output_dim=embedding_size,\n",
    "                    input_length=maxlen, mask_zero=True))\n",
    "model.add(Bidirectional(LSTM(hidden_size, return_sequences=True)))\n",
    "model.add(TimeDistributed(Dense(out_size)))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filepath = \"models/NER-Wikigold-{epoch:02d}-{val_loss:.2f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='auto')\n",
    "earlystopping = EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=1, mode='auto')\n",
    "callbacks_list = [checkpoint, earlystopping]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs,\n",
    "          validation_data=(X_val, y_val), callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = load_model('models/NER-Wikigold-09-0.08.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "score = model.evaluate(X_test, y_test, batch_size=batch_size, verbose=1)\n",
    "print('Raw test score:', score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def score(yh, pr):\n",
    "    coords = [np.where(yhh > 0)[0][0] for yhh in yh]\n",
    "    yh = [yhh[co:] for yhh, co in zip(yh, coords)]\n",
    "    ypr = [prr[co:] for prr, co in zip(pr, coords)]\n",
    "    fyh = [c for row in yh for c in row]\n",
    "    fpr = [c for row in ypr for c in row]\n",
    "    return fyh, fpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# On the training set ]\n",
    "\n",
    "pr = model.predict(X_train)\n",
    "pr = pr.argmax(2)\n",
    "print(pr.shape)\n",
    "print(pr[1])\n",
    "print(pr[0][0])\n",
    "yh = y_train.argmax(2)\n",
    "print(yh.shape)\n",
    "print(yh[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fyh, fpr = score(yh, pr)\n",
    "print('Testing accuracy:', accuracy_score(fyh, fpr))\n",
    "print('Testing confusion matrix:')\n",
    "print(confusion_matrix(fyh, fpr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# On the validatiotn set\n",
    "\n",
    "pr = model.predict(X_val)\n",
    "pr = pr.argmax(2)\n",
    "print(pr.shape)\n",
    "print(pr[0])\n",
    "print(pr[0][0])\n",
    "yh = y_val.argmax(2)\n",
    "print(yh.shape)\n",
    "print(yh[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fyh, fpr = score(yh, pr)\n",
    "print('Testing accuracy:', accuracy_score(fyh, fpr))\n",
    "print('Testing confusion matrix:')\n",
    "print(confusion_matrix(fyh, fpr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# On the test set \n",
    "pr = model.predict(X_test)\n",
    "pr = pr.argmax(2)\n",
    "print(pr.shape)\n",
    "print(pr[0])\n",
    "print(pr[0][0])\n",
    "yh = y_test.argmax(2)\n",
    "print(yh.shape)\n",
    "print(yh[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fyh, fpr = score(yh, pr)\n",
    "print('Testing accuracy:', accuracy_score(fyh, fpr))\n",
    "print('Testing confusion matrix:')\n",
    "print(confusion_matrix(fyh, fpr))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
