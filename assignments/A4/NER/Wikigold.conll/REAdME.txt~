Wikigold.conll folder structure

data foler contains the datasets, jupyter notebook and python script for data preprocessing
- datasets sources: wikigold.conll.txt
- processed data: conll.pkl
- notebook: Wikigold.conll data processing.ipynb, shows the flow of data loading, preprocessing and saving
- python script: Wikigold.conll_data_preprocessing.py, execute this will generate usable datasets in the same folder

models folder contains checkpoint files for trained NER models on the processed Wikigold.conll datasets

NER on Wikigold.conll.ipynb (jupyter notebook): shows data loading, model construction, training and evaluation

NER_on_Wikigold.conll.py (python script): refactored from the notebook, has structured utility functions, the main section also constructs, trains and evaluates a NER model.


Starting from scratch:
1. go to data folder, execute Wikigold.conll_data_preprocessing.py to generate preprocessed data (already there by default)
2. execute NER_on_Wikigold.conll.py to build and evaluate a NER model on the Wikigold.conll data set 
