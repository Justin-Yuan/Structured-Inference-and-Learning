{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function \n",
    "import numpy as np\n",
    "import tensorflow as tf \n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Flatten, Lambda\n",
    "from keras.layers import Conv1D, MaxPooling1D, Embedding\n",
    "from keras.layers import SimpleRNN, GRU, LSTM, Bidirectional\n",
    "\n",
    "import keras.backend as K\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class RNNClassifier():\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    def __init__(self, batch_size, epochs, raw_data_path=None, embedded_data_path='data/data_and_embedding100.npz',\n",
    "                 embedding_dim=100, rnn_type='lstm'):\n",
    "        super(RNNClassifier, self).__init__(batch_size, epochs, raw_data_path=None,\n",
    "                embedded_data_path=embedded_data_path, embedding_dim=embedding_dim) \n",
    "        \n",
    "        # get the RNN model type \n",
    "        self.type = rnn_type\n",
    "        \n",
    "    def build(self):\n",
    "        \"\"\" \n",
    "        \"\"\"\n",
    "        if self.type == 'simple':\n",
    "            self.model = self.build_simple_rnn()\n",
    "        elif self.type == 'lstm':\n",
    "            self.model = self.build_lstm()\n",
    "        elif self.type == 'gru':\n",
    "            self.model = self.build_gru()\n",
    "        elif self.type == 'bidirectional':\n",
    "            self.model = self.build_bidirectional_lstm()\n",
    "            \n",
    "    def build_simple_rnn(self):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        sequence_input = Input(shape=(max_sequence_length, ), dtype='int32')\n",
    "        embedded_sequences = self.embedding_layer(sequence_input)\n",
    "        x = SimpleRNN(50, dropout=0.2, recurrent_dropout=0.2)(embedded_sequences)\n",
    "        preds = Dense(6, activation='softmax')(x)\n",
    "        model_rnn_final_state = Model(sequence_input, preds)\n",
    "        return model_rnn_final_state\n",
    "    \n",
    "    def build_lstm(self):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        sequence_input = Input(shape=(max_sequence_length, ), dtype='int32')\n",
    "        embedded_sequences = self.embedding_layer(sequence_input)\n",
    "        x = LSTM(50, dropout=0.2, recurrent_dropout=0.2)(embedded_sequences)\n",
    "        preds = Dense(6, activation='softmax')(x)\n",
    "        model_lstm_final_state = Model(sequence_input, preds)\n",
    "        print(model_lstm_final_state)\n",
    "    \n",
    "    def build_gru(self):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        sequence_input = Input(shape=(max_sequence_length, ), dtype='int32')\n",
    "        embedded_sequences = self.embedding_layer(sequence_input)\n",
    "        x = GRU(50, dropout=0.2, recurrent_dropout=0.2)(embedded_sequences)\n",
    "        preds = Dense(6, activation='softmax')(x)\n",
    "        model_gru_final_state = Model(sequence_input, preds)\n",
    "        return model_gru_final_state\n",
    "    \n",
    "    def build_bidirectional_lstm(self):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        sequence_input = Input(shape=(max_sequence_length, ), dtype='int32')\n",
    "        embedded_sequences = self.embedding_layer(sequence_input)\n",
    "        x = Bidirectional(LSTM(50, dropout=0.2, recurrent_dropout=0.2))(embedded_sequences)\n",
    "        preds = Dense(6, activation='softmax')(x)\n",
    "        model_bidirlstm_final_state = Model(sequence_input, preds)\n",
    "        return model_bidirlstm_final_state\n",
    "        \n",
    "    def train(self, loss='categorical_crossentropy', optimizer='adam', model_base_path=\"models/\"):\n",
    "        \"\"\" for Simple RNN, the optimizer needs to implement gradients clipping to prevent explosion \n",
    "        \"\"\"\n",
    "        if self.type == 'simple':\n",
    "            optimizer = optimizers.Adam(clipnorm=1.)\n",
    "        model_base_path += self.type + '/'\n",
    "        super(RNNClassifier, self).train(optimizer=optimizer, model_base_path=model_base_path)\n",
    "    \n",
    "    def save(self, path='models/model.h5'):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        path = 'models/'\n",
    "        path += self.type + '/model.h5'\n",
    "        super(RNNClassifier, self).save(path=path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \"\"\" test different RNN models\n",
    "    \"\"\"\n",
    "    \n",
    "    # Simple RNN with gradient clipping\n",
    "    simple_RNN = RNNClassifier(batch_size=128, epochs=10, raw_data_path=None,\n",
    "                        embedded_data_path='data/data_and_embedding100.npz', embedding_dim=100, rnn_type='simple')\n",
    "    simple_RNN.build()\n",
    "    simple_RNN.train()\n",
    "    print(\"constructed simple RNN classifier\")\n",
    "    simple_RNN.evaluate()\n",
    "    print(\"simple RNN classifier evaluated\")\n",
    "    \n",
    "    # LSTM \n",
    "    lstm = RNNClassifier(batch_size=128, epochs=10, raw_data_path=None,\n",
    "                        embedded_data_path='data/data_and_embedding100.npz', embedding_dim=100, rnn_type='lstm')\n",
    "    lstm.build()\n",
    "    lstm.train()\n",
    "    print(\"constructed LSTM classifier\")\n",
    "    lstm.evaluate()\n",
    "    print(\"LSTM classifier evaluated\")\n",
    "    \n",
    "    # GRU\n",
    "    gru = RNNClassifier(batch_size=128, epochs=10, raw_data_path=None,\n",
    "                        embedded_data_path='data/data_and_embedding100.npz', embedding_dim=100, rnn_type='gru')\n",
    "    gru.build()\n",
    "    gru.train()\n",
    "    print(\"constructed GRU classifier\")\n",
    "    gru.evaluate()\n",
    "    print(\"GRU classifier evaluated\")\n",
    "    \n",
    "    # Bidirectional LSTM\n",
    "    bidirectional_lstm = RNNClassifier(batch_size=128, epochs=10, raw_data_path=None,\n",
    "                        embedded_data_path='data/data_and_embedding100.npz', embedding_dim=100, rnn_type='bidirectional')\n",
    "    bidirectional_lstm.build()\n",
    "    bidirectional_lstm.train()\n",
    "    print(\"constructed bidirectional LSTM classifier\")\n",
    "    bidirectional_lstm.evaluate()\n",
    "    print(\"bidirectional LSTM classifier evaluated\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
