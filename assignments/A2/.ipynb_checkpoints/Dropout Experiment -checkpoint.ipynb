{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Droptout Experiment with CNN on CIFAR-10 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cPickle'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-f8bce28c07be>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcPickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'cPickle'"
     ]
    }
   ],
   "source": [
    "import pickle, cPickle\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6,\n",
       " 9,\n",
       " 9,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 7,\n",
       " 8,\n",
       " 3,\n",
       " 4,\n",
       " 7,\n",
       " 7,\n",
       " 2,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 3,\n",
       " 2,\n",
       " 6,\n",
       " 4,\n",
       " 3,\n",
       " 6,\n",
       " 6,\n",
       " 2,\n",
       " 6,\n",
       " 3,\n",
       " 5,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 9,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 0,\n",
       " 3,\n",
       " 7,\n",
       " 3,\n",
       " 3,\n",
       " 5,\n",
       " 2,\n",
       " 2,\n",
       " 7,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 9,\n",
       " 5,\n",
       " 7,\n",
       " 9,\n",
       " 2,\n",
       " 2,\n",
       " 5,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 8,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 9,\n",
       " 7,\n",
       " 8,\n",
       " 5,\n",
       " 9,\n",
       " 6,\n",
       " 7,\n",
       " 3,\n",
       " 1,\n",
       " 9,\n",
       " 0,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 7,\n",
       " 7,\n",
       " 4,\n",
       " 7,\n",
       " 9,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 8,\n",
       " 0,\n",
       " 1,\n",
       " 6,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 8,\n",
       " 3,\n",
       " 9,\n",
       " 6,\n",
       " 6,\n",
       " 1,\n",
       " 8,\n",
       " 5,\n",
       " 2,\n",
       " 9,\n",
       " 9,\n",
       " 8,\n",
       " 1,\n",
       " 7,\n",
       " 7,\n",
       " 0,\n",
       " 0,\n",
       " 6,\n",
       " 9,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 9,\n",
       " 2,\n",
       " 6,\n",
       " 6,\n",
       " 1,\n",
       " 9,\n",
       " 5,\n",
       " 0,\n",
       " 4,\n",
       " 7,\n",
       " 6,\n",
       " 7,\n",
       " 1,\n",
       " 8,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 8,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 6,\n",
       " 2,\n",
       " 4,\n",
       " 9,\n",
       " 9,\n",
       " 5,\n",
       " 4,\n",
       " 3,\n",
       " 6,\n",
       " 7,\n",
       " 4,\n",
       " 6,\n",
       " 8,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " 3,\n",
       " 1,\n",
       " 8,\n",
       " 4,\n",
       " 7,\n",
       " 6,\n",
       " 0,\n",
       " 9,\n",
       " 5,\n",
       " 1,\n",
       " 3,\n",
       " 8,\n",
       " 2,\n",
       " 7,\n",
       " 5,\n",
       " 3,\n",
       " 4,\n",
       " 1,\n",
       " 5,\n",
       " 7,\n",
       " 0,\n",
       " 4,\n",
       " 7,\n",
       " 5,\n",
       " 5,\n",
       " 1,\n",
       " 0,\n",
       " 9,\n",
       " 6,\n",
       " 9,\n",
       " 0,\n",
       " 8,\n",
       " 7,\n",
       " 8,\n",
       " 8,\n",
       " 2,\n",
       " 5,\n",
       " 2,\n",
       " 3,\n",
       " 5,\n",
       " 0,\n",
       " 6,\n",
       " 1,\n",
       " 9,\n",
       " 3,\n",
       " 6,\n",
       " 9,\n",
       " 1,\n",
       " 3,\n",
       " 9,\n",
       " 6,\n",
       " 6,\n",
       " 7,\n",
       " 1,\n",
       " 0,\n",
       " 9,\n",
       " 5,\n",
       " 8,\n",
       " 5,\n",
       " 2,\n",
       " 9,\n",
       " 0,\n",
       " 8,\n",
       " 8,\n",
       " 0,\n",
       " 6,\n",
       " 9,\n",
       " 1,\n",
       " 1,\n",
       " 6,\n",
       " 3,\n",
       " 7,\n",
       " 6,\n",
       " 6,\n",
       " 0,\n",
       " 6,\n",
       " 6,\n",
       " 1,\n",
       " 7,\n",
       " 1,\n",
       " 5,\n",
       " 8,\n",
       " 3,\n",
       " 6,\n",
       " 6,\n",
       " 8,\n",
       " 6,\n",
       " 8,\n",
       " 4,\n",
       " 6,\n",
       " 6,\n",
       " 1,\n",
       " 3,\n",
       " 8,\n",
       " 3,\n",
       " 4,\n",
       " 1,\n",
       " 7,\n",
       " 1,\n",
       " 3,\n",
       " 8,\n",
       " 5,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 0,\n",
       " 9,\n",
       " 3,\n",
       " 7,\n",
       " 4,\n",
       " 9,\n",
       " 9,\n",
       " 2,\n",
       " 4,\n",
       " 9,\n",
       " 9,\n",
       " 1,\n",
       " 0,\n",
       " 5,\n",
       " 9,\n",
       " 0,\n",
       " 8,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 5,\n",
       " 6,\n",
       " 3,\n",
       " 2,\n",
       " 7,\n",
       " 8,\n",
       " 8,\n",
       " 6,\n",
       " 0,\n",
       " 7,\n",
       " 9,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 4,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 5,\n",
       " 9,\n",
       " 9,\n",
       " 0,\n",
       " 8,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 6,\n",
       " 3,\n",
       " 3,\n",
       " 9,\n",
       " 0,\n",
       " 7,\n",
       " 9,\n",
       " 7,\n",
       " 7,\n",
       " 9,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 6,\n",
       " 6,\n",
       " 8,\n",
       " 7,\n",
       " 1,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 4,\n",
       " 5,\n",
       " 7,\n",
       " 5,\n",
       " 9,\n",
       " 0,\n",
       " 3,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 6,\n",
       " 0,\n",
       " 0,\n",
       " 6,\n",
       " 6,\n",
       " 0,\n",
       " 8,\n",
       " 1,\n",
       " 6,\n",
       " 2,\n",
       " 9,\n",
       " 2,\n",
       " 5,\n",
       " 9,\n",
       " 6,\n",
       " 7,\n",
       " 4,\n",
       " 1,\n",
       " 8,\n",
       " 7,\n",
       " 3,\n",
       " 6,\n",
       " 9,\n",
       " 3,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 5,\n",
       " 1,\n",
       " 0,\n",
       " 3,\n",
       " 4,\n",
       " 8,\n",
       " 5,\n",
       " 4,\n",
       " 7,\n",
       " 2,\n",
       " 3,\n",
       " 9,\n",
       " 7,\n",
       " 6,\n",
       " 7,\n",
       " 1,\n",
       " 4,\n",
       " 7,\n",
       " 0,\n",
       " 1,\n",
       " 7,\n",
       " 3,\n",
       " 1,\n",
       " 8,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 9,\n",
       " 0,\n",
       " 9,\n",
       " 6,\n",
       " 8,\n",
       " 2,\n",
       " 7,\n",
       " 7,\n",
       " 4,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 8,\n",
       " 9,\n",
       " 4,\n",
       " 2,\n",
       " 7,\n",
       " 2,\n",
       " 5,\n",
       " 2,\n",
       " 5,\n",
       " 1,\n",
       " 9,\n",
       " 4,\n",
       " 8,\n",
       " 5,\n",
       " 1,\n",
       " 7,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 6,\n",
       " 9,\n",
       " 0,\n",
       " 7,\n",
       " 8,\n",
       " 8,\n",
       " 9,\n",
       " 9,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 6,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 8,\n",
       " 0,\n",
       " 4,\n",
       " 8,\n",
       " 8,\n",
       " 1,\n",
       " 5,\n",
       " 2,\n",
       " 6,\n",
       " 8,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 7,\n",
       " 7,\n",
       " 5,\n",
       " 9,\n",
       " 6,\n",
       " 2,\n",
       " 8,\n",
       " 3,\n",
       " 4,\n",
       " 7,\n",
       " 3,\n",
       " 9,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 4,\n",
       " 8,\n",
       " 1,\n",
       " 8,\n",
       " 6,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 7,\n",
       " 1,\n",
       " 3,\n",
       " 9,\n",
       " 8,\n",
       " 0,\n",
       " 1,\n",
       " 7,\n",
       " 5,\n",
       " 8,\n",
       " 2,\n",
       " 8,\n",
       " 0,\n",
       " 4,\n",
       " 1,\n",
       " 8,\n",
       " 9,\n",
       " 8,\n",
       " 2,\n",
       " 9,\n",
       " 9,\n",
       " 2,\n",
       " 7,\n",
       " 5,\n",
       " 7,\n",
       " 3,\n",
       " 8,\n",
       " 8,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 7,\n",
       " 1,\n",
       " 6,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 6,\n",
       " 9,\n",
       " 7,\n",
       " 6,\n",
       " 2,\n",
       " 5,\n",
       " 5,\n",
       " 1,\n",
       " 7,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 9,\n",
       " 5,\n",
       " 4,\n",
       " 2,\n",
       " 7,\n",
       " 8,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 7,\n",
       " 6,\n",
       " 9,\n",
       " 8,\n",
       " 0,\n",
       " 6,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 8,\n",
       " 4,\n",
       " 0,\n",
       " 1,\n",
       " 8,\n",
       " 8,\n",
       " 1,\n",
       " 5,\n",
       " 7,\n",
       " 6,\n",
       " 4,\n",
       " 5,\n",
       " 8,\n",
       " 7,\n",
       " 1,\n",
       " 9,\n",
       " 1,\n",
       " 9,\n",
       " 8,\n",
       " 4,\n",
       " 7,\n",
       " 3,\n",
       " 8,\n",
       " 8,\n",
       " 2,\n",
       " 6,\n",
       " 6,\n",
       " 7,\n",
       " 1,\n",
       " 6,\n",
       " 8,\n",
       " 1,\n",
       " 9,\n",
       " 7,\n",
       " 8,\n",
       " 3,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 8,\n",
       " 8,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 5,\n",
       " 0,\n",
       " 8,\n",
       " 8,\n",
       " 7,\n",
       " 9,\n",
       " 9,\n",
       " 0,\n",
       " 9,\n",
       " 4,\n",
       " 1,\n",
       " 3,\n",
       " 6,\n",
       " 6,\n",
       " 4,\n",
       " 4,\n",
       " 7,\n",
       " 5,\n",
       " 6,\n",
       " 0,\n",
       " 8,\n",
       " 0,\n",
       " 3,\n",
       " 2,\n",
       " 8,\n",
       " 4,\n",
       " 6,\n",
       " 9,\n",
       " 9,\n",
       " 7,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 6,\n",
       " 7,\n",
       " 4,\n",
       " 9,\n",
       " 1,\n",
       " 6,\n",
       " 2,\n",
       " 7,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 6,\n",
       " 7,\n",
       " 5,\n",
       " 7,\n",
       " 6,\n",
       " 8,\n",
       " 9,\n",
       " 0,\n",
       " 9,\n",
       " 4,\n",
       " 4,\n",
       " 7,\n",
       " 0,\n",
       " 9,\n",
       " 4,\n",
       " 9,\n",
       " 6,\n",
       " 9,\n",
       " 4,\n",
       " 5,\n",
       " 7,\n",
       " 9,\n",
       " 2,\n",
       " 4,\n",
       " 5,\n",
       " 1,\n",
       " 4,\n",
       " 3,\n",
       " 9,\n",
       " 6,\n",
       " 5,\n",
       " 6,\n",
       " 9,\n",
       " 3,\n",
       " 3,\n",
       " 5,\n",
       " 0,\n",
       " 7,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 6,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 5,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 3,\n",
       " 9,\n",
       " 8,\n",
       " 4,\n",
       " 9,\n",
       " 8,\n",
       " 0,\n",
       " 2,\n",
       " 6,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 1,\n",
       " 8,\n",
       " 8,\n",
       " 3,\n",
       " 6,\n",
       " 9,\n",
       " 6,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 2,\n",
       " 4,\n",
       " 5,\n",
       " 7,\n",
       " 6,\n",
       " 5,\n",
       " 3,\n",
       " 0,\n",
       " 5,\n",
       " 0,\n",
       " 5,\n",
       " 0,\n",
       " 8,\n",
       " 2,\n",
       " 6,\n",
       " 7,\n",
       " 3,\n",
       " 8,\n",
       " 2,\n",
       " 1,\n",
       " 7,\n",
       " 6,\n",
       " 7,\n",
       " 1,\n",
       " 0,\n",
       " 9,\n",
       " 5,\n",
       " 5,\n",
       " 0,\n",
       " 1,\n",
       " 7,\n",
       " 6,\n",
       " 9,\n",
       " 0,\n",
       " 4,\n",
       " 7,\n",
       " 7,\n",
       " 1,\n",
       " 5,\n",
       " 9,\n",
       " 4,\n",
       " 0,\n",
       " 8,\n",
       " 5,\n",
       " 9,\n",
       " 9,\n",
       " 6,\n",
       " 7,\n",
       " 1,\n",
       " 8,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 8,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 6,\n",
       " 0,\n",
       " 0,\n",
       " 5,\n",
       " 3,\n",
       " 8,\n",
       " 2,\n",
       " 3,\n",
       " 7,\n",
       " 2,\n",
       " 9,\n",
       " 3,\n",
       " 8,\n",
       " 7,\n",
       " 8,\n",
       " 2,\n",
       " 7,\n",
       " 9,\n",
       " 0,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 6,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 8,\n",
       " 0,\n",
       " 5,\n",
       " 5,\n",
       " 1,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 6,\n",
       " 2,\n",
       " 7,\n",
       " 0,\n",
       " 1,\n",
       " 7,\n",
       " 7,\n",
       " 8,\n",
       " 2,\n",
       " 9,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 5,\n",
       " 1,\n",
       " 1,\n",
       " 7,\n",
       " 0,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 7,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 6,\n",
       " 1,\n",
       " 4,\n",
       " 3,\n",
       " 7,\n",
       " 8,\n",
       " 8,\n",
       " 3,\n",
       " 6,\n",
       " 6,\n",
       " 2,\n",
       " 3,\n",
       " 0,\n",
       " 9,\n",
       " 4,\n",
       " 3,\n",
       " 8,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 5,\n",
       " 4,\n",
       " 9,\n",
       " 3,\n",
       " 1,\n",
       " 8,\n",
       " 9,\n",
       " 3,\n",
       " 9,\n",
       " 9,\n",
       " 2,\n",
       " 9,\n",
       " 4,\n",
       " 8,\n",
       " 2,\n",
       " 9,\n",
       " 8,\n",
       " 8,\n",
       " 1,\n",
       " 5,\n",
       " 3,\n",
       " 6,\n",
       " 8,\n",
       " 7,\n",
       " 6,\n",
       " 9,\n",
       " 8,\n",
       " 0,\n",
       " 6,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 5,\n",
       " 8,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 7,\n",
       " 6,\n",
       " 9,\n",
       " 7,\n",
       " 1,\n",
       " 5,\n",
       " 5,\n",
       " 6,\n",
       " 6,\n",
       " 3,\n",
       " 6,\n",
       " 2,\n",
       " 4,\n",
       " 7,\n",
       " 0,\n",
       " 5,\n",
       " 6,\n",
       " 4,\n",
       " 6,\n",
       " 5,\n",
       " 2,\n",
       " 4,\n",
       " 6,\n",
       " 1,\n",
       " 6,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 3,\n",
       " 1,\n",
       " 8,\n",
       " 5,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 7,\n",
       " 3,\n",
       " 9,\n",
       " 4,\n",
       " 7,\n",
       " 9,\n",
       " 7,\n",
       " 3,\n",
       " 7,\n",
       " 2,\n",
       " 8,\n",
       " 4,\n",
       " 6,\n",
       " 6,\n",
       " 1,\n",
       " 2,\n",
       " 9,\n",
       " 0,\n",
       " 4,\n",
       " 8,\n",
       " 7,\n",
       " 3,\n",
       " 9,\n",
       " 8,\n",
       " 7,\n",
       " 7,\n",
       " 0,\n",
       " 2,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 5,\n",
       " 4,\n",
       " 0,\n",
       " 5,\n",
       " 6,\n",
       " 2,\n",
       " 8,\n",
       " 5,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 5,\n",
       " 7,\n",
       " 3,\n",
       " 5,\n",
       " 1,\n",
       " 3,\n",
       " 5,\n",
       " ...]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def unpickle(file):\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict\n",
    "\n",
    "def createTrainingSet():\n",
    "    labels = []\n",
    "    data = []\n",
    "    for i in range(5):\n",
    "        batch = unpickle(\"cifar-10-batches-py/data_batch_%d\" % (i+1))\n",
    "        batch_label = batch[b'labels']\n",
    "        batch_data = batch[b'data']\n",
    "        labels.extend(batch_label)\n",
    "        data.extend(batch_data)\n",
    "    return labels, data\n",
    "\n",
    "def createTestSet(path):\n",
    "    batch = unpickle(path)\n",
    "    label = batch[b'labels']\n",
    "    data = batch[b'data']\n",
    "    return label, data\n",
    "                     \n",
    "train_labels, train_data = createTrainingSet()\n",
    "test_labels, test_data = createTestSet(\"cifar-10-batches-py/test_batch\")\n",
    "\n",
    "\n",
    "# # train_data_m = np.asarray([val for sublist in train_data for val in sublist]).reshape(50000, 32*32*3)\n",
    "# train_labels = np.asarray(train_labels)\n",
    "# # test_data = \n",
    "# test_labels = np.asarray(test_labels)\n",
    "\n",
    "# print(len(train_data))\n",
    "# train_data[1]      \n",
    "# train_data.shape[0]\n",
    "train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_labels = 10\n",
    "num_train = len(train_data)\n",
    "num_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  6.00000000e+00,   1.48000000e+02,   7.20000000e+01,\n",
       "          3.50000000e+01,   0.00000000e+00,   3.36000000e+01,\n",
       "          6.27000000e-01,   5.00000000e+01,   1.00000000e+00],\n",
       "       [  1.00000000e+00,   8.50000000e+01,   6.60000000e+01,\n",
       "          2.90000000e+01,   0.00000000e+00,   2.66000000e+01,\n",
       "          3.51000000e-01,   3.10000000e+01,   0.00000000e+00],\n",
       "       [  8.00000000e+00,   1.83000000e+02,   6.40000000e+01,\n",
       "          0.00000000e+00,   0.00000000e+00,   2.33000000e+01,\n",
       "          6.72000000e-01,   3.20000000e+01,   1.00000000e+00],\n",
       "       [  1.00000000e+00,   8.90000000e+01,   6.60000000e+01,\n",
       "          2.30000000e+01,   9.40000000e+01,   2.81000000e+01,\n",
       "          1.67000000e-01,   2.10000000e+01,   0.00000000e+00],\n",
       "       [  0.00000000e+00,   1.37000000e+02,   4.00000000e+01,\n",
       "          3.50000000e+01,   1.68000000e+02,   4.31000000e+01,\n",
       "          2.28800000e+00,   3.30000000e+01,   1.00000000e+00]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = np.loadtxt(\"../test/pima-indians-diabetes.csv\", delimiter=\",\")\n",
    "dataset[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape=[None, 784])\n",
    "y_ = tf.placeholder(tf.float32, shape=[None, 10])\n",
    "\n",
    "x_image = tf.reshape(x, [-1, 28, 28, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-da1db53db3ea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'binary_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatchsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "W_conv2 = weight_variable([5, 5, 32, 64])\n",
    "b_conv2 = bias_variable([64])\n",
    "\n",
    "#\n",
    "h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "h_pool2 = max_pool_2x2(h_conv2)\n",
    "\n",
    "#\n",
    "W_conv2 = weight_variable([5, 5, 32, 64])\n",
    "b_conv2 = bias_variable([64])\n",
    "\n",
    "#\n",
    "h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "h_pool2 = max_pool_2x2(h_conv2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W_fc1 = weight_variable([7 * 7 * 64, 1024])\n",
    "b_fc1 = bias_variable([1024])\n",
    "\n",
    "h_pool2_flat = tf.reshape(h_pool2, [-1, 7 * 7 * 64])\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n",
    "\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W_fc2 = weight_variable([1024, 10])\n",
    "b_fc2 = bias_variable([10])\n",
    "\n",
    "y_conv = tf.matmul(h_fc1_drop, W_fc2) + b_fc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y_conv))\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(y_conv, 1), tf.argmax(y_, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for i in range(4000):\n",
    "    batch = mnist.train.next_batch(50)\n",
    "    \n",
    "    if i % 100 == 0: \n",
    "        train_accuracy = accuracy.eval(feed_dict={x: batch[0], y_: batch[1], keep_prob: 1.0})\n",
    "        print(\"step %d, training accuracy %g\" % (i, train_accuracy))\n",
    "    train_step.run(feed_dict={x: batch[0], y_: batch[1], keep_prob: 0.5})\n",
    "    \n",
    "print(\"test accuracy %g\" % accuracy.eval(feed_dict={x: mnist.test.images, y_: mnist.test.labels, keep_prob: 1.0}))\n",
    "total_time = (time.time() - start_time) / 3600\n",
    "print(\"time {0:.2f}\".format(total_time))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dropouts = [0, 0.1 , 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "import random\n",
    "acc = [random.uniform(0, 1) for i in range(11)]\n",
    "dropouts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "histogram of accuracy vs dropout rate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f315ef44da0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "width = 0.1\n",
    "\n",
    "plt.bar(dropouts, acc, width, align='center')\n",
    "\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Dropout rate')\n",
    "plt.show"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
