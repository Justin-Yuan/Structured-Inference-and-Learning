{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow Study Notes "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structuring Your TensorFlow Models \n",
    "http://danijar.com/structuring-your-tensorflow-models/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the compute graph \n",
    "It’s sensible to start with *** one class per model ***. What is the interface of that class? Usually, *** your model connects to some input data and target placeholders and provides operations for training, evaluation, and inference ***."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Model:\n",
    "\n",
    "    def __init__(self, data, target):\n",
    "        data_size = int(data.get_shape()[1])\n",
    "        target_size = int(target.get_shape()[1])\n",
    "        weight = tf.Variable(tf.truncated_normal([data_size, target_size]))\n",
    "        bias = tf.Variable(tf.constant(0.1, shape=[target_size]))\n",
    "        incoming = tf.matmul(data, weight) + bias\n",
    "        self._prediction = tf.nn.softmax(incoming)\n",
    "        cross_entropy = -tf.reduce_sum(target, tf.log(self._prediction))\n",
    "        self._optimize = tf.train.RMSPropOptimizer(0.03).minimize(cross_entropy)\n",
    "        mistakes = tf.not_equal(\n",
    "            tf.argmax(target, 1), tf.argmax(self._prediction, 1))\n",
    "        self._error = tf.reduce_mean(tf.cast(mistakes, tf.float32))\n",
    "\n",
    "    @property\n",
    "    def prediction(self):\n",
    "        return self._prediction\n",
    "\n",
    "    @property\n",
    "    def optimize(self):\n",
    "        return self._optimize\n",
    "\n",
    "    @property\n",
    "    def error(self):\n",
    "        return self._error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is basically, how models are defined in the TensorFlow codebase. However, there are some problems with it. Most notably, the whole graph is define in a single function, the constructor. This is neither particularly readable nor reusable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using properties"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just splitting the code into functions doesn’t work, since every time the functions are called, the graph would be extended by new code. Therefore, we have to ensure that the operations are added to the graph only when the function is called for the first time. This is basically lazy-loading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Model:\n",
    "\n",
    "    def __init__(self, data, target):\n",
    "        self.data = data\n",
    "        self.target = target\n",
    "        self._prediction = None\n",
    "        self._optimize = None\n",
    "        self._error = None\n",
    "\n",
    "    @property\n",
    "    def prediction(self):\n",
    "        if not self._prediction:\n",
    "            data_size = int(self.data.get_shape()[1])\n",
    "            target_size = int(self.target.get_shape()[1])\n",
    "            weight = tf.Variable(tf.truncated_normal([data_size, target_size]))\n",
    "            bias = tf.Variable(tf.constant(0.1, shape=[target_size]))\n",
    "            incoming = tf.matmul(self.data, weight) + bias\n",
    "            self._prediction = tf.nn.softmax(incoming)\n",
    "        return self._prediction\n",
    "\n",
    "    @property\n",
    "    def optimize(self):\n",
    "        if not self._optimize:\n",
    "            cross_entropy = -tf.reduce_sum(self.target, tf.log(self.prediction))\n",
    "            optimizer = tf.train.RMSPropOptimizer(0.03)\n",
    "            self._optimize = optimizer.minimize(cross_entropy)\n",
    "        return self._optimize\n",
    "\n",
    "    @property\n",
    "    def error(self):\n",
    "        if not self._error:\n",
    "            mistakes = tf.not_equal(\n",
    "                tf.argmax(self.target, 1), tf.argmax(self.prediction, 1))\n",
    "            self._error = tf.reduce_mean(tf.cast(mistakes, tf.float32))\n",
    "        return self._error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lazy propertydecorator\n",
    "We will use a decorator that behaves like @property but only evaluates the function once. It stores the result in a member named after the decorated function (prepended with a prefix) and returns this value on any subsequent calls. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import functools\n",
    "\n",
    "def lazy_property(function):\n",
    "    attribute = '_cache_' + function.__name__\n",
    "\n",
    "    @property\n",
    "    @functools.wraps(function)\n",
    "    def decorator(self):\n",
    "        if not hasattr(self, attribute):\n",
    "            setattr(self, attribute, function(self))\n",
    "        return getattr(self, attribute)\n",
    "\n",
    "    return decorator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Model:\n",
    "\n",
    "    def __init__(self, data, target):\n",
    "        self.data = data\n",
    "        self.target = target\n",
    "        self.prediction\n",
    "        self.optimize\n",
    "        self.error\n",
    "\n",
    "    @lazy_property\n",
    "    def prediction(self):\n",
    "        data_size = int(self.data.get_shape()[1])\n",
    "        target_size = int(self.target.get_shape()[1])\n",
    "        weight = tf.Variable(tf.truncated_normal([data_size, target_size]))\n",
    "        bias = tf.Variable(tf.constant(0.1, shape=[target_size]))\n",
    "        incoming = tf.matmul(self.data, weight) + bias\n",
    "        return tf.nn.softmax(incoming)\n",
    "\n",
    "    @lazy_property\n",
    "    def optimize(self):\n",
    "        cross_entropy = -tf.reduce_sum(self.target, tf.log(self.prediction))\n",
    "        optimizer = tf.train.RMSPropOptimizer(0.03)\n",
    "        return optimizer.minimize(cross_entropy)\n",
    "\n",
    "    @lazy_property\n",
    "    def error(self):\n",
    "        mistakes = tf.not_equal(\n",
    "            tf.argmax(self.target, 1), tf.argmax(self.prediction, 1))\n",
    "        return tf.reduce_mean(tf.cast(mistakes, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Organizing the graph with scopes\n",
    "The solution would be to wrap the content of each function by a with tf.name_scope('name') or with tf.variable_scope('name'). Nodes would then be grouped together in the graph. But we adjust our previous decorator to do that automatically:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import functools\n",
    "\n",
    "def define_scope(function):\n",
    "    attribute = '_cache_' + function.__name__\n",
    "\n",
    "    @property\n",
    "    @functools.wraps(function)\n",
    "    def decorator(self):\n",
    "        if not hasattr(self, attribute):\n",
    "            with tf.variable_scope(function.__name__):\n",
    "                setattr(self, attribute, function(self))\n",
    "        return getattr(self, attribute)\n",
    "\n",
    "    return decorator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could go even further an enable the @define_scope decorator to forward arguments to the tf.variable_scope(), for example to define a default initializer for the scope. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
