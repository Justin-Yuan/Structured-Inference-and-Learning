{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "total_series_length = 50000\n",
    "truncated_backprop_length = 15\n",
    "state_size = 4\n",
    "num_classes = 2\n",
    "echo_step = 3\n",
    "batch_size = 5\n",
    "num_batches = total_series_length//batch_size//truncated_backprop_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generateData():\n",
    "    x = np.array(np.random.choice(2, total_series_length, p=[0.5, 0.5]))\n",
    "    y = np.roll(x, echo_step)\n",
    "    y[0:echo_step] = 0\n",
    "\n",
    "    x = x.reshape((batch_size, -1))  # The first index changing slowest, subseries as rows\n",
    "    y = y.reshape((batch_size, -1))\n",
    "\n",
    "    return (x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batchX_placeholder = tf.placeholder(tf.float32, [batch_size, truncated_backprop_length])\n",
    "batchY_placeholder = tf.placeholder(tf.int32, [batch_size, truncated_backprop_length])\n",
    "\n",
    "init_state = tf.placeholder(tf.float32, [batch_size, state_size])\n",
    "\n",
    "W2 = tf.Variable(np.random.rand(state_size, num_classes),dtype=tf.float32)\n",
    "b2 = tf.Variable(np.zeros((1,num_classes)), dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "(5, 1)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Variable rnn/basic_rnn_cell/weights already exists, disallowed. Did you mean to set reuse=True in VarScope? Originally defined at:\n\n  File \"/Users/zhaocongyuan/anaconda3/lib/python3.5/site-packages/tensorflow/contrib/rnn/python/ops/core_rnn_cell_impl.py\", line 747, in _linear\n    \"weights\", [total_arg_size, output_size], dtype=dtype)\n  File \"/Users/zhaocongyuan/anaconda3/lib/python3.5/site-packages/tensorflow/contrib/rnn/python/ops/core_rnn_cell_impl.py\", line 64, in __call__\n    _linear([inputs, state], self._num_units, True, scope=scope))\n  File \"/Users/zhaocongyuan/anaconda3/lib/python3.5/site-packages/tensorflow/contrib/rnn/python/ops/core_rnn.py\", line 184, in <lambda>\n    call_cell = lambda: cell(input_, state)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-e1894a9844b2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Forward passes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mcell\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBasicRNNCell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mstates_series\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatic_rnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs_series\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/zhaocongyuan/anaconda3/lib/python3.5/site-packages/tensorflow/contrib/rnn/python/ops/core_rnn.py\u001b[0m in \u001b[0;36mstatic_rnn\u001b[0;34m(cell, inputs, initial_state, dtype, sequence_length, scope)\u001b[0m\n\u001b[1;32m    195\u001b[0m             state_size=cell.state_size)\n\u001b[1;32m    196\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m         \u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_cell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m       \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/zhaocongyuan/anaconda3/lib/python3.5/site-packages/tensorflow/contrib/rnn/python/ops/core_rnn.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    182\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mtime\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mvarscope\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreuse_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m       \u001b[0;31m# pylint: disable=cell-var-from-loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m       \u001b[0mcall_cell\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m       \u001b[0;31m# pylint: enable=cell-var-from-loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0msequence_length\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/zhaocongyuan/anaconda3/lib/python3.5/site-packages/tensorflow/contrib/rnn/python/ops/core_rnn_cell_impl.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, state, scope)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mvs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariable_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscope\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m\"basic_rnn_cell\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m       output = self._activation(\n\u001b[0;32m---> 64\u001b[0;31m           _linear([inputs, state], self._num_units, True, scope=scope))\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/zhaocongyuan/anaconda3/lib/python3.5/site-packages/tensorflow/contrib/rnn/python/ops/core_rnn_cell_impl.py\u001b[0m in \u001b[0;36m_linear\u001b[0;34m(args, output_size, bias, bias_start, scope)\u001b[0m\n\u001b[1;32m    745\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mvs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariable_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mouter_scope\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m     weights = vs.get_variable(\n\u001b[0;32m--> 747\u001b[0;31m         \"weights\", [total_arg_size, output_size], dtype=dtype)\n\u001b[0m\u001b[1;32m    748\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    749\u001b[0m       \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/zhaocongyuan/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[0;34m(name, shape, dtype, initializer, regularizer, trainable, collections, caching_device, partitioner, validate_shape, custom_getter)\u001b[0m\n\u001b[1;32m    986\u001b[0m       \u001b[0mcollections\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollections\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaching_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcaching_device\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    987\u001b[0m       \u001b[0mpartitioner\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpartitioner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 988\u001b[0;31m       custom_getter=custom_getter)\n\u001b[0m\u001b[1;32m    989\u001b[0m get_variable_or_local_docstring = (\n\u001b[1;32m    990\u001b[0m     \"\"\"%s\n",
      "\u001b[0;32m/Users/zhaocongyuan/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[0;34m(self, var_store, name, shape, dtype, initializer, regularizer, trainable, collections, caching_device, partitioner, validate_shape, custom_getter)\u001b[0m\n\u001b[1;32m    888\u001b[0m           \u001b[0mcollections\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollections\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaching_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcaching_device\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    889\u001b[0m           \u001b[0mpartitioner\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpartitioner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 890\u001b[0;31m           custom_getter=custom_getter)\n\u001b[0m\u001b[1;32m    891\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    892\u001b[0m   def _get_partitioned_variable(self,\n",
      "\u001b[0;32m/Users/zhaocongyuan/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, custom_getter)\u001b[0m\n\u001b[1;32m    346\u001b[0m           \u001b[0mreuse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreuse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollections\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m           \u001b[0mcaching_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcaching_device\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpartitioner\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpartitioner\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 348\u001b[0;31m           validate_shape=validate_shape)\n\u001b[0m\u001b[1;32m    349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m   def _get_partitioned_variable(\n",
      "\u001b[0;32m/Users/zhaocongyuan/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36m_true_getter\u001b[0;34m(name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape)\u001b[0m\n\u001b[1;32m    331\u001b[0m           \u001b[0minitializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregularizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mregularizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreuse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreuse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m           \u001b[0mtrainable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollections\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 333\u001b[0;31m           caching_device=caching_device, validate_shape=validate_shape)\n\u001b[0m\u001b[1;32m    334\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcustom_getter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/zhaocongyuan/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36m_get_single_variable\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, partition_info, reuse, trainable, collections, caching_device, validate_shape)\u001b[0m\n\u001b[1;32m    637\u001b[0m                          \u001b[0;34m\" Did you mean to set reuse=True in VarScope? \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    638\u001b[0m                          \"Originally defined at:\\n\\n%s\" % (\n\u001b[0;32m--> 639\u001b[0;31m                              name, \"\".join(traceback.format_list(tb))))\n\u001b[0m\u001b[1;32m    640\u001b[0m       \u001b[0mfound_var\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_vars\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_compatible_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfound_var\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Variable rnn/basic_rnn_cell/weights already exists, disallowed. Did you mean to set reuse=True in VarScope? Originally defined at:\n\n  File \"/Users/zhaocongyuan/anaconda3/lib/python3.5/site-packages/tensorflow/contrib/rnn/python/ops/core_rnn_cell_impl.py\", line 747, in _linear\n    \"weights\", [total_arg_size, output_size], dtype=dtype)\n  File \"/Users/zhaocongyuan/anaconda3/lib/python3.5/site-packages/tensorflow/contrib/rnn/python/ops/core_rnn_cell_impl.py\", line 64, in __call__\n    _linear([inputs, state], self._num_units, True, scope=scope))\n  File \"/Users/zhaocongyuan/anaconda3/lib/python3.5/site-packages/tensorflow/contrib/rnn/python/ops/core_rnn.py\", line 184, in <lambda>\n    call_cell = lambda: cell(input_, state)\n"
     ]
    }
   ],
   "source": [
    "# Unpack columns\n",
    "inputs_series = tf.split(batchX_placeholder, truncated_backprop_length, 1)\n",
    "labels_series = tf.unstack(batchY_placeholder, axis=1)\n",
    "print(len(inputs_series))\n",
    "print(inputs_series[0].shape)\n",
    "\n",
    "# Forward passes\n",
    "cell = tf.contrib.rnn.BasicRNNCell(state_size)\n",
    "states_series, current_state = tf.contrib.rnn.static_rnn(cell, inputs_series, init_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Variable rnn/basic_rnn_cell/weights/Adagrad/ already exists, disallowed. Did you mean to set reuse=True in VarScope? Originally defined at:\n\n  File \"<ipython-input-6-49d15f5bde77>\", line 7, in <module>\n    train_step = tf.train.AdagradOptimizer(0.3).minimize(total_loss)\n  File \"/Users/zhaocongyuan/anaconda3/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"/Users/zhaocongyuan/anaconda3/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-49d15f5bde77>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtotal_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mtrain_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdagradOptimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/zhaocongyuan/anaconda3/lib/python3.5/site-packages/tensorflow/python/training/optimizer.py\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(self, loss, global_step, var_list, gate_gradients, aggregation_method, colocate_gradients_with_ops, name, grad_loss)\u001b[0m\n\u001b[1;32m    296\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m     return self.apply_gradients(grads_and_vars, global_step=global_step,\n\u001b[0;32m--> 298\u001b[0;31m                                 name=name)\n\u001b[0m\u001b[1;32m    299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m   def compute_gradients(self, loss, var_list=None,\n",
      "\u001b[0;32m/Users/zhaocongyuan/anaconda3/lib/python3.5/site-packages/tensorflow/python/training/optimizer.py\u001b[0m in \u001b[0;36mapply_gradients\u001b[0;34m(self, grads_and_vars, global_step, name)\u001b[0m\n\u001b[1;32m    410\u001b[0m                        ([str(v) for _, _, v in converted_grads_and_vars],))\n\u001b[1;32m    411\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 412\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_slots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    413\u001b[0m     \u001b[0mupdate_ops\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/zhaocongyuan/anaconda3/lib/python3.5/site-packages/tensorflow/python/training/adagrad.py\u001b[0m in \u001b[0;36m_create_slots\u001b[0;34m(self, var_list)\u001b[0m\n\u001b[1;32m     64\u001b[0m                                    \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m                                    dtype=v.dtype.base_dtype)\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_or_make_slot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"accumulator\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_prepare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/zhaocongyuan/anaconda3/lib/python3.5/site-packages/tensorflow/python/training/optimizer.py\u001b[0m in \u001b[0;36m_get_or_make_slot\u001b[0;34m(self, var, val, slot_name, op_name)\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0mnamed_slots\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slot_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslot_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    638\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mvar\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnamed_slots\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 639\u001b[0;31m       \u001b[0mnamed_slots\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mslot_creator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_slot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    640\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnamed_slots\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/zhaocongyuan/anaconda3/lib/python3.5/site-packages/tensorflow/python/training/slot_creator.py\u001b[0m in \u001b[0;36mcreate_slot\u001b[0;34m(primary, val, name, colocate_with_primary)\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcolocate_with_primary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolocate_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_create_slot_var\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_create_slot_var\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/zhaocongyuan/anaconda3/lib/python3.5/site-packages/tensorflow/python/training/slot_creator.py\u001b[0m in \u001b[0;36m_create_slot_var\u001b[0;34m(primary, val, scope)\u001b[0m\n\u001b[1;32m     53\u001b[0m   \u001b[0mcurrent_partitioner\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvariable_scope\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_variable_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartitioner\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m   \u001b[0mvariable_scope\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_variable_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_partitioner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m   \u001b[0mslot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvariable_scope\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0mvariable_scope\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_variable_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_partitioner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_partitioner\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/zhaocongyuan/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[0;34m(name, shape, dtype, initializer, regularizer, trainable, collections, caching_device, partitioner, validate_shape, custom_getter)\u001b[0m\n\u001b[1;32m    986\u001b[0m       \u001b[0mcollections\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollections\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaching_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcaching_device\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    987\u001b[0m       \u001b[0mpartitioner\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpartitioner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 988\u001b[0;31m       custom_getter=custom_getter)\n\u001b[0m\u001b[1;32m    989\u001b[0m get_variable_or_local_docstring = (\n\u001b[1;32m    990\u001b[0m     \"\"\"%s\n",
      "\u001b[0;32m/Users/zhaocongyuan/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[0;34m(self, var_store, name, shape, dtype, initializer, regularizer, trainable, collections, caching_device, partitioner, validate_shape, custom_getter)\u001b[0m\n\u001b[1;32m    888\u001b[0m           \u001b[0mcollections\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollections\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaching_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcaching_device\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    889\u001b[0m           \u001b[0mpartitioner\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpartitioner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 890\u001b[0;31m           custom_getter=custom_getter)\n\u001b[0m\u001b[1;32m    891\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    892\u001b[0m   def _get_partitioned_variable(self,\n",
      "\u001b[0;32m/Users/zhaocongyuan/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, custom_getter)\u001b[0m\n\u001b[1;32m    346\u001b[0m           \u001b[0mreuse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreuse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollections\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m           \u001b[0mcaching_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcaching_device\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpartitioner\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpartitioner\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 348\u001b[0;31m           validate_shape=validate_shape)\n\u001b[0m\u001b[1;32m    349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m   def _get_partitioned_variable(\n",
      "\u001b[0;32m/Users/zhaocongyuan/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36m_true_getter\u001b[0;34m(name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape)\u001b[0m\n\u001b[1;32m    331\u001b[0m           \u001b[0minitializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregularizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mregularizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreuse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreuse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m           \u001b[0mtrainable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollections\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 333\u001b[0;31m           caching_device=caching_device, validate_shape=validate_shape)\n\u001b[0m\u001b[1;32m    334\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcustom_getter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/zhaocongyuan/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36m_get_single_variable\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, partition_info, reuse, trainable, collections, caching_device, validate_shape)\u001b[0m\n\u001b[1;32m    637\u001b[0m                          \u001b[0;34m\" Did you mean to set reuse=True in VarScope? \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    638\u001b[0m                          \"Originally defined at:\\n\\n%s\" % (\n\u001b[0;32m--> 639\u001b[0;31m                              name, \"\".join(traceback.format_list(tb))))\n\u001b[0m\u001b[1;32m    640\u001b[0m       \u001b[0mfound_var\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_vars\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_compatible_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfound_var\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Variable rnn/basic_rnn_cell/weights/Adagrad/ already exists, disallowed. Did you mean to set reuse=True in VarScope? Originally defined at:\n\n  File \"<ipython-input-6-49d15f5bde77>\", line 7, in <module>\n    train_step = tf.train.AdagradOptimizer(0.3).minimize(total_loss)\n  File \"/Users/zhaocongyuan/anaconda3/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"/Users/zhaocongyuan/anaconda3/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n"
     ]
    }
   ],
   "source": [
    "logits_series = [tf.matmul(state, W2) + b2 for state in states_series] #Broadcasted addition\n",
    "predictions_series = [tf.nn.softmax(logits) for logits in logits_series]\n",
    "\n",
    "losses = [tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=labels) for logits, labels in zip(logits_series,labels_series)]\n",
    "total_loss = tf.reduce_mean(losses)\n",
    "\n",
    "train_step = tf.train.AdagradOptimizer(0.3).minimize(total_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot(loss_list, predictions_series, batchX, batchY):\n",
    "    plt.subplot(2, 3, 1)\n",
    "    plt.cla()\n",
    "    plt.plot(loss_list)\n",
    "\n",
    "    for batch_series_idx in range(5):\n",
    "        one_hot_output_series = np.array(predictions_series)[:, batch_series_idx, :]\n",
    "        single_output_series = np.array([(1 if out[0] < 0.5 else 0) for out in one_hot_output_series])\n",
    "\n",
    "        plt.subplot(2, 3, batch_series_idx + 2)\n",
    "        plt.cla()\n",
    "        plt.axis([0, truncated_backprop_length, 0, 2])\n",
    "        left_offset = range(truncated_backprop_length)\n",
    "        plt.bar(left_offset, batchX[batch_series_idx, :], width=1, color=\"blue\")\n",
    "        plt.bar(left_offset, batchY[batch_series_idx, :] * 0.5, width=1, color=\"red\")\n",
    "        plt.bar(left_offset, single_output_series * 0.3, width=1, color=\"green\")\n",
    "\n",
    "    plt.draw()\n",
    "    plt.pause(0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-11-081f153bf0a5>:2: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11ae0a0b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New data, epoch 0\n",
      "Step 0 Loss 0.704498\n",
      "Step 100 Loss 0.0164675\n",
      "Step 200 Loss 0.00639236\n",
      "Step 300 Loss 0.00275861\n",
      "Step 400 Loss 0.00213916\n",
      "Step 500 Loss 0.00161558\n",
      "Step 600 Loss 0.00159877\n",
      "New data, epoch 1\n",
      "Step 0 Loss 0.130619\n",
      "Step 100 Loss 0.00173101\n",
      "Step 200 Loss 0.00129559\n",
      "Step 300 Loss 0.000977402\n",
      "Step 400 Loss 0.000867362\n",
      "Step 500 Loss 0.000877774\n",
      "Step 600 Loss 0.000751316\n",
      "New data, epoch 2\n",
      "Step 0 Loss 0.343625\n",
      "Step 100 Loss 0.000697004\n",
      "Step 200 Loss 0.000667205\n",
      "Step 300 Loss 0.000585871\n",
      "Step 400 Loss 0.000564076\n",
      "Step 500 Loss 0.000476239\n",
      "Step 600 Loss 0.00044136\n",
      "New data, epoch 3\n",
      "Step 0 Loss 0.138118\n",
      "Step 100 Loss 0.000469597\n",
      "Step 200 Loss 0.000457927\n",
      "Step 300 Loss 0.000383887\n",
      "Step 400 Loss 0.000384963\n",
      "Step 500 Loss 0.000355876\n",
      "Step 600 Loss 0.000334645\n",
      "New data, epoch 4\n",
      "Step 0 Loss 0.204329\n",
      "Step 100 Loss 0.000374702\n",
      "Step 200 Loss 0.000338772\n",
      "Step 300 Loss 0.000330902\n",
      "Step 400 Loss 0.000300096\n",
      "Step 500 Loss 0.000336676\n",
      "Step 600 Loss 0.000275236\n",
      "New data, epoch 5\n",
      "Step 0 Loss 0.289331\n",
      "Step 100 Loss 0.000354128\n",
      "Step 200 Loss 0.000295922\n",
      "Step 300 Loss 0.000270787\n",
      "Step 400 Loss 0.00022841\n",
      "Step 500 Loss 0.000249809\n",
      "Step 600 Loss 0.000239461\n",
      "New data, epoch 6\n",
      "Step 0 Loss 0.166404\n",
      "Step 100 Loss 0.0002176\n",
      "Step 200 Loss 0.000231835\n",
      "Step 300 Loss 0.000205044\n",
      "Step 400 Loss 0.000199979\n",
      "Step 500 Loss 0.000203999\n",
      "Step 600 Loss 0.000178367\n",
      "New data, epoch 7\n",
      "Step 0 Loss 0.229685\n",
      "Step 100 Loss 0.000219376\n",
      "Step 200 Loss 0.000192335\n",
      "Step 300 Loss 0.000202472\n",
      "Step 400 Loss 0.000205103\n",
      "Step 500 Loss 0.000187709\n",
      "Step 600 Loss 0.00019843\n",
      "New data, epoch 8\n",
      "Step 0 Loss 0.138009\n",
      "Step 100 Loss 0.000186187\n",
      "Step 200 Loss 0.000188698\n",
      "Step 300 Loss 0.000177605\n",
      "Step 400 Loss 0.000188009\n",
      "Step 500 Loss 0.000169384\n",
      "Step 600 Loss 0.000177309\n",
      "New data, epoch 9\n",
      "Step 0 Loss 0.298749\n",
      "Step 100 Loss 0.000158776\n",
      "Step 200 Loss 0.000146755\n",
      "Step 300 Loss 0.000134724\n",
      "Step 400 Loss 0.000150183\n",
      "Step 500 Loss 0.00014158\n",
      "Step 600 Loss 0.000141059\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCoCISEapAIiIZNT/B+358URGNbLsAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11ae16588>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.initialize_all_variables())\n",
    "    plt.ion()\n",
    "    plt.figure()\n",
    "    plt.show()\n",
    "    loss_list = []\n",
    "\n",
    "    for epoch_idx in range(num_epochs):\n",
    "        x,y = generateData()\n",
    "        _current_state = np.zeros((batch_size, state_size))\n",
    "\n",
    "\n",
    "        print(\"New data, epoch\", epoch_idx)\n",
    "\n",
    "        for batch_idx in range(num_batches):\n",
    "            start_idx = batch_idx * truncated_backprop_length\n",
    "            end_idx = start_idx + truncated_backprop_length\n",
    "\n",
    "            batchX = x[:,start_idx:end_idx]\n",
    "            batchY = y[:,start_idx:end_idx]\n",
    "\n",
    "            _total_loss, _train_step, _current_state, _predictions_series = sess.run(\n",
    "                [total_loss, train_step, current_state, predictions_series],\n",
    "                feed_dict={\n",
    "                    batchX_placeholder:batchX,\n",
    "                    batchY_placeholder:batchY,\n",
    "                    init_state:_current_state\n",
    "                })\n",
    "\n",
    "            loss_list.append(_total_loss)\n",
    "\n",
    "            if batch_idx%100 == 0:\n",
    "                print(\"Step\",batch_idx, \"Loss\", _total_loss)\n",
    "                plot(loss_list, _predictions_series, batchX, batchY)\n",
    "\n",
    "plt.ioff()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
