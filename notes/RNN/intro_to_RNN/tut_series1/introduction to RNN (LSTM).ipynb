{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_epochs = 100\n",
    "total_series_length = 50000\n",
    "truncated_backprop_length = 15\n",
    "state_size = 4\n",
    "num_classes = 2\n",
    "echo_step = 3\n",
    "batch_size = 5\n",
    "num_batches = total_series_length//batch_size//truncated_backprop_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generateData():\n",
    "    x = np.array(np.random.choice(2, total_series_length, p=[0.5, 0.5]))\n",
    "    y = np.roll(x, echo_step)\n",
    "    y[0:echo_step] = 0\n",
    "\n",
    "    x = x.reshape((batch_size, -1))  # The first index changing slowest, subseries as rows\n",
    "    y = y.reshape((batch_size, -1))\n",
    "\n",
    "    return (x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batchX_placeholder = tf.placeholder(tf.float32, [batch_size, truncated_backprop_length])\n",
    "batchY_placeholder = tf.placeholder(tf.int32, [batch_size, truncated_backprop_length])\n",
    "\n",
    "cell_state = tf.placeholder(tf.float32, [batch_size, state_size])\n",
    "hidden_state = tf.placeholder(tf.float32, [batch_size, state_size])\n",
    "init_state = tf.contrib.rnn.LSTMStateTuple(cell_state, hidden_state)\n",
    "\n",
    "W2 = tf.Variable(np.random.rand(state_size, num_classes),dtype=tf.float32)\n",
    "b2 = tf.Variable(np.zeros((1,num_classes)), dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Unpack columns\n",
    "inputs_series = tf.split(batchX_placeholder, truncated_backprop_length, 1)\n",
    "labels_series = tf.unstack(batchY_placeholder, axis=1)\n",
    "\n",
    "# Forward passes\n",
    "cell = tf.contrib.rnn.BasicLSTMCell(state_size, state_is_tuple=True)\n",
    "states_series, current_state = tf.contrib.rnn.static_rnn(cell, inputs_series, init_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "logits_series = [tf.matmul(state, W2) + b2 for state in states_series] #Broadcasted addition\n",
    "predictions_series = [tf.nn.softmax(logits) for logits in logits_series]\n",
    "\n",
    "losses = [tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=labels) for logits, labels in zip(logits_series,labels_series)]\n",
    "total_loss = tf.reduce_mean(losses)\n",
    "\n",
    "train_step = tf.train.AdagradOptimizer(0.3).minimize(total_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot(loss_list, predictions_series, batchX, batchY):\n",
    "    plt.subplot(2, 3, 1)\n",
    "    plt.cla()\n",
    "    plt.plot(loss_list)\n",
    "\n",
    "    for batch_series_idx in range(5):\n",
    "        one_hot_output_series = np.array(predictions_series)[:, batch_series_idx, :]\n",
    "        single_output_series = np.array([(1 if out[0] < 0.5 else 0) for out in one_hot_output_series])\n",
    "\n",
    "        plt.subplot(2, 3, batch_series_idx + 2)\n",
    "        plt.cla()\n",
    "        plt.axis([0, truncated_backprop_length, 0, 2])\n",
    "        left_offset = range(truncated_backprop_length)\n",
    "        plt.bar(left_offset, batchX[batch_series_idx, :], width=1, color=\"blue\")\n",
    "        plt.bar(left_offset, batchY[batch_series_idx, :] * 0.5, width=1, color=\"red\")\n",
    "        plt.bar(left_offset, single_output_series * 0.3, width=1, color=\"green\")\n",
    "\n",
    "    plt.draw()\n",
    "    plt.pause(0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-9-b1d67c5b27ea>:2: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11b3370f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New data, epoch 0\n",
      "Step 0 Batch loss 0.709135\n",
      "Step 100 Batch loss 0.520601\n",
      "Step 200 Batch loss 0.428233\n",
      "Step 300 Batch loss 0.365698\n",
      "Step 400 Batch loss 0.0179429\n",
      "Step 500 Batch loss 0.00834771\n",
      "Step 600 Batch loss 0.00575004\n",
      "New data, epoch 1\n",
      "Step 0 Batch loss 0.629686\n",
      "Step 100 Batch loss 0.00338771\n",
      "Step 200 Batch loss 0.00308497\n",
      "Step 300 Batch loss 0.00303276\n",
      "Step 400 Batch loss 0.00183209\n",
      "Step 500 Batch loss 0.00177152\n",
      "Step 600 Batch loss 0.00171834\n",
      "New data, epoch 2\n",
      "Step 0 Batch loss 0.540661\n",
      "Step 100 Batch loss 0.00194967\n",
      "Step 200 Batch loss 0.00146735\n",
      "Step 300 Batch loss 0.00131602\n",
      "Step 400 Batch loss 0.00113264\n",
      "Step 500 Batch loss 0.000944204\n",
      "Step 600 Batch loss 0.00111875\n",
      "New data, epoch 3\n",
      "Step 0 Batch loss 0.468308\n",
      "Step 100 Batch loss 0.00094576\n",
      "Step 200 Batch loss 0.000880749\n",
      "Step 300 Batch loss 0.000939516\n",
      "Step 400 Batch loss 0.000676153\n",
      "Step 500 Batch loss 0.000680783\n",
      "Step 600 Batch loss 0.000722903\n",
      "New data, epoch 4\n",
      "Step 0 Batch loss 0.635875\n",
      "Step 100 Batch loss 0.000674456\n",
      "Step 200 Batch loss 0.000657252\n",
      "Step 300 Batch loss 0.000597802\n",
      "Step 400 Batch loss 0.00061894\n",
      "Step 500 Batch loss 0.000731186\n",
      "Step 600 Batch loss 0.000589921\n",
      "New data, epoch 5\n",
      "Step 0 Batch loss 0.445983\n",
      "Step 100 Batch loss 0.000574134\n",
      "Step 200 Batch loss 0.000576562\n",
      "Step 300 Batch loss 0.000573485\n",
      "Step 400 Batch loss 0.000317088\n",
      "Step 500 Batch loss 0.000567115\n",
      "Step 600 Batch loss 0.0005078\n",
      "New data, epoch 6\n",
      "Step 0 Batch loss 0.780235\n",
      "Step 100 Batch loss 0.000536077\n",
      "Step 200 Batch loss 0.000374258\n",
      "Step 300 Batch loss 0.000530741\n",
      "Step 400 Batch loss 0.000486854\n",
      "Step 500 Batch loss 0.00034897\n",
      "Step 600 Batch loss 0.00034712\n",
      "New data, epoch 7\n",
      "Step 0 Batch loss 0.476701\n",
      "Step 100 Batch loss 0.000346327\n",
      "Step 200 Batch loss 0.000464864\n",
      "Step 300 Batch loss 0.000346777\n",
      "Step 400 Batch loss 0.000316843\n",
      "Step 500 Batch loss 0.000385248\n",
      "Step 600 Batch loss 0.000326825\n",
      "New data, epoch 8\n",
      "Step 0 Batch loss 0.573536\n",
      "Step 100 Batch loss 0.000354594\n",
      "Step 200 Batch loss 0.00041271\n",
      "Step 300 Batch loss 0.000331933\n",
      "Step 400 Batch loss 0.000359712\n",
      "Step 500 Batch loss 0.000335323\n",
      "Step 600 Batch loss 0.000270466\n",
      "New data, epoch 9\n",
      "Step 0 Batch loss 0.875238\n",
      "Step 100 Batch loss 0.000341143\n",
      "Step 200 Batch loss 0.000325907\n",
      "Step 300 Batch loss 0.000271631\n",
      "Step 400 Batch loss 0.000305253\n",
      "Step 500 Batch loss 0.000277069\n",
      "Step 600 Batch loss 0.000276752\n",
      "New data, epoch 10\n",
      "Step 0 Batch loss 0.483741\n",
      "Step 100 Batch loss 0.000298927\n",
      "Step 200 Batch loss 0.000234392\n",
      "Step 300 Batch loss 0.000232199\n",
      "Step 400 Batch loss 0.000234271\n",
      "Step 500 Batch loss 0.000295544\n",
      "Step 600 Batch loss 0.00025319\n",
      "New data, epoch 11\n",
      "Step 0 Batch loss 0.272107\n",
      "Step 100 Batch loss 0.000254901\n",
      "Step 200 Batch loss 0.000216005\n",
      "Step 300 Batch loss 0.0002434\n",
      "Step 400 Batch loss 0.0001986\n",
      "Step 500 Batch loss 0.000264125\n",
      "Step 600 Batch loss 0.000210719\n",
      "New data, epoch 12\n",
      "Step 0 Batch loss 0.579217\n",
      "Step 100 Batch loss 0.000260797\n",
      "Step 200 Batch loss 0.000234171\n",
      "Step 300 Batch loss 0.000207023\n",
      "Step 400 Batch loss 0.000206402\n",
      "Step 500 Batch loss 0.00024827\n",
      "Step 600 Batch loss 0.000214494\n",
      "New data, epoch 13\n",
      "Step 0 Batch loss 0.5729\n",
      "Step 100 Batch loss 0.000261013\n",
      "Step 200 Batch loss 0.000249361\n",
      "Step 300 Batch loss 0.000179663\n",
      "Step 400 Batch loss 0.000157939\n",
      "Step 500 Batch loss 0.000239286\n",
      "Step 600 Batch loss 0.000176502\n",
      "New data, epoch 14\n",
      "Step 0 Batch loss 0.40346\n",
      "Step 100 Batch loss 0.000187428\n",
      "Step 200 Batch loss 0.00017474\n",
      "Step 300 Batch loss 0.000238103\n",
      "Step 400 Batch loss 0.000205897\n",
      "Step 500 Batch loss 0.000171597\n",
      "Step 600 Batch loss 0.000209386\n",
      "New data, epoch 15\n",
      "Step 0 Batch loss 0.621092\n",
      "Step 100 Batch loss 0.000244795\n",
      "Step 200 Batch loss 0.000202309\n",
      "Step 300 Batch loss 0.000262091\n",
      "Step 400 Batch loss 0.000222908\n",
      "Step 500 Batch loss 0.000213875\n",
      "Step 600 Batch loss 0.000171082\n",
      "New data, epoch 16\n",
      "Step 0 Batch loss 0.669048\n",
      "Step 100 Batch loss 0.000179161\n",
      "Step 200 Batch loss 0.000196316\n",
      "Step 300 Batch loss 0.000209478\n",
      "Step 400 Batch loss 0.000164318\n",
      "Step 500 Batch loss 0.000159303\n",
      "Step 600 Batch loss 0.000199369\n",
      "New data, epoch 17\n",
      "Step 0 Batch loss 0.220236\n",
      "Step 100 Batch loss 0.000213226\n",
      "Step 200 Batch loss 0.000207793\n",
      "Step 300 Batch loss 0.000174975\n",
      "Step 400 Batch loss 0.000212314\n",
      "Step 500 Batch loss 0.000208992\n",
      "Step 600 Batch loss 0.000190286\n",
      "New data, epoch 18\n",
      "Step 0 Batch loss 0.397652\n",
      "Step 100 Batch loss 0.000199123\n",
      "Step 200 Batch loss 0.000194674\n",
      "Step 300 Batch loss 0.000156878\n",
      "Step 400 Batch loss 0.000183831\n",
      "Step 500 Batch loss 0.000192205\n",
      "Step 600 Batch loss 0.000184178\n",
      "New data, epoch 19\n",
      "Step 0 Batch loss 0.353505\n",
      "Step 100 Batch loss 0.00018991\n",
      "Step 200 Batch loss 0.000211651\n",
      "Step 300 Batch loss 0.000204011\n",
      "Step 400 Batch loss 0.000209704\n",
      "Step 500 Batch loss 0.000175043\n",
      "Step 600 Batch loss 0.000132243\n",
      "New data, epoch 20\n",
      "Step 0 Batch loss 0.376371\n",
      "Step 100 Batch loss 0.000290845\n",
      "Step 200 Batch loss 0.000207229\n",
      "Step 300 Batch loss 0.000183265\n",
      "Step 400 Batch loss 0.000155336\n",
      "Step 500 Batch loss 0.000184784\n",
      "Step 600 Batch loss 0.000181588\n",
      "New data, epoch 21\n",
      "Step 0 Batch loss 0.570051\n",
      "Step 100 Batch loss 0.000193973\n",
      "Step 200 Batch loss 0.00019388\n",
      "Step 300 Batch loss 0.000183922\n",
      "Step 400 Batch loss 0.000141434\n",
      "Step 500 Batch loss 0.00012851\n",
      "Step 600 Batch loss 0.00015636\n",
      "New data, epoch 22\n",
      "Step 0 Batch loss 0.337211\n",
      "Step 100 Batch loss 0.000184955\n",
      "Step 200 Batch loss 0.000138587\n",
      "Step 300 Batch loss 0.000148262\n",
      "Step 400 Batch loss 9.94847e-05\n",
      "Step 500 Batch loss 0.000126008\n",
      "Step 600 Batch loss 0.000123114\n",
      "New data, epoch 23\n",
      "Step 0 Batch loss 0.595919\n",
      "Step 100 Batch loss 0.000157065\n",
      "Step 200 Batch loss 0.000122724\n",
      "Step 300 Batch loss 0.000137978\n",
      "Step 400 Batch loss 0.00012139\n",
      "Step 500 Batch loss 0.000111701\n",
      "Step 600 Batch loss 0.000130813\n",
      "New data, epoch 24\n",
      "Step 0 Batch loss 0.367065\n",
      "Step 100 Batch loss 0.000185262\n",
      "Step 200 Batch loss 0.000192536\n",
      "Step 300 Batch loss 0.000159569\n",
      "Step 400 Batch loss 0.000167167\n",
      "Step 500 Batch loss 0.000148361\n",
      "Step 600 Batch loss 0.000117272\n",
      "New data, epoch 25\n",
      "Step 0 Batch loss 0.38022\n",
      "Step 100 Batch loss 0.000137664\n",
      "Step 200 Batch loss 0.000138673\n",
      "Step 300 Batch loss 0.000145929\n",
      "Step 400 Batch loss 9.45448e-05\n",
      "Step 500 Batch loss 0.000120309\n",
      "Step 600 Batch loss 0.00013758\n",
      "New data, epoch 26\n",
      "Step 0 Batch loss 0.257066\n",
      "Step 100 Batch loss 0.00012996\n",
      "Step 200 Batch loss 0.000120582\n",
      "Step 300 Batch loss 0.000132756\n",
      "Step 400 Batch loss 0.000120989\n",
      "Step 500 Batch loss 0.000131466\n",
      "Step 600 Batch loss 0.000102156\n",
      "New data, epoch 27\n",
      "Step 0 Batch loss 0.205348\n",
      "Step 100 Batch loss 0.00016306\n",
      "Step 200 Batch loss 0.000166735\n",
      "Step 300 Batch loss 0.00010454\n",
      "Step 400 Batch loss 0.000115094\n",
      "Step 500 Batch loss 0.00013007\n",
      "Step 600 Batch loss 9.50873e-05\n",
      "New data, epoch 28\n",
      "Step 0 Batch loss 0.519674\n",
      "Step 100 Batch loss 0.000192243\n",
      "Step 200 Batch loss 0.000128443\n",
      "Step 300 Batch loss 0.000178589\n",
      "Step 400 Batch loss 0.000182451\n",
      "Step 500 Batch loss 0.000124181\n",
      "Step 600 Batch loss 0.00010651\n",
      "New data, epoch 29\n",
      "Step 0 Batch loss 0.517898\n",
      "Step 100 Batch loss 0.000178251\n",
      "Step 200 Batch loss 0.000211426\n",
      "Step 300 Batch loss 0.000136045\n",
      "Step 400 Batch loss 0.000143976\n",
      "Step 500 Batch loss 0.000110222\n",
      "Step 600 Batch loss 0.000139695\n",
      "New data, epoch 30\n",
      "Step 0 Batch loss 0.294914\n",
      "Step 100 Batch loss 0.000170332\n",
      "Step 200 Batch loss 0.00014833\n",
      "Step 300 Batch loss 0.000142538\n",
      "Step 400 Batch loss 0.000125682\n",
      "Step 500 Batch loss 0.000109564\n",
      "Step 600 Batch loss 0.000119528\n",
      "New data, epoch 31\n",
      "Step 0 Batch loss 0.358271\n",
      "Step 100 Batch loss 0.000123934\n",
      "Step 200 Batch loss 0.000132395\n",
      "Step 300 Batch loss 0.000110777\n",
      "Step 400 Batch loss 9.88153e-05\n",
      "Step 500 Batch loss 0.00011738\n",
      "Step 600 Batch loss 0.000106066\n",
      "New data, epoch 32\n",
      "Step 0 Batch loss 0.119076\n",
      "Step 100 Batch loss 0.000120339\n",
      "Step 200 Batch loss 9.66356e-05\n",
      "Step 300 Batch loss 0.00010703\n",
      "Step 400 Batch loss 0.000101936\n",
      "Step 500 Batch loss 8.63371e-05\n",
      "Step 600 Batch loss 0.000109298\n",
      "New data, epoch 33\n",
      "Step 0 Batch loss 0.261577\n",
      "Step 100 Batch loss 0.000121497\n",
      "Step 200 Batch loss 0.000101925\n",
      "Step 300 Batch loss 0.000123702\n",
      "Step 400 Batch loss 9.03065e-05\n",
      "Step 500 Batch loss 8.73602e-05\n",
      "Step 600 Batch loss 8.57208e-05\n",
      "New data, epoch 34\n",
      "Step 0 Batch loss 0.270599\n",
      "Step 100 Batch loss 0.000107459\n",
      "Step 200 Batch loss 0.000122458\n",
      "Step 300 Batch loss 0.000104312\n",
      "Step 400 Batch loss 0.000107861\n",
      "Step 500 Batch loss 8.87942e-05\n",
      "Step 600 Batch loss 0.000110499\n",
      "New data, epoch 35\n",
      "Step 0 Batch loss 0.461564\n",
      "Step 100 Batch loss 0.000105628\n",
      "Step 200 Batch loss 9.46628e-05\n",
      "Step 300 Batch loss 0.000118502\n",
      "Step 400 Batch loss 0.00010572\n",
      "Step 500 Batch loss 0.000101453\n",
      "Step 600 Batch loss 8.53278e-05\n",
      "New data, epoch 36\n",
      "Step 0 Batch loss 0.303861\n",
      "Step 100 Batch loss 0.000194436\n",
      "Step 200 Batch loss 0.000132819\n",
      "Step 300 Batch loss 0.000111299\n",
      "Step 400 Batch loss 8.78536e-05\n",
      "Step 500 Batch loss 9.43926e-05\n",
      "Step 600 Batch loss 9.58385e-05\n",
      "New data, epoch 37\n",
      "Step 0 Batch loss 0.474697\n",
      "Step 100 Batch loss 8.89704e-05\n",
      "Step 200 Batch loss 0.000103886\n",
      "Step 300 Batch loss 8.82016e-05\n",
      "Step 400 Batch loss 0.000100626\n",
      "Step 500 Batch loss 9.40939e-05\n",
      "Step 600 Batch loss 9.76814e-05\n",
      "New data, epoch 38\n",
      "Step 0 Batch loss 0.433595\n",
      "Step 100 Batch loss 0.000141872\n",
      "Step 200 Batch loss 0.00011449\n",
      "Step 300 Batch loss 8.44436e-05\n",
      "Step 400 Batch loss 0.000103356\n",
      "Step 500 Batch loss 0.000100201\n",
      "Step 600 Batch loss 9.36534e-05\n",
      "New data, epoch 39\n",
      "Step 0 Batch loss 0.416955\n",
      "Step 100 Batch loss 0.000142269\n",
      "Step 200 Batch loss 0.000115775\n",
      "Step 300 Batch loss 0.000107532\n",
      "Step 400 Batch loss 8.28195e-05\n",
      "Step 500 Batch loss 7.6923e-05\n",
      "Step 600 Batch loss 8.80418e-05\n",
      "New data, epoch 40\n",
      "Step 0 Batch loss 0.513854\n",
      "Step 100 Batch loss 0.000142271\n",
      "Step 200 Batch loss 0.000124998\n",
      "Step 300 Batch loss 0.000113546\n",
      "Step 400 Batch loss 9.01013e-05\n",
      "Step 500 Batch loss 9.37662e-05\n",
      "Step 600 Batch loss 8.39604e-05\n",
      "New data, epoch 41\n",
      "Step 0 Batch loss 0.209124\n",
      "Step 100 Batch loss 0.000122604\n",
      "Step 200 Batch loss 0.000122447\n",
      "Step 300 Batch loss 0.000111507\n",
      "Step 400 Batch loss 9.09783e-05\n",
      "Step 500 Batch loss 9.92489e-05\n",
      "Step 600 Batch loss 0.000107807\n",
      "New data, epoch 42\n",
      "Step 0 Batch loss 0.352262\n",
      "Step 100 Batch loss 0.000117252\n",
      "Step 200 Batch loss 7.921e-05\n",
      "Step 300 Batch loss 8.10923e-05\n",
      "Step 400 Batch loss 0.000101468\n",
      "Step 500 Batch loss 7.65586e-05\n",
      "Step 600 Batch loss 8.71266e-05\n",
      "New data, epoch 43\n",
      "Step 0 Batch loss 0.316842\n",
      "Step 100 Batch loss 9.66016e-05\n",
      "Step 200 Batch loss 8.28106e-05\n",
      "Step 300 Batch loss 8.90882e-05\n",
      "Step 400 Batch loss 7.96399e-05\n",
      "Step 500 Batch loss 8.87115e-05\n",
      "Step 600 Batch loss 9.89517e-05\n",
      "New data, epoch 44\n",
      "Step 0 Batch loss 0.552449\n",
      "Step 100 Batch loss 0.000144941\n",
      "Step 200 Batch loss 0.000111297\n",
      "Step 300 Batch loss 9.51987e-05\n",
      "Step 400 Batch loss 9.74061e-05\n",
      "Step 500 Batch loss 7.86266e-05\n",
      "Step 600 Batch loss 7.8563e-05\n",
      "New data, epoch 45\n",
      "Step 0 Batch loss 0.267177\n",
      "Step 100 Batch loss 9.3026e-05\n",
      "Step 200 Batch loss 0.000112977\n",
      "Step 300 Batch loss 9.14576e-05\n",
      "Step 400 Batch loss 8.03772e-05\n",
      "Step 500 Batch loss 8.30398e-05\n",
      "Step 600 Batch loss 7.58714e-05\n",
      "New data, epoch 46\n",
      "Step 0 Batch loss 0.349424\n",
      "Step 100 Batch loss 9.18021e-05\n",
      "Step 200 Batch loss 9.99094e-05\n",
      "Step 300 Batch loss 8.88229e-05\n",
      "Step 400 Batch loss 9.67815e-05\n",
      "Step 500 Batch loss 9.48763e-05\n",
      "Step 600 Batch loss 8.86471e-05\n",
      "New data, epoch 47\n",
      "Step 0 Batch loss 0.32558\n",
      "Step 100 Batch loss 0.0001186\n",
      "Step 200 Batch loss 0.000104132\n",
      "Step 300 Batch loss 0.000101296\n",
      "Step 400 Batch loss 9.13896e-05\n",
      "Step 500 Batch loss 8.2619e-05\n",
      "Step 600 Batch loss 9.21485e-05\n",
      "New data, epoch 48\n",
      "Step 0 Batch loss 0.432862\n",
      "Step 100 Batch loss 0.000131406\n",
      "Step 200 Batch loss 0.00013062\n",
      "Step 300 Batch loss 0.000107662\n",
      "Step 400 Batch loss 0.000103938\n",
      "Step 500 Batch loss 0.000105014\n",
      "Step 600 Batch loss 0.000106167\n",
      "New data, epoch 49\n",
      "Step 0 Batch loss 0.281127\n",
      "Step 100 Batch loss 0.000336519\n",
      "Step 200 Batch loss 0.000285011\n",
      "Step 300 Batch loss 0.000219489\n",
      "Step 400 Batch loss 0.000154507\n",
      "Step 500 Batch loss 0.000150521\n",
      "Step 600 Batch loss 0.000117828\n",
      "New data, epoch 50\n",
      "Step 0 Batch loss 0.259178\n",
      "Step 100 Batch loss 0.000135064\n",
      "Step 200 Batch loss 0.000146371\n",
      "Step 300 Batch loss 0.000123017\n",
      "Step 400 Batch loss 8.90637e-05\n",
      "Step 500 Batch loss 9.2166e-05\n",
      "Step 600 Batch loss 9.87654e-05\n",
      "New data, epoch 51\n",
      "Step 0 Batch loss 0.477752\n",
      "Step 100 Batch loss 0.000139749\n",
      "Step 200 Batch loss 0.00012709\n",
      "Step 300 Batch loss 0.000111822\n",
      "Step 400 Batch loss 0.000120406\n",
      "Step 500 Batch loss 0.000105488\n",
      "Step 600 Batch loss 9.20551e-05\n",
      "New data, epoch 52\n",
      "Step 0 Batch loss 0.433839\n",
      "Step 100 Batch loss 0.000109427\n",
      "Step 200 Batch loss 0.000112969\n",
      "Step 300 Batch loss 0.000128549\n",
      "Step 400 Batch loss 9.99734e-05\n",
      "Step 500 Batch loss 8.78031e-05\n",
      "Step 600 Batch loss 7.83301e-05\n",
      "New data, epoch 53\n",
      "Step 0 Batch loss 0.415519\n",
      "Step 100 Batch loss 0.000154017\n",
      "Step 200 Batch loss 0.000115497\n",
      "Step 300 Batch loss 0.000112778\n",
      "Step 400 Batch loss 9.75248e-05\n",
      "Step 500 Batch loss 8.06552e-05\n",
      "Step 600 Batch loss 8.65274e-05\n",
      "New data, epoch 54\n",
      "Step 0 Batch loss 0.227521\n",
      "Step 100 Batch loss 9.73498e-05\n",
      "Step 200 Batch loss 8.19178e-05\n",
      "Step 300 Batch loss 8.62918e-05\n",
      "Step 400 Batch loss 8.20519e-05\n",
      "Step 500 Batch loss 8.21217e-05\n",
      "Step 600 Batch loss 8.59151e-05\n",
      "New data, epoch 55\n",
      "Step 0 Batch loss 0.357288\n",
      "Step 100 Batch loss 9.94102e-05\n",
      "Step 200 Batch loss 0.000101932\n",
      "Step 300 Batch loss 8.03584e-05\n",
      "Step 400 Batch loss 8.58947e-05\n",
      "Step 500 Batch loss 7.87138e-05\n",
      "Step 600 Batch loss 8.26832e-05\n",
      "New data, epoch 56\n",
      "Step 0 Batch loss 0.701912\n",
      "Step 100 Batch loss 0.000124607\n",
      "Step 200 Batch loss 9.77211e-05\n",
      "Step 300 Batch loss 8.46234e-05\n",
      "Step 400 Batch loss 0.000103145\n",
      "Step 500 Batch loss 8.94812e-05\n",
      "Step 600 Batch loss 8.59037e-05\n",
      "New data, epoch 57\n",
      "Step 0 Batch loss 0.448573\n",
      "Step 100 Batch loss 0.000132007\n",
      "Step 200 Batch loss 0.000105269\n",
      "Step 300 Batch loss 8.0333e-05\n",
      "Step 400 Batch loss 0.000102813\n",
      "Step 500 Batch loss 8.4065e-05\n",
      "Step 600 Batch loss 9.67262e-05\n",
      "New data, epoch 58\n",
      "Step 0 Batch loss 0.171629\n",
      "Step 100 Batch loss 0.000141848\n",
      "Step 200 Batch loss 0.000102197\n",
      "Step 300 Batch loss 9.31689e-05\n",
      "Step 400 Batch loss 8.41382e-05\n",
      "Step 500 Batch loss 8.64803e-05\n",
      "Step 600 Batch loss 7.68876e-05\n",
      "New data, epoch 59\n",
      "Step 0 Batch loss 0.281187\n",
      "Step 100 Batch loss 6.54563e-05\n",
      "Step 200 Batch loss 8.58747e-05\n",
      "Step 300 Batch loss 8.48729e-05\n",
      "Step 400 Batch loss 7.80261e-05\n",
      "Step 500 Batch loss 7.62668e-05\n",
      "Step 600 Batch loss 7.82742e-05\n",
      "New data, epoch 60\n",
      "Step 0 Batch loss 0.313361\n",
      "Step 100 Batch loss 8.02768e-05\n",
      "Step 200 Batch loss 8.28071e-05\n",
      "Step 300 Batch loss 7.87692e-05\n",
      "Step 400 Batch loss 8.04752e-05\n",
      "Step 500 Batch loss 7.42531e-05\n",
      "Step 600 Batch loss 7.59429e-05\n",
      "New data, epoch 61\n",
      "Step 0 Batch loss 0.302226\n",
      "Step 100 Batch loss 0.000150956\n",
      "Step 200 Batch loss 8.76036e-05\n",
      "Step 300 Batch loss 7.77685e-05\n",
      "Step 400 Batch loss 7.23619e-05\n",
      "Step 500 Batch loss 7.71873e-05\n",
      "Step 600 Batch loss 7.32962e-05\n",
      "New data, epoch 62\n",
      "Step 0 Batch loss 0.141879\n",
      "Step 100 Batch loss 8.38499e-05\n",
      "Step 200 Batch loss 8.74766e-05\n",
      "Step 300 Batch loss 7.07954e-05\n",
      "Step 400 Batch loss 6.19442e-05\n",
      "Step 500 Batch loss 7.06045e-05\n",
      "Step 600 Batch loss 7.18325e-05\n",
      "New data, epoch 63\n",
      "Step 0 Batch loss 0.27559\n",
      "Step 100 Batch loss 0.000145004\n",
      "Step 200 Batch loss 8.25515e-05\n",
      "Step 300 Batch loss 6.54629e-05\n",
      "Step 400 Batch loss 8.21821e-05\n",
      "Step 500 Batch loss 6.49905e-05\n",
      "Step 600 Batch loss 6.62639e-05\n",
      "New data, epoch 64\n",
      "Step 0 Batch loss 0.335461\n",
      "Step 100 Batch loss 6.06822e-05\n",
      "Step 200 Batch loss 7.29775e-05\n",
      "Step 300 Batch loss 6.48876e-05\n",
      "Step 400 Batch loss 7.49545e-05\n",
      "Step 500 Batch loss 6.23151e-05\n",
      "Step 600 Batch loss 6.91664e-05\n",
      "New data, epoch 65\n",
      "Step 0 Batch loss 0.37561\n",
      "Step 100 Batch loss 9.12286e-05\n",
      "Step 200 Batch loss 8.75371e-05\n",
      "Step 300 Batch loss 8.14405e-05\n",
      "Step 400 Batch loss 7.30491e-05\n",
      "Step 500 Batch loss 8.01625e-05\n",
      "Step 600 Batch loss 5.7942e-05\n",
      "New data, epoch 66\n",
      "Step 0 Batch loss 0.296993\n",
      "Step 100 Batch loss 0.000135984\n",
      "Step 200 Batch loss 8.57148e-05\n",
      "Step 300 Batch loss 7.00553e-05\n",
      "Step 400 Batch loss 7.56635e-05\n",
      "Step 500 Batch loss 7.22332e-05\n",
      "Step 600 Batch loss 6.87925e-05\n",
      "New data, epoch 67\n",
      "Step 0 Batch loss 0.543355\n",
      "Step 100 Batch loss 0.000129528\n",
      "Step 200 Batch loss 0.000122661\n",
      "Step 300 Batch loss 8.37869e-05\n",
      "Step 400 Batch loss 8.54064e-05\n",
      "Step 500 Batch loss 8.74359e-05\n",
      "Step 600 Batch loss 8.27003e-05\n",
      "New data, epoch 68\n",
      "Step 0 Batch loss 0.388504\n",
      "Step 100 Batch loss 0.000125665\n",
      "Step 200 Batch loss 0.000106427\n",
      "Step 300 Batch loss 0.00010213\n",
      "Step 400 Batch loss 0.000101329\n",
      "Step 500 Batch loss 8.21596e-05\n",
      "Step 600 Batch loss 7.54941e-05\n",
      "New data, epoch 69\n",
      "Step 0 Batch loss 0.161791\n",
      "Step 100 Batch loss 8.31301e-05\n",
      "Step 200 Batch loss 9.76534e-05\n",
      "Step 300 Batch loss 7.22256e-05\n",
      "Step 400 Batch loss 8.32843e-05\n",
      "Step 500 Batch loss 6.48503e-05\n",
      "Step 600 Batch loss 5.92751e-05\n",
      "New data, epoch 70\n",
      "Step 0 Batch loss 0.452036\n",
      "Step 100 Batch loss 0.000126891\n",
      "Step 200 Batch loss 0.000114795\n",
      "Step 300 Batch loss 0.000103532\n",
      "Step 400 Batch loss 0.000101542\n",
      "Step 500 Batch loss 9.56007e-05\n",
      "Step 600 Batch loss 8.82569e-05\n",
      "New data, epoch 71\n",
      "Step 0 Batch loss 0.404058\n",
      "Step 100 Batch loss 0.00011456\n",
      "Step 200 Batch loss 0.000119848\n",
      "Step 300 Batch loss 0.000103086\n",
      "Step 400 Batch loss 9.2597e-05\n",
      "Step 500 Batch loss 9.2114e-05\n",
      "Step 600 Batch loss 8.724e-05\n",
      "New data, epoch 72\n",
      "Step 0 Batch loss 0.28179\n",
      "Step 100 Batch loss 0.000167726\n",
      "Step 200 Batch loss 9.03438e-05\n",
      "Step 300 Batch loss 6.65126e-05\n",
      "Step 400 Batch loss 7.39167e-05\n",
      "Step 500 Batch loss 8.80507e-05\n",
      "Step 600 Batch loss 7.68557e-05\n",
      "New data, epoch 73\n",
      "Step 0 Batch loss 0.30983\n",
      "Step 100 Batch loss 9.42876e-05\n",
      "Step 200 Batch loss 0.000105422\n",
      "Step 300 Batch loss 8.5301e-05\n",
      "Step 400 Batch loss 9.34673e-05\n",
      "Step 500 Batch loss 7.92175e-05\n",
      "Step 600 Batch loss 7.80372e-05\n",
      "New data, epoch 74\n",
      "Step 0 Batch loss 0.230532\n",
      "Step 100 Batch loss 8.12159e-05\n",
      "Step 200 Batch loss 7.42296e-05\n",
      "Step 300 Batch loss 7.01211e-05\n",
      "Step 400 Batch loss 7.79518e-05\n",
      "Step 500 Batch loss 6.63151e-05\n",
      "Step 600 Batch loss 8.34676e-05\n",
      "New data, epoch 75\n",
      "Step 0 Batch loss 0.174469\n",
      "Step 100 Batch loss 7.00304e-05\n",
      "Step 200 Batch loss 7.25735e-05\n",
      "Step 300 Batch loss 7.08501e-05\n",
      "Step 400 Batch loss 7.70508e-05\n",
      "Step 500 Batch loss 7.21066e-05\n",
      "Step 600 Batch loss 5.95319e-05\n",
      "New data, epoch 76\n",
      "Step 0 Batch loss 0.146626\n",
      "Step 100 Batch loss 7.29023e-05\n",
      "Step 200 Batch loss 7.02048e-05\n",
      "Step 300 Batch loss 6.75928e-05\n",
      "Step 400 Batch loss 5.93917e-05\n",
      "Step 500 Batch loss 4.85858e-05\n",
      "Step 600 Batch loss 6.05997e-05\n",
      "New data, epoch 77\n",
      "Step 0 Batch loss 0.220507\n",
      "Step 100 Batch loss 8.29913e-05\n",
      "Step 200 Batch loss 6.71469e-05\n",
      "Step 300 Batch loss 7.35476e-05\n",
      "Step 400 Batch loss 4.95807e-05\n",
      "Step 500 Batch loss 5.92534e-05\n",
      "Step 600 Batch loss 5.98845e-05\n",
      "New data, epoch 78\n",
      "Step 0 Batch loss 0.185859\n",
      "Step 100 Batch loss 7.20933e-05\n",
      "Step 200 Batch loss 6.43543e-05\n",
      "Step 300 Batch loss 5.86241e-05\n",
      "Step 400 Batch loss 7.24493e-05\n",
      "Step 500 Batch loss 5.48254e-05\n",
      "Step 600 Batch loss 5.9635e-05\n",
      "New data, epoch 79\n",
      "Step 0 Batch loss 0.288984\n",
      "Step 100 Batch loss 5.89779e-05\n",
      "Step 200 Batch loss 5.67741e-05\n",
      "Step 300 Batch loss 5.88293e-05\n",
      "Step 400 Batch loss 5.67808e-05\n",
      "Step 500 Batch loss 5.93099e-05\n",
      "Step 600 Batch loss 5.72163e-05\n",
      "New data, epoch 80\n",
      "Step 0 Batch loss 0.256993\n",
      "Step 100 Batch loss 5.94344e-05\n",
      "Step 200 Batch loss 6.70602e-05\n",
      "Step 300 Batch loss 6.40527e-05\n",
      "Step 400 Batch loss 5.60546e-05\n",
      "Step 500 Batch loss 5.97892e-05\n",
      "Step 600 Batch loss 5.26818e-05\n",
      "New data, epoch 81\n",
      "Step 0 Batch loss 0.205442\n",
      "Step 100 Batch loss 6.09513e-05\n",
      "Step 200 Batch loss 5.21383e-05\n",
      "Step 300 Batch loss 6.62754e-05\n",
      "Step 400 Batch loss 5.85941e-05\n",
      "Step 500 Batch loss 5.08733e-05\n",
      "Step 600 Batch loss 5.65316e-05\n",
      "New data, epoch 82\n",
      "Step 0 Batch loss 0.200489\n",
      "Step 100 Batch loss 5.23307e-05\n",
      "Step 200 Batch loss 5.99243e-05\n",
      "Step 300 Batch loss 5.37689e-05\n",
      "Step 400 Batch loss 6.26565e-05\n",
      "Step 500 Batch loss 4.96398e-05\n",
      "Step 600 Batch loss 4.73894e-05\n",
      "New data, epoch 83\n",
      "Step 0 Batch loss 0.184116\n",
      "Step 100 Batch loss 6.95272e-05\n",
      "Step 200 Batch loss 7.34644e-05\n",
      "Step 300 Batch loss 5.83484e-05\n",
      "Step 400 Batch loss 6.45425e-05\n",
      "Step 500 Batch loss 5.59329e-05\n",
      "Step 600 Batch loss 5.03257e-05\n",
      "New data, epoch 84\n",
      "Step 0 Batch loss 0.249949\n",
      "Step 100 Batch loss 7.95632e-05\n",
      "Step 200 Batch loss 5.1942e-05\n",
      "Step 300 Batch loss 4.66168e-05\n",
      "Step 400 Batch loss 5.14122e-05\n",
      "Step 500 Batch loss 4.6623e-05\n",
      "Step 600 Batch loss 4.05584e-05\n",
      "New data, epoch 85\n",
      "Step 0 Batch loss 0.280213\n",
      "Step 100 Batch loss 0.000109165\n",
      "Step 200 Batch loss 6.57701e-05\n",
      "Step 300 Batch loss 6.32135e-05\n",
      "Step 400 Batch loss 5.38511e-05\n",
      "Step 500 Batch loss 5.08825e-05\n",
      "Step 600 Batch loss 5.45204e-05\n",
      "New data, epoch 86\n",
      "Step 0 Batch loss 0.137077\n",
      "Step 100 Batch loss 4.93651e-05\n",
      "Step 200 Batch loss 3.98924e-05\n",
      "Step 300 Batch loss 4.5603e-05\n",
      "Step 400 Batch loss 5.68017e-05\n",
      "Step 500 Batch loss 4.96163e-05\n",
      "Step 600 Batch loss 4.03359e-05\n",
      "New data, epoch 87\n",
      "Step 0 Batch loss 0.209271\n",
      "Step 100 Batch loss 7.0601e-05\n",
      "Step 200 Batch loss 5.39545e-05\n",
      "Step 300 Batch loss 5.84389e-05\n",
      "Step 400 Batch loss 4.8926e-05\n",
      "Step 500 Batch loss 4.58491e-05\n",
      "Step 600 Batch loss 4.64072e-05\n",
      "New data, epoch 88\n",
      "Step 0 Batch loss 0.157245\n",
      "Step 100 Batch loss 5.12484e-05\n",
      "Step 200 Batch loss 3.85026e-05\n",
      "Step 300 Batch loss 4.65128e-05\n",
      "Step 400 Batch loss 3.76466e-05\n",
      "Step 500 Batch loss 4.66026e-05\n",
      "Step 600 Batch loss 3.69949e-05\n",
      "New data, epoch 89\n",
      "Step 0 Batch loss 0.131675\n",
      "Step 100 Batch loss 4.13227e-05\n",
      "Step 200 Batch loss 4.12561e-05\n",
      "Step 300 Batch loss 4.42885e-05\n",
      "Step 400 Batch loss 3.99285e-05\n",
      "Step 500 Batch loss 3.63003e-05\n",
      "Step 600 Batch loss 3.68645e-05\n",
      "New data, epoch 90\n",
      "Step 0 Batch loss 0.250473\n",
      "Step 100 Batch loss 5.54912e-05\n",
      "Step 200 Batch loss 4.47699e-05\n",
      "Step 300 Batch loss 5.21964e-05\n",
      "Step 400 Batch loss 4.61321e-05\n",
      "Step 500 Batch loss 4.35952e-05\n",
      "Step 600 Batch loss 4.08029e-05\n",
      "New data, epoch 91\n",
      "Step 0 Batch loss 0.148108\n",
      "Step 100 Batch loss 3.99127e-05\n",
      "Step 200 Batch loss 4.13893e-05\n",
      "Step 300 Batch loss 3.94332e-05\n",
      "Step 400 Batch loss 3.29389e-05\n",
      "Step 500 Batch loss 4.57474e-05\n",
      "Step 600 Batch loss 3.70427e-05\n",
      "New data, epoch 92\n",
      "Step 0 Batch loss 0.14973\n",
      "Step 100 Batch loss 6.36678e-05\n",
      "Step 200 Batch loss 6.64065e-05\n",
      "Step 300 Batch loss 5.31333e-05\n",
      "Step 400 Batch loss 5.86219e-05\n",
      "Step 500 Batch loss 4.39688e-05\n",
      "Step 600 Batch loss 4.8802e-05\n",
      "New data, epoch 93\n",
      "Step 0 Batch loss 0.138668\n",
      "Step 100 Batch loss 3.70549e-05\n",
      "Step 200 Batch loss 3.45502e-05\n",
      "Step 300 Batch loss 3.97333e-05\n",
      "Step 400 Batch loss 3.7923e-05\n",
      "Step 500 Batch loss 2.75238e-05\n",
      "Step 600 Batch loss 3.68629e-05\n",
      "New data, epoch 94\n",
      "Step 0 Batch loss 0.186943\n",
      "Step 100 Batch loss 3.70266e-05\n",
      "Step 200 Batch loss 5.37373e-05\n",
      "Step 300 Batch loss 4.62177e-05\n",
      "Step 400 Batch loss 3.01793e-05\n",
      "Step 500 Batch loss 3.24144e-05\n",
      "Step 600 Batch loss 4.41773e-05\n",
      "New data, epoch 95\n",
      "Step 0 Batch loss 0.242233\n",
      "Step 100 Batch loss 6.36278e-05\n",
      "Step 200 Batch loss 4.34331e-05\n",
      "Step 300 Batch loss 4.66387e-05\n",
      "Step 400 Batch loss 4.52357e-05\n",
      "Step 500 Batch loss 4.32636e-05\n",
      "Step 600 Batch loss 3.80631e-05\n",
      "New data, epoch 96\n",
      "Step 0 Batch loss 0.174077\n",
      "Step 100 Batch loss 4.17977e-05\n",
      "Step 200 Batch loss 4.03947e-05\n",
      "Step 300 Batch loss 3.16975e-05\n",
      "Step 400 Batch loss 3.84906e-05\n",
      "Step 500 Batch loss 4.05521e-05\n",
      "Step 600 Batch loss 4.46574e-05\n",
      "New data, epoch 97\n",
      "Step 0 Batch loss 0.241842\n",
      "Step 100 Batch loss 4.54e-05\n",
      "Step 200 Batch loss 4.27796e-05\n",
      "Step 300 Batch loss 3.05291e-05\n",
      "Step 400 Batch loss 4.14335e-05\n",
      "Step 500 Batch loss 3.49541e-05\n",
      "Step 600 Batch loss 2.4717e-05\n",
      "New data, epoch 98\n",
      "Step 0 Batch loss 0.245206\n",
      "Step 100 Batch loss 5.16848e-05\n",
      "Step 200 Batch loss 5.3256e-05\n",
      "Step 300 Batch loss 4.56658e-05\n",
      "Step 400 Batch loss 3.5526e-05\n",
      "Step 500 Batch loss 3.77959e-05\n",
      "Step 600 Batch loss 4.21793e-05\n",
      "New data, epoch 99\n",
      "Step 0 Batch loss 0.1373\n",
      "Step 100 Batch loss 3.99385e-05\n",
      "Step 200 Batch loss 3.32456e-05\n",
      "Step 300 Batch loss 4.09573e-05\n",
      "Step 400 Batch loss 3.60446e-05\n",
      "Step 500 Batch loss 3.18198e-05\n",
      "Step 600 Batch loss 3.45394e-05\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11b337a20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.initialize_all_variables())\n",
    "    plt.ion()\n",
    "    plt.figure()\n",
    "    plt.show()\n",
    "    loss_list = []\n",
    "\n",
    "    for epoch_idx in range(num_epochs):\n",
    "        x,y = generateData()\n",
    "        _current_cell_state = np.zeros((batch_size, state_size))\n",
    "        _current_hidden_state = np.zeros((batch_size, state_size))\n",
    "\n",
    "        print(\"New data, epoch\", epoch_idx)\n",
    "\n",
    "        for batch_idx in range(num_batches):\n",
    "            start_idx = batch_idx * truncated_backprop_length\n",
    "            end_idx = start_idx + truncated_backprop_length\n",
    "\n",
    "            batchX = x[:,start_idx:end_idx]\n",
    "            batchY = y[:,start_idx:end_idx]\n",
    "\n",
    "            _total_loss, _train_step, _current_state, _predictions_series = sess.run(\n",
    "                [total_loss, train_step, current_state, predictions_series],\n",
    "                feed_dict={\n",
    "                    batchX_placeholder: batchX,\n",
    "                    batchY_placeholder: batchY,\n",
    "                    cell_state: _current_cell_state,\n",
    "                    hidden_state: _current_hidden_state\n",
    "\n",
    "                })\n",
    "\n",
    "            _current_cell_state, _current_hidden_state = _current_state\n",
    "\n",
    "            loss_list.append(_total_loss)\n",
    "\n",
    "            if batch_idx%100 == 0:\n",
    "                print(\"Step\",batch_idx, \"Batch loss\", _total_loss)\n",
    "                plot(loss_list, _predictions_series, batchX, batchY)\n",
    "\n",
    "plt.ioff()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
